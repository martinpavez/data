{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e070a02",
   "metadata": {},
   "source": [
    "# RNN Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9720773",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4be95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow_addons.metrics import RSquare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abda7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\Desktop\\data\\hw_extra\n"
     ]
    }
   ],
   "source": [
    "# Add the folder to the Python path\n",
    "\n",
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())\n",
    "folder_path = os.path.abspath(\"functions/\") #INPUT_PATH)#'path_to_your_folder')  # Replace with the actual folder path\n",
    "sys.path.insert(0, folder_path)\n",
    "\n",
    "from Predictions import (\n",
    "    PredictionExperiment,\n",
    "    PredictionModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb95ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>season</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                       filename  season   \n",
       "0    978f49d7   predictor_978f49d7_1.parquet       1  \\\n",
       "1    978f49d7   predictor_978f49d7_2.parquet       2   \n",
       "2    978f49d7   predictor_978f49d7_3.parquet       3   \n",
       "3    978f49d7   predictor_978f49d7_4.parquet       4   \n",
       "4    978f49d7   predictor_978f49d7_5.parquet       5   \n",
       "..        ...                            ...     ...   \n",
       "247  458d357c   predictor_458d357c_8.parquet       8   \n",
       "248  458d357c   predictor_458d357c_9.parquet       9   \n",
       "249  458d357c  predictor_458d357c_10.parquet      10   \n",
       "250  458d357c  predictor_458d357c_11.parquet      11   \n",
       "251  458d357c  predictor_458d357c_12.parquet      12   \n",
       "\n",
       "                                               indices  \n",
       "0    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "1    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "2    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "3    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "4    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "..                                                 ...  \n",
       "247  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "248  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "249  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "250  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "251  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region=\"chile\"\n",
    "metadata_path = f\"data/climate_features/{region}/metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.reset_index(inplace=True, drop=True)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f10228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fde0e327-sst</th>\n",
       "      <th>340e2882-sst</th>\n",
       "      <th>b91ccd4e-t</th>\n",
       "      <th>c6184040-max_value</th>\n",
       "      <th>c6184040-latitude</th>\n",
       "      <th>c6184040-longitude</th>\n",
       "      <th>c1c59e4d-u</th>\n",
       "      <th>8c4a4c9c-u</th>\n",
       "      <th>cb76aaa7-u</th>\n",
       "      <th>d416bd24-u</th>\n",
       "      <th>...</th>\n",
       "      <th>PDO-longitude</th>\n",
       "      <th>ONI-PDO</th>\n",
       "      <th>SAM-ONI</th>\n",
       "      <th>DMI-SAM</th>\n",
       "      <th>ADV-DMI</th>\n",
       "      <th>HWN</th>\n",
       "      <th>HWF</th>\n",
       "      <th>HWD</th>\n",
       "      <th>HWM</th>\n",
       "      <th>HWA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.919132</td>\n",
       "      <td>1.738772</td>\n",
       "      <td>1.089508</td>\n",
       "      <td>97.656250</td>\n",
       "      <td>-44.75</td>\n",
       "      <td>284.00</td>\n",
       "      <td>0.105871</td>\n",
       "      <td>-0.078898</td>\n",
       "      <td>-0.430445</td>\n",
       "      <td>-0.884190</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.264685</td>\n",
       "      <td>0.454609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.787336</td>\n",
       "      <td>-1.410034</td>\n",
       "      <td>-0.630829</td>\n",
       "      <td>373.351562</td>\n",
       "      <td>-30.50</td>\n",
       "      <td>254.75</td>\n",
       "      <td>-0.627693</td>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.409054</td>\n",
       "      <td>-0.499015</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.924454</td>\n",
       "      <td>-1.843321</td>\n",
       "      <td>-0.622803</td>\n",
       "      <td>176.867188</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>267.00</td>\n",
       "      <td>-0.043367</td>\n",
       "      <td>-0.130367</td>\n",
       "      <td>-1.143116</td>\n",
       "      <td>-1.717260</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.316004</td>\n",
       "      <td>0.459299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.654869</td>\n",
       "      <td>-1.510971</td>\n",
       "      <td>-0.594147</td>\n",
       "      <td>257.140625</td>\n",
       "      <td>-39.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>-0.916506</td>\n",
       "      <td>-0.131766</td>\n",
       "      <td>0.242939</td>\n",
       "      <td>2.045603</td>\n",
       "      <td>...</td>\n",
       "      <td>284.50</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.731778</td>\n",
       "      <td>-0.329125</td>\n",
       "      <td>-0.561279</td>\n",
       "      <td>-177.140625</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>283.75</td>\n",
       "      <td>-0.382942</td>\n",
       "      <td>0.059941</td>\n",
       "      <td>1.272537</td>\n",
       "      <td>1.059203</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333758</td>\n",
       "      <td>1.009113</td>\n",
       "      <td>1.376251</td>\n",
       "      <td>479.250000</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>279.75</td>\n",
       "      <td>-1.298745</td>\n",
       "      <td>-0.230251</td>\n",
       "      <td>-1.866019</td>\n",
       "      <td>-3.538790</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.667017</td>\n",
       "      <td>1.287477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.319313</td>\n",
       "      <td>0.542892</td>\n",
       "      <td>1.694794</td>\n",
       "      <td>389.710938</td>\n",
       "      <td>-43.50</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-1.948353</td>\n",
       "      <td>-0.334173</td>\n",
       "      <td>-1.931295</td>\n",
       "      <td>-0.892254</td>\n",
       "      <td>...</td>\n",
       "      <td>285.50</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.045834</td>\n",
       "      <td>0.052455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.408862</td>\n",
       "      <td>0.216794</td>\n",
       "      <td>0.038391</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>-16.75</td>\n",
       "      <td>284.00</td>\n",
       "      <td>1.119975</td>\n",
       "      <td>-0.035370</td>\n",
       "      <td>0.270793</td>\n",
       "      <td>-1.237028</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.159879</td>\n",
       "      <td>0.336347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.305299</td>\n",
       "      <td>-0.773594</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>8.046875</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-0.212742</td>\n",
       "      <td>-0.110399</td>\n",
       "      <td>0.689868</td>\n",
       "      <td>0.749291</td>\n",
       "      <td>...</td>\n",
       "      <td>288.75</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.057992</td>\n",
       "      <td>-0.154225</td>\n",
       "      <td>-0.037231</td>\n",
       "      <td>511.515625</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>262.75</td>\n",
       "      <td>-0.149329</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>-0.341097</td>\n",
       "      <td>-0.983117</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2.21</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.787631</td>\n",
       "      <td>3.281134</td>\n",
       "      <td>1.904541</td>\n",
       "      <td>78.195312</td>\n",
       "      <td>-44.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-0.875827</td>\n",
       "      <td>-0.320428</td>\n",
       "      <td>-1.203329</td>\n",
       "      <td>-0.665547</td>\n",
       "      <td>...</td>\n",
       "      <td>288.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.18</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.232138</td>\n",
       "      <td>0.471902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.941696</td>\n",
       "      <td>0.118529</td>\n",
       "      <td>2.358032</td>\n",
       "      <td>145.171875</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-0.054579</td>\n",
       "      <td>-0.187836</td>\n",
       "      <td>-0.908075</td>\n",
       "      <td>-1.441484</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.128366</td>\n",
       "      <td>0.210749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.891779</td>\n",
       "      <td>0.668478</td>\n",
       "      <td>-0.367432</td>\n",
       "      <td>240.671875</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>276.25</td>\n",
       "      <td>-0.408831</td>\n",
       "      <td>0.033902</td>\n",
       "      <td>-0.807465</td>\n",
       "      <td>-2.105917</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-3.22</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.944119</td>\n",
       "      <td>1.671575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.822953</td>\n",
       "      <td>-0.111657</td>\n",
       "      <td>0.459320</td>\n",
       "      <td>509.304688</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>267.00</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>-0.014998</td>\n",
       "      <td>-1.053000</td>\n",
       "      <td>-1.580801</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.477985</td>\n",
       "      <td>0.791476</td>\n",
       "      <td>1.455139</td>\n",
       "      <td>326.085938</td>\n",
       "      <td>-37.75</td>\n",
       "      <td>248.00</td>\n",
       "      <td>-0.163268</td>\n",
       "      <td>-0.171091</td>\n",
       "      <td>-0.185525</td>\n",
       "      <td>-1.013541</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.140605</td>\n",
       "      <td>0.252510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.114140</td>\n",
       "      <td>0.559251</td>\n",
       "      <td>-0.345276</td>\n",
       "      <td>214.601562</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>279.25</td>\n",
       "      <td>-0.107252</td>\n",
       "      <td>-0.123992</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>-0.273835</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.162245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.800834</td>\n",
       "      <td>0.567632</td>\n",
       "      <td>-0.110260</td>\n",
       "      <td>181.664062</td>\n",
       "      <td>-34.75</td>\n",
       "      <td>269.50</td>\n",
       "      <td>-0.511619</td>\n",
       "      <td>-0.049460</td>\n",
       "      <td>-0.171346</td>\n",
       "      <td>1.625746</td>\n",
       "      <td>...</td>\n",
       "      <td>286.00</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.025564</td>\n",
       "      <td>-0.756622</td>\n",
       "      <td>-0.845428</td>\n",
       "      <td>168.304688</td>\n",
       "      <td>-31.50</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.780700</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>2.588101</td>\n",
       "      <td>3.529167</td>\n",
       "      <td>...</td>\n",
       "      <td>288.50</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.077496</td>\n",
       "      <td>0.188724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.122514</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>-0.428619</td>\n",
       "      <td>286.773438</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.896087</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>0.385470</td>\n",
       "      <td>-0.401255</td>\n",
       "      <td>...</td>\n",
       "      <td>288.50</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.577545</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>-2.803192</td>\n",
       "      <td>109.968750</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.240632</td>\n",
       "      <td>1.980949</td>\n",
       "      <td>1.935663</td>\n",
       "      <td>...</td>\n",
       "      <td>288.25</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.917992</td>\n",
       "      <td>0.805571</td>\n",
       "      <td>-1.676941</td>\n",
       "      <td>112.273438</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1.479571</td>\n",
       "      <td>0.159303</td>\n",
       "      <td>1.942374</td>\n",
       "      <td>1.564141</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.305154</td>\n",
       "      <td>-0.564701</td>\n",
       "      <td>-0.055542</td>\n",
       "      <td>167.328125</td>\n",
       "      <td>-40.75</td>\n",
       "      <td>254.25</td>\n",
       "      <td>-0.417084</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>-0.158457</td>\n",
       "      <td>0.494560</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.290145</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>0.301636</td>\n",
       "      <td>121.617188</td>\n",
       "      <td>-31.50</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.797355</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>1.101400</td>\n",
       "      <td>1.312052</td>\n",
       "      <td>...</td>\n",
       "      <td>288.50</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.078350</td>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.994559</td>\n",
       "      <td>-0.997697</td>\n",
       "      <td>3.390656</td>\n",
       "      <td>267.171875</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-0.835561</td>\n",
       "      <td>-0.323256</td>\n",
       "      <td>-1.237919</td>\n",
       "      <td>-1.502152</td>\n",
       "      <td>...</td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.201349</td>\n",
       "      <td>1.964806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.622711</td>\n",
       "      <td>-1.414225</td>\n",
       "      <td>-0.558289</td>\n",
       "      <td>482.539062</td>\n",
       "      <td>-42.75</td>\n",
       "      <td>266.50</td>\n",
       "      <td>-0.256694</td>\n",
       "      <td>0.142748</td>\n",
       "      <td>-0.794753</td>\n",
       "      <td>-1.503265</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.420392</td>\n",
       "      <td>2.401146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.904834</td>\n",
       "      <td>4.005782</td>\n",
       "      <td>-0.664856</td>\n",
       "      <td>467.734375</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>263.50</td>\n",
       "      <td>-0.033916</td>\n",
       "      <td>0.122715</td>\n",
       "      <td>-0.696356</td>\n",
       "      <td>-0.651065</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.40</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.883779</td>\n",
       "      <td>-0.649003</td>\n",
       "      <td>1.052490</td>\n",
       "      <td>309.171875</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>270.00</td>\n",
       "      <td>-1.253862</td>\n",
       "      <td>-0.033725</td>\n",
       "      <td>-0.617760</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>2.59</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.090156</td>\n",
       "      <td>0.120077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.764071</td>\n",
       "      <td>-1.088994</td>\n",
       "      <td>-0.132904</td>\n",
       "      <td>471.460938</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.388574</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>-0.182132</td>\n",
       "      <td>-0.499381</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.813097</td>\n",
       "      <td>-1.028325</td>\n",
       "      <td>-0.153351</td>\n",
       "      <td>187.953125</td>\n",
       "      <td>-40.75</td>\n",
       "      <td>270.75</td>\n",
       "      <td>-0.416868</td>\n",
       "      <td>0.080299</td>\n",
       "      <td>0.031501</td>\n",
       "      <td>1.503116</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.159312</td>\n",
       "      <td>0.261181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.316208</td>\n",
       "      <td>-1.001537</td>\n",
       "      <td>2.926208</td>\n",
       "      <td>253.609375</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-1.931704</td>\n",
       "      <td>-0.328592</td>\n",
       "      <td>-1.373727</td>\n",
       "      <td>-0.731982</td>\n",
       "      <td>...</td>\n",
       "      <td>284.25</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.703961</td>\n",
       "      <td>1.345956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.545902</td>\n",
       "      <td>0.684458</td>\n",
       "      <td>-0.716248</td>\n",
       "      <td>73.984375</td>\n",
       "      <td>-20.75</td>\n",
       "      <td>279.75</td>\n",
       "      <td>0.502480</td>\n",
       "      <td>0.019963</td>\n",
       "      <td>0.398782</td>\n",
       "      <td>-0.175047</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.407281</td>\n",
       "      <td>0.095528</td>\n",
       "      <td>-2.356140</td>\n",
       "      <td>522.773438</td>\n",
       "      <td>-39.75</td>\n",
       "      <td>260.25</td>\n",
       "      <td>-0.012340</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.525798</td>\n",
       "      <td>1.673651</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.804391</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>-0.764587</td>\n",
       "      <td>98.296875</td>\n",
       "      <td>-33.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>0.048256</td>\n",
       "      <td>1.417780</td>\n",
       "      <td>1.811432</td>\n",
       "      <td>...</td>\n",
       "      <td>288.25</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.623110</td>\n",
       "      <td>-0.775934</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>635.664062</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>-0.005297</td>\n",
       "      <td>0.042142</td>\n",
       "      <td>-1.091081</td>\n",
       "      <td>-2.791398</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.271118</td>\n",
       "      <td>0.596909</td>\n",
       "      <td>-1.518921</td>\n",
       "      <td>279.187500</td>\n",
       "      <td>-42.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1.137715</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>2.317019</td>\n",
       "      <td>3.192926</td>\n",
       "      <td>...</td>\n",
       "      <td>288.00</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.503137</td>\n",
       "      <td>-2.069502</td>\n",
       "      <td>0.145416</td>\n",
       "      <td>356.726562</td>\n",
       "      <td>-39.00</td>\n",
       "      <td>268.25</td>\n",
       "      <td>-0.666852</td>\n",
       "      <td>-0.013266</td>\n",
       "      <td>-0.852003</td>\n",
       "      <td>-0.626503</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>0.393845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.815855</td>\n",
       "      <td>-0.599653</td>\n",
       "      <td>1.963348</td>\n",
       "      <td>576.476562</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>274.50</td>\n",
       "      <td>-0.738280</td>\n",
       "      <td>-0.177069</td>\n",
       "      <td>-2.385782</td>\n",
       "      <td>-3.334502</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.013254</td>\n",
       "      <td>1.734547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.694864</td>\n",
       "      <td>0.298523</td>\n",
       "      <td>-1.240906</td>\n",
       "      <td>425.710938</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.881341</td>\n",
       "      <td>0.197502</td>\n",
       "      <td>1.113960</td>\n",
       "      <td>0.424298</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.136404</td>\n",
       "      <td>0.392977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1.684551</td>\n",
       "      <td>-1.279567</td>\n",
       "      <td>-1.594513</td>\n",
       "      <td>741.007812</td>\n",
       "      <td>-37.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>-0.144831</td>\n",
       "      <td>-0.010335</td>\n",
       "      <td>-0.448903</td>\n",
       "      <td>0.479555</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.236235</td>\n",
       "      <td>0.449445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.972525</td>\n",
       "      <td>-0.811385</td>\n",
       "      <td>2.480347</td>\n",
       "      <td>340.070312</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>281.50</td>\n",
       "      <td>-0.714111</td>\n",
       "      <td>-0.198986</td>\n",
       "      <td>-1.254210</td>\n",
       "      <td>-2.100796</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.832757</td>\n",
       "      <td>1.470685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.674154</td>\n",
       "      <td>-2.604309</td>\n",
       "      <td>196.914062</td>\n",
       "      <td>-32.00</td>\n",
       "      <td>251.75</td>\n",
       "      <td>1.969577</td>\n",
       "      <td>0.293628</td>\n",
       "      <td>2.718291</td>\n",
       "      <td>2.566399</td>\n",
       "      <td>...</td>\n",
       "      <td>288.25</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.038625</td>\n",
       "      <td>-0.281197</td>\n",
       "      <td>1.889008</td>\n",
       "      <td>293.242188</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>275.25</td>\n",
       "      <td>-1.626010</td>\n",
       "      <td>-0.131432</td>\n",
       "      <td>-1.337071</td>\n",
       "      <td>-1.079539</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.642546</td>\n",
       "      <td>1.574507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.798505</td>\n",
       "      <td>-0.066134</td>\n",
       "      <td>-0.601898</td>\n",
       "      <td>394.335938</td>\n",
       "      <td>-30.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>-0.069963</td>\n",
       "      <td>0.047161</td>\n",
       "      <td>-0.478754</td>\n",
       "      <td>-0.459560</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.096066</td>\n",
       "      <td>0.142240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.696853</td>\n",
       "      <td>1.828449</td>\n",
       "      <td>-0.069305</td>\n",
       "      <td>241.273438</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.210970</td>\n",
       "      <td>-0.090252</td>\n",
       "      <td>-0.647864</td>\n",
       "      <td>-0.523568</td>\n",
       "      <td>...</td>\n",
       "      <td>290.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.182383</td>\n",
       "      <td>0.347030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.289804</td>\n",
       "      <td>-0.283383</td>\n",
       "      <td>0.296448</td>\n",
       "      <td>69.273438</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>-0.329532</td>\n",
       "      <td>-0.134166</td>\n",
       "      <td>-0.098069</td>\n",
       "      <td>1.014850</td>\n",
       "      <td>...</td>\n",
       "      <td>288.50</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.805386</td>\n",
       "      <td>-1.339101</td>\n",
       "      <td>1.041809</td>\n",
       "      <td>173.921875</td>\n",
       "      <td>-30.75</td>\n",
       "      <td>263.75</td>\n",
       "      <td>-0.359766</td>\n",
       "      <td>-0.112230</td>\n",
       "      <td>-0.617500</td>\n",
       "      <td>0.157585</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.888151</td>\n",
       "      <td>0.463281</td>\n",
       "      <td>0.174347</td>\n",
       "      <td>416.359375</td>\n",
       "      <td>-38.75</td>\n",
       "      <td>250.50</td>\n",
       "      <td>0.099207</td>\n",
       "      <td>-0.098081</td>\n",
       "      <td>-0.825885</td>\n",
       "      <td>-1.598131</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.093115</td>\n",
       "      <td>0.159736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.498531</td>\n",
       "      <td>0.105024</td>\n",
       "      <td>0.890228</td>\n",
       "      <td>193.250000</td>\n",
       "      <td>-41.50</td>\n",
       "      <td>284.00</td>\n",
       "      <td>-0.500976</td>\n",
       "      <td>0.093317</td>\n",
       "      <td>-0.361774</td>\n",
       "      <td>-0.169246</td>\n",
       "      <td>...</td>\n",
       "      <td>287.75</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.608831</td>\n",
       "      <td>1.051362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.032100</td>\n",
       "      <td>-0.932777</td>\n",
       "      <td>0.294556</td>\n",
       "      <td>236.789062</td>\n",
       "      <td>-32.75</td>\n",
       "      <td>273.00</td>\n",
       "      <td>-0.565875</td>\n",
       "      <td>0.113102</td>\n",
       "      <td>-0.017455</td>\n",
       "      <td>0.060891</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.127023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.892110</td>\n",
       "      <td>-1.568828</td>\n",
       "      <td>2.215240</td>\n",
       "      <td>571.453125</td>\n",
       "      <td>-45.00</td>\n",
       "      <td>269.00</td>\n",
       "      <td>-0.719636</td>\n",
       "      <td>-0.069003</td>\n",
       "      <td>-2.059958</td>\n",
       "      <td>-2.939700</td>\n",
       "      <td>...</td>\n",
       "      <td>282.00</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.856872</td>\n",
       "      <td>1.633572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.777572</td>\n",
       "      <td>-0.755047</td>\n",
       "      <td>1.604645</td>\n",
       "      <td>218.343750</td>\n",
       "      <td>-31.75</td>\n",
       "      <td>245.00</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>-0.130564</td>\n",
       "      <td>-0.400377</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>...</td>\n",
       "      <td>292.00</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.735379</td>\n",
       "      <td>1.570003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fde0e327-sst  340e2882-sst  b91ccd4e-t  c6184040-max_value   \n",
       "0       1.919132      1.738772    1.089508           97.656250  \\\n",
       "1      -1.787336     -1.410034   -0.630829          373.351562   \n",
       "2      -0.924454     -1.843321   -0.622803          176.867188   \n",
       "3      -1.654869     -1.510971   -0.594147          257.140625   \n",
       "4      -1.731778     -0.329125   -0.561279         -177.140625   \n",
       "5       0.333758      1.009113    1.376251          479.250000   \n",
       "6       0.319313      0.542892    1.694794          389.710938   \n",
       "7       0.408862      0.216794    0.038391            1.476562   \n",
       "8      -0.305299     -0.773594    0.053955            8.046875   \n",
       "9      -1.057992     -0.154225   -0.037231          511.515625   \n",
       "10      2.787631      3.281134    1.904541           78.195312   \n",
       "11     -0.941696      0.118529    2.358032          145.171875   \n",
       "12     -0.891779      0.668478   -0.367432          240.671875   \n",
       "13     -0.822953     -0.111657    0.459320          509.304688   \n",
       "14     -0.477985      0.791476    1.455139          326.085938   \n",
       "15      1.114140      0.559251   -0.345276          214.601562   \n",
       "16      0.800834      0.567632   -0.110260          181.664062   \n",
       "17     -2.025564     -0.756622   -0.845428          168.304688   \n",
       "18      0.122514      0.031417   -0.428619          286.773438   \n",
       "19      0.577545      0.038116   -2.803192          109.968750   \n",
       "20      1.917992      0.805571   -1.676941          112.273438   \n",
       "21      0.305154     -0.564701   -0.055542          167.328125   \n",
       "22      1.290145      0.759400    0.301636          121.617188   \n",
       "23     -0.994559     -0.997697    3.390656          267.171875   \n",
       "24     -0.622711     -1.414225   -0.558289          482.539062   \n",
       "25      2.904834      4.005782   -0.664856          467.734375   \n",
       "26     -1.883779     -0.649003    1.052490          309.171875   \n",
       "27     -1.764071     -1.088994   -0.132904          471.460938   \n",
       "28     -0.813097     -1.028325   -0.153351          187.953125   \n",
       "29     -0.316208     -1.001537    2.926208          253.609375   \n",
       "30      1.545902      0.684458   -0.716248           73.984375   \n",
       "31      0.407281      0.095528   -2.356140          522.773438   \n",
       "32      0.804391     -0.036971   -0.764587           98.296875   \n",
       "33     -0.623110     -0.775934    0.359375          635.664062   \n",
       "34      1.271118      0.596909   -1.518921          279.187500   \n",
       "35     -1.503137     -2.069502    0.145416          356.726562   \n",
       "36     -0.815855     -0.599653    1.963348          576.476562   \n",
       "37      1.694864      0.298523   -1.240906          425.710938   \n",
       "38     -1.684551     -1.279567   -1.594513          741.007812   \n",
       "39     -0.972525     -0.811385    2.480347          340.070312   \n",
       "40     -0.060150     -0.674154   -2.604309          196.914062   \n",
       "41      0.038625     -0.281197    1.889008          293.242188   \n",
       "42      0.798505     -0.066134   -0.601898          394.335938   \n",
       "43      2.696853      1.828449   -0.069305          241.273438   \n",
       "44     -0.289804     -0.283383    0.296448           69.273438   \n",
       "45     -0.805386     -1.339101    1.041809          173.921875   \n",
       "46      0.888151      0.463281    0.174347          416.359375   \n",
       "47      0.498531      0.105024    0.890228          193.250000   \n",
       "48     -1.032100     -0.932777    0.294556          236.789062   \n",
       "49     -0.892110     -1.568828    2.215240          571.453125   \n",
       "50     -0.777572     -0.755047    1.604645          218.343750   \n",
       "\n",
       "    c6184040-latitude  c6184040-longitude  c1c59e4d-u  8c4a4c9c-u  cb76aaa7-u   \n",
       "0              -44.75              284.00    0.105871   -0.078898   -0.430445  \\\n",
       "1              -30.50              254.75   -0.627693   -0.089662   -0.409054   \n",
       "2              -45.00              267.00   -0.043367   -0.130367   -1.143116   \n",
       "3              -39.75              245.00   -0.916506   -0.131766    0.242939   \n",
       "4              -15.00              283.75   -0.382942    0.059941    1.272537   \n",
       "5              -45.00              279.75   -1.298745   -0.230251   -1.866019   \n",
       "6              -43.50              284.00   -1.948353   -0.334173   -1.931295   \n",
       "7              -16.75              284.00    1.119975   -0.035370    0.270793   \n",
       "8              -15.00              284.00   -0.212742   -0.110399    0.689868   \n",
       "9              -45.00              262.75   -0.149329    0.024278   -0.341097   \n",
       "10             -44.00              284.00   -0.875827   -0.320428   -1.203329   \n",
       "11             -45.00              284.00   -0.054579   -0.187836   -0.908075   \n",
       "12             -45.00              276.25   -0.408831    0.033902   -0.807465   \n",
       "13             -45.00              267.00    0.226747   -0.014998   -1.053000   \n",
       "14             -37.75              248.00   -0.163268   -0.171091   -0.185525   \n",
       "15             -45.00              279.25   -0.107252   -0.123992    0.015712   \n",
       "16             -34.75              269.50   -0.511619   -0.049460   -0.171346   \n",
       "17             -31.50              245.00    0.780700    0.038399    2.588101   \n",
       "18             -45.00              245.00    0.896087    0.125448    0.385470   \n",
       "19             -45.00              260.00    1.208770    0.240632    1.980949   \n",
       "20             -45.00              245.00    1.479571    0.159303    1.942374   \n",
       "21             -40.75              254.25   -0.417084    0.020963   -0.158457   \n",
       "22             -31.50              245.00    0.797355    0.079296    1.101400   \n",
       "23             -45.00              284.00   -0.835561   -0.323256   -1.237919   \n",
       "24             -42.75              266.50   -0.256694    0.142748   -0.794753   \n",
       "25             -45.00              263.50   -0.033916    0.122715   -0.696356   \n",
       "26             -35.00              270.00   -1.253862   -0.033725   -0.617760   \n",
       "27             -45.00              245.00    0.388574    0.039939   -0.182132   \n",
       "28             -40.75              270.75   -0.416868    0.080299    0.031501   \n",
       "29             -45.00              284.00   -1.931704   -0.328592   -1.373727   \n",
       "30             -20.75              279.75    0.502480    0.019963    0.398782   \n",
       "31             -39.75              260.25   -0.012340    0.248396    0.525798   \n",
       "32             -33.75              245.00    0.897397    0.048256    1.417780   \n",
       "33             -45.00              275.00   -0.005297    0.042142   -1.091081   \n",
       "34             -42.75              245.00    1.137715    0.200264    2.317019   \n",
       "35             -39.00              268.25   -0.666852   -0.013266   -0.852003   \n",
       "36             -45.00              274.50   -0.738280   -0.177069   -2.385782   \n",
       "37             -45.00              245.00    0.881341    0.197502    1.113960   \n",
       "38             -37.75              245.00   -0.144831   -0.010335   -0.448903   \n",
       "39             -45.00              281.50   -0.714111   -0.198986   -1.254210   \n",
       "40             -32.00              251.75    1.969577    0.293628    2.718291   \n",
       "41             -45.00              275.25   -1.626010   -0.131432   -1.337071   \n",
       "42             -30.75              245.00   -0.069963    0.047161   -0.478754   \n",
       "43             -45.00              245.00    0.210970   -0.090252   -0.647864   \n",
       "44             -45.00              245.00   -0.329532   -0.134166   -0.098069   \n",
       "45             -30.75              263.75   -0.359766   -0.112230   -0.617500   \n",
       "46             -38.75              250.50    0.099207   -0.098081   -0.825885   \n",
       "47             -41.50              284.00   -0.500976    0.093317   -0.361774   \n",
       "48             -32.75              273.00   -0.565875    0.113102   -0.017455   \n",
       "49             -45.00              269.00   -0.719636   -0.069003   -2.059958   \n",
       "50             -31.75              245.00   -0.224689   -0.130564   -0.400377   \n",
       "\n",
       "    d416bd24-u  ...  PDO-longitude  ONI-PDO  SAM-ONI  DMI-SAM  ADV-DMI  HWN   \n",
       "0    -0.884190  ...         292.00    -0.37     2.09    -1.38    0.477  0.3  \\\n",
       "1    -0.499015  ...         282.00    -0.89    -1.95     2.17    0.047  0.0   \n",
       "2    -1.717260  ...         292.00     0.27    -0.75    -2.37   -0.360  0.1   \n",
       "3     2.045603  ...         284.50    -1.49    -1.55     0.35   -0.170  0.0   \n",
       "4     1.059203  ...         292.00     1.20     0.86    -5.07    0.028  0.0   \n",
       "5    -3.538790  ...         292.00    -0.06     0.81    -0.95   -0.020  0.4   \n",
       "6    -0.892254  ...         285.50    -0.51    -0.08    -0.01   -0.260  0.1   \n",
       "7    -1.237028  ...         292.00     0.06     0.52    -1.88   -0.101  0.1   \n",
       "8     0.749291  ...         288.75     0.30     0.11    -0.10   -0.483  0.0   \n",
       "9    -0.983117  ...         282.00     0.59    -0.15     2.21   -0.019  0.0   \n",
       "10   -0.665547  ...         288.25     0.16     2.18    -2.21   -0.162  0.3   \n",
       "11   -1.441484  ...         292.00     1.72    -1.00     1.52   -0.101  0.1   \n",
       "12   -2.105917  ...         292.00     0.48    -0.92    -3.22   -0.278  0.4   \n",
       "13   -1.580801  ...         282.00     0.33    -0.27     1.90   -0.417  0.0   \n",
       "14   -1.013541  ...         282.00     1.71     1.14     1.31   -0.274  0.1   \n",
       "15   -0.273835  ...         282.00     0.94     1.25     0.30    0.152  0.1   \n",
       "16    1.625746  ...         286.00    -0.14    -1.80     1.88    0.156  0.0   \n",
       "17    3.529167  ...         288.50    -0.10    -0.16    -0.05   -0.167  0.2   \n",
       "18   -0.401255  ...         288.50    -2.22     0.40    -0.20    0.003  0.0   \n",
       "19    1.935663  ...         288.25    -0.21     1.21    -1.23    0.084  0.0   \n",
       "20    1.564141  ...         292.00     0.33    -0.28     0.58   -0.317  0.0   \n",
       "21    0.494560  ...         282.00     0.67     0.04     1.38   -0.206  0.0   \n",
       "22    1.312052  ...         288.50    -2.22     1.01     1.91    0.263  0.1   \n",
       "23   -1.502152  ...         285.00     0.44    -1.00     1.93    0.090  0.6   \n",
       "24   -1.503265  ...         282.00    -0.03    -0.45     0.03   -0.413  0.4   \n",
       "25   -0.651065  ...         282.00     0.99     2.40    -0.89    0.863  0.0   \n",
       "26   -0.014796  ...         282.00    -1.09    -1.48     2.59   -0.336  0.1   \n",
       "27   -0.499381  ...         282.00    -1.92    -1.46     3.12   -0.148  0.0   \n",
       "28    1.503116  ...         282.00     0.00    -0.75    -2.05   -0.248  0.1   \n",
       "29   -0.731982  ...         284.25    -1.12    -0.35     1.16   -0.051  0.9   \n",
       "30   -0.175047  ...         292.00     1.57     1.31     1.29   -0.158  0.0   \n",
       "31    1.673651  ...         282.00    -0.60     0.35    -0.69    0.189  0.0   \n",
       "32    1.811432  ...         288.25    -0.64     0.66    -1.02   -0.132  0.0   \n",
       "33   -2.791398  ...         282.00    -0.10    -0.57    -2.76   -0.300  0.0   \n",
       "34    3.192926  ...         288.00    -0.42     0.94     1.34    0.172  0.0   \n",
       "35   -0.626503  ...         282.00    -0.87    -1.50     2.80   -0.227  0.2   \n",
       "36   -3.334502  ...         282.00    -1.31    -0.55     1.01   -0.053  0.6   \n",
       "37    0.424298  ...         292.00    -0.51     1.36     1.09    0.160  0.1   \n",
       "38    0.479555  ...         282.00    -2.04    -1.64     0.25   -0.212  0.1   \n",
       "39   -2.100796  ...         282.00    -2.40    -1.09     3.43   -0.128  0.6   \n",
       "40    2.566399  ...         288.25    -1.31     0.05    -0.90    0.268  0.0   \n",
       "41   -1.079539  ...         282.00    -1.04    -0.17     0.77    0.141  0.7   \n",
       "42   -0.459560  ...         282.00     1.86     0.64     2.45    0.046  0.1   \n",
       "43   -0.523568  ...         290.75     0.29     2.57     0.72    0.272  0.2   \n",
       "44    1.014850  ...         288.50     0.61    -0.67    -1.52   -0.310  0.0   \n",
       "45    0.157585  ...         282.00    -0.03    -0.84     1.44    0.109  0.0   \n",
       "46   -1.598131  ...         292.00    -0.21     0.90     1.44    0.309  0.1   \n",
       "47   -0.169246  ...         287.75    -0.00     0.51    -1.78    0.243  0.4   \n",
       "48    0.060891  ...         282.00    -0.99    -1.27     2.28    0.030  0.1   \n",
       "49   -2.939700  ...         282.00    -2.71    -0.98     2.74   -0.120  1.0   \n",
       "50    0.030860  ...         292.00    -2.21    -0.92     2.94   -0.092  0.6   \n",
       "\n",
       "    HWF  HWD       HWM       HWA  \n",
       "0   0.9  0.6  0.264685  0.454609  \n",
       "1   0.0  0.0  0.000000  0.000000  \n",
       "2   0.3  0.3  0.316004  0.459299  \n",
       "3   0.0  0.0  0.000000  0.000000  \n",
       "4   0.0  0.0  0.000000  0.000000  \n",
       "5   1.4  0.8  0.667017  1.287477  \n",
       "6   0.3  0.3  0.045834  0.052455  \n",
       "7   0.3  0.3  0.159879  0.336347  \n",
       "8   0.0  0.0  0.000000  0.000000  \n",
       "9   0.0  0.0  0.000000  0.000000  \n",
       "10  0.9  0.9  0.232138  0.471902  \n",
       "11  0.3  0.3  0.128366  0.210749  \n",
       "12  1.2  0.9  0.944119  1.671575  \n",
       "13  0.0  0.0  0.000000  0.000000  \n",
       "14  0.3  0.3  0.140605  0.252510  \n",
       "15  0.4  0.4  0.091075  0.162245  \n",
       "16  0.0  0.0  0.000000  0.000000  \n",
       "17  0.7  0.4  0.077496  0.188724  \n",
       "18  0.0  0.0  0.000000  0.000000  \n",
       "19  0.0  0.0  0.000000  0.000000  \n",
       "20  0.0  0.0  0.000000  0.000000  \n",
       "21  0.0  0.0  0.000000  0.000000  \n",
       "22  0.3  0.3  0.078350  0.119306  \n",
       "23  2.8  2.8  1.201349  1.964806  \n",
       "24  1.6  1.6  1.420392  2.401146  \n",
       "25  0.0  0.0  0.000000  0.000000  \n",
       "26  0.3  0.3  0.090156  0.120077  \n",
       "27  0.0  0.0  0.000000  0.000000  \n",
       "28  0.3  0.3  0.159312  0.261181  \n",
       "29  3.1  2.1  0.703961  1.345956  \n",
       "30  0.0  0.0  0.000000  0.000000  \n",
       "31  0.0  0.0  0.000000  0.000000  \n",
       "32  0.0  0.0  0.000000  0.000000  \n",
       "33  0.0  0.0  0.000000  0.000000  \n",
       "34  0.0  0.0  0.000000  0.000000  \n",
       "35  0.6  0.6  0.223714  0.393845  \n",
       "36  2.4  2.1  1.013254  1.734547  \n",
       "37  0.4  0.4  0.136404  0.392977  \n",
       "38  0.3  0.3  0.236235  0.449445  \n",
       "39  2.8  2.4  0.832757  1.470685  \n",
       "40  0.0  0.0  0.000000  0.000000  \n",
       "41  3.0  2.7  0.642546  1.574507  \n",
       "42  0.3  0.3  0.096066  0.142240  \n",
       "43  0.9  0.9  0.182383  0.347030  \n",
       "44  0.0  0.0  0.000000  0.000000  \n",
       "45  0.0  0.0  0.000000  0.000000  \n",
       "46  0.3  0.3  0.093115  0.159736  \n",
       "47  1.6  1.6  0.608831  1.051362  \n",
       "48  0.3  0.3  0.090361  0.127023  \n",
       "49  3.5  2.6  0.856872  1.633572  \n",
       "50  2.0  1.4  0.735379  1.570003  \n",
       "\n",
       "[51 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {i: pd.read_parquet(f\"data/climate_features/{region}/predictor_9bd58418_{i}.parquet\") for i in range(1,13)}\n",
    "data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3974e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = [\"HWN\", \"HWF\", \"HWD\", \"HWA\", \"HWM\"]\n",
    "label = [\"HWF\",\"HWD\"]\n",
    "#data[12].drop(columns=indices_of_interest, inplace=True)\n",
    "features = data[12].columns.difference(indices_of_interest)\n",
    "\n",
    "X = data[12][features]\n",
    "y = data[12][indices_of_interest]\n",
    "n_labels = len(indices_of_interest)\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "n_features = len(features)\n",
    "model = PredictionModel(data[12], 12, indices_of_interest, Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, n_features)),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(n_labels)  # Predict 5 indices\n",
    "]), name_regressor=\"RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41843d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[0.09803922 0.10021786 0.10021786 0.10021786 0.10021786 0.10021786\n",
      " 0.10021786 0.10021786 0.10021786 0.10021786]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.train_predict(5) ##check how to mesaure metrics correctly because of NN using 5 size output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c101f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RNN',\n",
       " 12,\n",
       " 'mae',\n",
       " 'CV',\n",
       " 0.5374250984345013,\n",
       " 0.4159048424597797,\n",
       " 0.4315235333695399,\n",
       " 0.5283999179911831,\n",
       " 0.483200864679509,\n",
       " 0.47929085138690264]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_metric(\"mae\", \"CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4e6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = [\"HWN\", \"HWF\", \"HWD\", \"HWA\", \"HWM\"]\n",
    "label = [\"HWF\",\"HWD\"]\n",
    "#data[12].drop(columns=indices_of_interest, inplace=True)\n",
    "features = data[12].columns.difference(indices_of_interest)\n",
    "\n",
    "X = data[12][features]\n",
    "y = data[12][indices_of_interest]\n",
    "n_labels = len(indices_of_interest)\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "n_features = len(features)\n",
    "\n",
    "# Standardize inputs\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Reshape for RNN/LSTM (samples, timesteps=1, features)\n",
    "X_scaled = X_scaled.reshape((n_samples, 1, n_features))  \n",
    "\n",
    "# Train/Validation split\n",
    "X_train, X_val = X_scaled[:46], X_scaled[46:]\n",
    "y_train, y_val = y_scaled[:46], y_scaled[46:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fcd8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 3s 79ms/step - loss: 0.8858 - mse: 1.2780 - mape: 247.9996 - r_square: -0.4531 - val_loss: 1.1801 - val_mse: 2.1849 - val_mape: 114.1782 - val_r_square: -0.6159\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8165 - mse: 1.1508 - mape: 211.7742 - r_square: -0.3085 - val_loss: 1.1671 - val_mse: 2.1323 - val_mape: 111.8369 - val_r_square: -0.5853\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8207 - mse: 1.1745 - mape: 217.6633 - r_square: -0.3386 - val_loss: 1.1553 - val_mse: 2.0857 - val_mape: 109.4768 - val_r_square: -0.5601\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7639 - mse: 1.0600 - mape: 187.5799 - r_square: -0.2058 - val_loss: 1.1467 - val_mse: 2.0502 - val_mape: 107.4829 - val_r_square: -0.5408\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7585 - mse: 1.0268 - mape: 202.1478 - r_square: -0.1629 - val_loss: 1.1404 - val_mse: 2.0189 - val_mape: 106.1671 - val_r_square: -0.5235\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7283 - mse: 0.9984 - mape: 175.1372 - r_square: -0.1326 - val_loss: 1.1354 - val_mse: 1.9896 - val_mape: 105.2030 - val_r_square: -0.5084\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7198 - mse: 0.9519 - mape: 157.3153 - r_square: -0.0770 - val_loss: 1.1314 - val_mse: 1.9665 - val_mape: 104.3870 - val_r_square: -0.4969\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7043 - mse: 0.9371 - mape: 178.0192 - r_square: -0.0608 - val_loss: 1.1275 - val_mse: 1.9467 - val_mape: 103.5119 - val_r_square: -0.4882\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6828 - mse: 0.8970 - mape: 151.4959 - r_square: -0.0184 - val_loss: 1.1224 - val_mse: 1.9215 - val_mape: 102.6159 - val_r_square: -0.4764\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6896 - mse: 0.8788 - mape: 148.4404 - r_square: 1.3336e-04 - val_loss: 1.1149 - val_mse: 1.8998 - val_mape: 100.9873 - val_r_square: -0.4656\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6699 - mse: 0.8528 - mape: 152.5132 - r_square: 0.0347 - val_loss: 1.1107 - val_mse: 1.8885 - val_mape: 99.8267 - val_r_square: -0.4625\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6501 - mse: 0.8393 - mape: 132.1521 - r_square: 0.0520 - val_loss: 1.1077 - val_mse: 1.8812 - val_mape: 99.0904 - val_r_square: -0.4616\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6251 - mse: 0.7742 - mape: 142.8479 - r_square: 0.1230 - val_loss: 1.1029 - val_mse: 1.8668 - val_mape: 98.1839 - val_r_square: -0.4547\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6318 - mse: 0.7897 - mape: 143.0226 - r_square: 0.1062 - val_loss: 1.0998 - val_mse: 1.8542 - val_mape: 97.6514 - val_r_square: -0.4486\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6178 - mse: 0.7700 - mape: 133.3905 - r_square: 0.1281 - val_loss: 1.0962 - val_mse: 1.8466 - val_mape: 96.7728 - val_r_square: -0.4425\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6161 - mse: 0.7578 - mape: 148.6443 - r_square: 0.1418 - val_loss: 1.0951 - val_mse: 1.8445 - val_mape: 96.3575 - val_r_square: -0.4418\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5895 - mse: 0.7222 - mape: 126.2786 - r_square: 0.1818 - val_loss: 1.0915 - val_mse: 1.8319 - val_mape: 95.8876 - val_r_square: -0.4324\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5964 - mse: 0.7469 - mape: 141.7832 - r_square: 0.1572 - val_loss: 1.0874 - val_mse: 1.8184 - val_mape: 95.2902 - val_r_square: -0.4219\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5703 - mse: 0.7106 - mape: 124.9303 - r_square: 0.1941 - val_loss: 1.0825 - val_mse: 1.8006 - val_mape: 94.8103 - val_r_square: -0.4086\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5791 - mse: 0.7139 - mape: 145.8914 - r_square: 0.1926 - val_loss: 1.0765 - val_mse: 1.7855 - val_mape: 93.8374 - val_r_square: -0.3957\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5820 - mse: 0.6967 - mape: 142.9888 - r_square: 0.2137 - val_loss: 1.0724 - val_mse: 1.7769 - val_mape: 93.1994 - val_r_square: -0.3888\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5543 - mse: 0.6749 - mape: 149.9363 - r_square: 0.2350 - val_loss: 1.0668 - val_mse: 1.7517 - val_mape: 93.0650 - val_r_square: -0.3719\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5403 - mse: 0.6510 - mape: 144.4231 - r_square: 0.2642 - val_loss: 1.0614 - val_mse: 1.7367 - val_mape: 92.1983 - val_r_square: -0.3610\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5371 - mse: 0.6384 - mape: 159.0051 - r_square: 0.2753 - val_loss: 1.0560 - val_mse: 1.7087 - val_mape: 92.1180 - val_r_square: -0.3415\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5085 - mse: 0.6062 - mape: 129.1322 - r_square: 0.3137 - val_loss: 1.0489 - val_mse: 1.6806 - val_mape: 91.6740 - val_r_square: -0.3207\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5086 - mse: 0.6114 - mape: 130.2932 - r_square: 0.3099 - val_loss: 1.0461 - val_mse: 1.6562 - val_mape: 92.3021 - val_r_square: -0.3041\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4897 - mse: 0.5669 - mape: 122.0026 - r_square: 0.3591 - val_loss: 1.0418 - val_mse: 1.6239 - val_mape: 93.0221 - val_r_square: -0.2833\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4866 - mse: 0.5786 - mape: 103.0790 - r_square: 0.3479 - val_loss: 1.0407 - val_mse: 1.6061 - val_mape: 93.7391 - val_r_square: -0.2733\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5040 - mse: 0.6042 - mape: 111.5670 - r_square: 0.3192 - val_loss: 1.0367 - val_mse: 1.5800 - val_mape: 94.2742 - val_r_square: -0.2562\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4823 - mse: 0.5506 - mape: 134.8867 - r_square: 0.3781 - val_loss: 1.0364 - val_mse: 1.5672 - val_mape: 95.0113 - val_r_square: -0.2496\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4743 - mse: 0.5398 - mape: 162.8387 - r_square: 0.3913 - val_loss: 1.0323 - val_mse: 1.5444 - val_mape: 95.4441 - val_r_square: -0.2344\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4820 - mse: 0.5666 - mape: 170.7294 - r_square: 0.3601 - val_loss: 1.0241 - val_mse: 1.5108 - val_mape: 95.3539 - val_r_square: -0.2102\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4637 - mse: 0.5484 - mape: 113.9978 - r_square: 0.3846 - val_loss: 1.0137 - val_mse: 1.4721 - val_mape: 95.0610 - val_r_square: -0.1814\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4406 - mse: 0.4972 - mape: 132.3844 - r_square: 0.4410 - val_loss: 1.0055 - val_mse: 1.4373 - val_mape: 95.2733 - val_r_square: -0.1553\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4455 - mse: 0.5044 - mape: 175.4548 - r_square: 0.4341 - val_loss: 1.0028 - val_mse: 1.4215 - val_mape: 95.6714 - val_r_square: -0.1446\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4664 - mse: 0.5170 - mape: 159.4699 - r_square: 0.4208 - val_loss: 0.9924 - val_mse: 1.3913 - val_mape: 94.7386 - val_r_square: -0.1218\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4273 - mse: 0.4636 - mape: 163.6693 - r_square: 0.4784 - val_loss: 0.9794 - val_mse: 1.3545 - val_mape: 93.6155 - val_r_square: -0.0937\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4259 - mse: 0.4581 - mape: 128.4948 - r_square: 0.4881 - val_loss: 0.9697 - val_mse: 1.3222 - val_mape: 93.3898 - val_r_square: -0.0692\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4194 - mse: 0.4627 - mape: 156.5503 - r_square: 0.4799 - val_loss: 0.9569 - val_mse: 1.2795 - val_mape: 93.1993 - val_r_square: -0.0382\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4110 - mse: 0.4455 - mape: 131.4938 - r_square: 0.5012 - val_loss: 0.9459 - val_mse: 1.2451 - val_mape: 92.9547 - val_r_square: -0.0128\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4205 - mse: 0.4524 - mape: 135.6989 - r_square: 0.4919 - val_loss: 0.9331 - val_mse: 1.2085 - val_mape: 92.2789 - val_r_square: 0.0131\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4191 - mse: 0.4442 - mape: 116.6928 - r_square: 0.5030 - val_loss: 0.9197 - val_mse: 1.1740 - val_mape: 91.3772 - val_r_square: 0.0372\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3779 - mse: 0.3767 - mape: 92.5499 - r_square: 0.5806 - val_loss: 0.9069 - val_mse: 1.1435 - val_mape: 90.5588 - val_r_square: 0.0596\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3667 - mse: 0.3535 - mape: 158.4839 - r_square: 0.6052 - val_loss: 0.8935 - val_mse: 1.1088 - val_mape: 90.1455 - val_r_square: 0.0856\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3737 - mse: 0.3765 - mape: 166.1257 - r_square: 0.5797 - val_loss: 0.8833 - val_mse: 1.0860 - val_mape: 89.7472 - val_r_square: 0.1030\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4054 - mse: 0.4395 - mape: 166.0301 - r_square: 0.5105 - val_loss: 0.8733 - val_mse: 1.0681 - val_mape: 89.1586 - val_r_square: 0.1179\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3621 - mse: 0.3607 - mape: 139.6296 - r_square: 0.5983 - val_loss: 0.8615 - val_mse: 1.0502 - val_mape: 87.7147 - val_r_square: 0.1317\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3706 - mse: 0.3621 - mape: 119.9169 - r_square: 0.5969 - val_loss: 0.8478 - val_mse: 1.0225 - val_mape: 86.4766 - val_r_square: 0.1520\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3554 - mse: 0.3523 - mape: 119.5074 - r_square: 0.6050 - val_loss: 0.8356 - val_mse: 0.9962 - val_mape: 85.9324 - val_r_square: 0.1726\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3477 - mse: 0.3293 - mape: 120.3697 - r_square: 0.6343 - val_loss: 0.8224 - val_mse: 0.9783 - val_mape: 84.3138 - val_r_square: 0.1888\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3535 - mse: 0.3221 - mape: 119.7659 - r_square: 0.6420 - val_loss: 0.8087 - val_mse: 0.9578 - val_mape: 82.8280 - val_r_square: 0.2061\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3435 - mse: 0.3342 - mape: 110.8121 - r_square: 0.6290 - val_loss: 0.8000 - val_mse: 0.9432 - val_mape: 82.0786 - val_r_square: 0.2163\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3416 - mse: 0.3332 - mape: 125.2464 - r_square: 0.6292 - val_loss: 0.7829 - val_mse: 0.9119 - val_mape: 80.4545 - val_r_square: 0.2396\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3293 - mse: 0.3024 - mape: 119.4577 - r_square: 0.6647 - val_loss: 0.7650 - val_mse: 0.8802 - val_mape: 79.0404 - val_r_square: 0.2636\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3451 - mse: 0.3269 - mape: 145.8582 - r_square: 0.6373 - val_loss: 0.7514 - val_mse: 0.8583 - val_mape: 78.0886 - val_r_square: 0.2797\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3294 - mse: 0.3092 - mape: 124.3064 - r_square: 0.6589 - val_loss: 0.7494 - val_mse: 0.8574 - val_mape: 78.4006 - val_r_square: 0.2802\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3088 - mse: 0.2655 - mape: 116.1285 - r_square: 0.7049 - val_loss: 0.7529 - val_mse: 0.8620 - val_mape: 79.4787 - val_r_square: 0.2759\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3199 - mse: 0.2758 - mape: 109.5466 - r_square: 0.6957 - val_loss: 0.7565 - val_mse: 0.8681 - val_mape: 80.1243 - val_r_square: 0.2705\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3136 - mse: 0.2638 - mape: 98.4482 - r_square: 0.7075 - val_loss: 0.7584 - val_mse: 0.8707 - val_mape: 80.6454 - val_r_square: 0.2686\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3217 - mse: 0.2847 - mape: 156.4947 - r_square: 0.6852 - val_loss: 0.7530 - val_mse: 0.8643 - val_mape: 80.0112 - val_r_square: 0.2748\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3189 - mse: 0.2949 - mape: 193.5024 - r_square: 0.6718 - val_loss: 0.7463 - val_mse: 0.8567 - val_mape: 79.4850 - val_r_square: 0.2822\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3272 - mse: 0.2933 - mape: 149.0520 - r_square: 0.6756 - val_loss: 0.7323 - val_mse: 0.8415 - val_mape: 77.6237 - val_r_square: 0.2967\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2999 - mse: 0.2656 - mape: 95.3730 - r_square: 0.7038 - val_loss: 0.7189 - val_mse: 0.8250 - val_mape: 75.9872 - val_r_square: 0.3125\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3137 - mse: 0.2861 - mape: 120.1729 - r_square: 0.6795 - val_loss: 0.7106 - val_mse: 0.8157 - val_mape: 75.1216 - val_r_square: 0.3220\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2996 - mse: 0.2749 - mape: 96.9813 - r_square: 0.6960 - val_loss: 0.7110 - val_mse: 0.8148 - val_mape: 75.1078 - val_r_square: 0.3236\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2755 - mse: 0.2298 - mape: 141.4250 - r_square: 0.7457 - val_loss: 0.7063 - val_mse: 0.8081 - val_mape: 74.6801 - val_r_square: 0.3301\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3113 - mse: 0.2984 - mape: 120.9916 - r_square: 0.6686 - val_loss: 0.6939 - val_mse: 0.7881 - val_mape: 73.7340 - val_r_square: 0.3459\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2881 - mse: 0.2479 - mape: 105.0552 - r_square: 0.7259 - val_loss: 0.6898 - val_mse: 0.7795 - val_mape: 73.8146 - val_r_square: 0.3537\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2975 - mse: 0.2333 - mape: 125.2874 - r_square: 0.7432 - val_loss: 0.6932 - val_mse: 0.7842 - val_mape: 74.0675 - val_r_square: 0.3511\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2860 - mse: 0.2223 - mape: 144.3579 - r_square: 0.7534 - val_loss: 0.7011 - val_mse: 0.7973 - val_mape: 74.9539 - val_r_square: 0.3412\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2950 - mse: 0.2789 - mape: 118.3623 - r_square: 0.6910 - val_loss: 0.7019 - val_mse: 0.7979 - val_mape: 74.6236 - val_r_square: 0.3414\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2830 - mse: 0.2298 - mape: 165.9855 - r_square: 0.7447 - val_loss: 0.6947 - val_mse: 0.7865 - val_mape: 73.5066 - val_r_square: 0.3501\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2858 - mse: 0.2484 - mape: 111.9043 - r_square: 0.7257 - val_loss: 0.6915 - val_mse: 0.7792 - val_mape: 73.1034 - val_r_square: 0.3547\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3084 - mse: 0.2469 - mape: 119.5974 - r_square: 0.7253 - val_loss: 0.6905 - val_mse: 0.7783 - val_mape: 73.5588 - val_r_square: 0.3542\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2811 - mse: 0.2387 - mape: 116.3358 - r_square: 0.7353 - val_loss: 0.6957 - val_mse: 0.7846 - val_mape: 74.6133 - val_r_square: 0.3477\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2931 - mse: 0.2336 - mape: 155.8284 - r_square: 0.7407 - val_loss: 0.7041 - val_mse: 0.7958 - val_mape: 75.4242 - val_r_square: 0.3380\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2375 - mse: 0.1949 - mape: 58.5413 - r_square: 0.7862 - val_loss: 0.7055 - val_mse: 0.7988 - val_mape: 75.3349 - val_r_square: 0.3361\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2796 - mse: 0.2209 - mape: 110.0304 - r_square: 0.7547 - val_loss: 0.6992 - val_mse: 0.7909 - val_mape: 74.6069 - val_r_square: 0.3431\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 16)                720       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 901\n",
      "Trainable params: 901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define an RNN model with Dropout\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, n_features)),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(n_labels)  # Predict 5 indices\n",
    "])\n",
    "\n",
    "# Compile\n",
    "rnn_model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\", \"mape\", RSquare()])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train with validation\n",
    "rnn_model.fit(X_train, y_train, epochs=200, batch_size=8, validation_data=(X_val, y_val),\n",
    "              callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Summary\n",
    "rnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011DA1DA89D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000011DA4014AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "[array([0.70361004, 0.68047515, 0.72400961, 0.64392887, 0.63689179]), array([ -1.05026093,  -4.60477475,  -1.20002839, -15.7154569 ,\n",
      "       -14.37387745]), array([0.71218407, 0.92948281, 0.88717301, 0.8204686 , 0.84586961]), array([0.66614026, 0.43188497, 0.45762006, 0.32655183, 0.52341476]), array([ 0.32980692,  0.3549644 ,  0.25480821, -0.40912829, -0.52822707])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, n_features)),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(n_labels)  # Predict 5 indices\n",
    "])\n",
    "def reshape_for_keras(X):\n",
    "    return np.expand_dims(X, axis=1)\n",
    "tscv = TimeSeriesSplit(test_size=5)\n",
    "X = data[12][features]\n",
    "y = data[12][indices_of_interest]\n",
    "r2_tscv = []\n",
    "mape_tscv= []\n",
    "train_sizes = []\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    train_sizes.append(len(train_index))\n",
    "    train_data, test_data, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = reshape_for_keras(train_data)\n",
    "    X_test = reshape_for_keras(test_data)\n",
    "    rnn_model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "    rnn_model.fit(X_train, y_train, epochs=200, batch_size=8, verbose=0, validation_data=(X_test, y_test))\n",
    "    pred = rnn_model.predict(X_test)\n",
    "    r2_tscv.append(r2_score(y_test, pred, multioutput=\"raw_values\")) \n",
    "    mape_tscv.append(mean_absolute_percentage_error(y_test, pred, multioutput=\"raw_values\"))\n",
    "weights = np.array(train_sizes)/np.sum(train_sizes)\n",
    "r2_tscv = np.dot(np.array(r2_tscv).T,weights)\n",
    "mape_tscv = np.dot(np.array(mape_tscv).T,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea777d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29920704, -0.3197702 ,  0.24469555, -2.479619  , -2.23010082])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_tscv = np.dot(r2_tscv, weights)\n",
    "r2_tscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a451b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 3s 100ms/step - loss: 0.7473 - mse: 0.9057 - mape: 146.3605 - r_square: -0.0233 - val_loss: 1.1267 - val_mse: 1.9693 - val_mape: 97.3572 - val_r_square: -0.5427\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7334 - mse: 0.8930 - mape: 126.6799 - r_square: -0.0089 - val_loss: 1.1252 - val_mse: 1.9685 - val_mape: 96.6118 - val_r_square: -0.5421\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7214 - mse: 0.8768 - mape: 132.0839 - r_square: 0.0090 - val_loss: 1.1234 - val_mse: 1.9657 - val_mape: 95.9315 - val_r_square: -0.5398\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7118 - mse: 0.8699 - mape: 124.9203 - r_square: 0.0173 - val_loss: 1.1223 - val_mse: 1.9689 - val_mape: 95.2261 - val_r_square: -0.5422\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7018 - mse: 0.8511 - mape: 125.4212 - r_square: 0.0391 - val_loss: 1.1221 - val_mse: 1.9753 - val_mape: 94.5400 - val_r_square: -0.5475\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6964 - mse: 0.8454 - mape: 134.3658 - r_square: 0.0458 - val_loss: 1.1205 - val_mse: 1.9764 - val_mape: 93.7830 - val_r_square: -0.5490\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6901 - mse: 0.8553 - mape: 124.3154 - r_square: 0.0334 - val_loss: 1.1191 - val_mse: 1.9791 - val_mape: 92.9868 - val_r_square: -0.5512\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6811 - mse: 0.8333 - mape: 121.8310 - r_square: 0.0594 - val_loss: 1.1174 - val_mse: 1.9791 - val_mape: 92.2873 - val_r_square: -0.5511\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6697 - mse: 0.8217 - mape: 118.6709 - r_square: 0.0740 - val_loss: 1.1147 - val_mse: 1.9728 - val_mape: 91.7094 - val_r_square: -0.5461\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6621 - mse: 0.8120 - mape: 108.0379 - r_square: 0.0846 - val_loss: 1.1132 - val_mse: 1.9669 - val_mape: 91.4751 - val_r_square: -0.5416\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6554 - mse: 0.8006 - mape: 117.1171 - r_square: 0.0979 - val_loss: 1.1140 - val_mse: 1.9682 - val_mape: 91.5035 - val_r_square: -0.5427\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6452 - mse: 0.7974 - mape: 107.6493 - r_square: 0.1019 - val_loss: 1.1163 - val_mse: 1.9698 - val_mape: 91.9579 - val_r_square: -0.5437\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6331 - mse: 0.7772 - mape: 96.3823 - r_square: 0.1251 - val_loss: 1.1151 - val_mse: 1.9598 - val_mape: 92.0973 - val_r_square: -0.5358\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6312 - mse: 0.7850 - mape: 96.3684 - r_square: 0.1159 - val_loss: 1.1139 - val_mse: 1.9500 - val_mape: 92.2463 - val_r_square: -0.5281\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6111 - mse: 0.7550 - mape: 100.1623 - r_square: 0.1506 - val_loss: 1.1122 - val_mse: 1.9402 - val_mape: 92.2334 - val_r_square: -0.5204\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6086 - mse: 0.7501 - mape: 101.7436 - r_square: 0.1558 - val_loss: 1.1121 - val_mse: 1.9342 - val_mape: 92.4924 - val_r_square: -0.5155\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5903 - mse: 0.7266 - mape: 98.2918 - r_square: 0.1826 - val_loss: 1.1102 - val_mse: 1.9192 - val_mape: 92.8256 - val_r_square: -0.5031\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5796 - mse: 0.7150 - mape: 96.9384 - r_square: 0.1968 - val_loss: 1.1089 - val_mse: 1.9053 - val_mape: 93.2804 - val_r_square: -0.4917\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5864 - mse: 0.7128 - mape: 103.9591 - r_square: 0.1986 - val_loss: 1.1054 - val_mse: 1.8846 - val_mape: 93.5853 - val_r_square: -0.4747\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5596 - mse: 0.6885 - mape: 91.1838 - r_square: 0.2279 - val_loss: 1.1016 - val_mse: 1.8668 - val_mape: 93.5987 - val_r_square: -0.4606\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5564 - mse: 0.6979 - mape: 88.1279 - r_square: 0.2155 - val_loss: 1.0999 - val_mse: 1.8564 - val_mape: 93.7902 - val_r_square: -0.4526\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5402 - mse: 0.6544 - mape: 98.8226 - r_square: 0.2650 - val_loss: 1.0926 - val_mse: 1.8261 - val_mape: 93.6430 - val_r_square: -0.4289\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5420 - mse: 0.6766 - mape: 101.5367 - r_square: 0.2393 - val_loss: 1.0881 - val_mse: 1.8073 - val_mape: 93.5351 - val_r_square: -0.4151\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5109 - mse: 0.6076 - mape: 101.2738 - r_square: 0.3183 - val_loss: 1.0810 - val_mse: 1.7751 - val_mape: 93.5890 - val_r_square: -0.3908\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5096 - mse: 0.6088 - mape: 104.3261 - r_square: 0.3179 - val_loss: 1.0707 - val_mse: 1.7359 - val_mape: 93.2378 - val_r_square: -0.3610\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5047 - mse: 0.6035 - mape: 99.3393 - r_square: 0.3233 - val_loss: 1.0604 - val_mse: 1.7014 - val_mape: 92.5522 - val_r_square: -0.3352\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4812 - mse: 0.5621 - mape: 114.8041 - r_square: 0.3709 - val_loss: 1.0460 - val_mse: 1.6539 - val_mape: 91.8010 - val_r_square: -0.2985\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4768 - mse: 0.5587 - mape: 108.4360 - r_square: 0.3738 - val_loss: 1.0368 - val_mse: 1.6262 - val_mape: 91.1700 - val_r_square: -0.2774\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4498 - mse: 0.5094 - mape: 119.3242 - r_square: 0.4307 - val_loss: 1.0214 - val_mse: 1.5797 - val_mape: 90.2676 - val_r_square: -0.2416\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4327 - mse: 0.4793 - mape: 100.3416 - r_square: 0.4639 - val_loss: 1.0088 - val_mse: 1.5405 - val_mape: 89.7636 - val_r_square: -0.2123\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4437 - mse: 0.5022 - mape: 116.4122 - r_square: 0.4376 - val_loss: 0.9962 - val_mse: 1.4998 - val_mape: 89.3329 - val_r_square: -0.1828\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4322 - mse: 0.4812 - mape: 104.3479 - r_square: 0.4613 - val_loss: 0.9837 - val_mse: 1.4612 - val_mape: 88.6565 - val_r_square: -0.1551\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4282 - mse: 0.4561 - mape: 111.7190 - r_square: 0.4892 - val_loss: 0.9681 - val_mse: 1.4160 - val_mape: 87.6416 - val_r_square: -0.1224\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4170 - mse: 0.4544 - mape: 110.9466 - r_square: 0.4899 - val_loss: 0.9545 - val_mse: 1.3781 - val_mape: 86.8628 - val_r_square: -0.0951\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3849 - mse: 0.3730 - mape: 111.7046 - r_square: 0.5846 - val_loss: 0.9518 - val_mse: 1.3716 - val_mape: 86.5688 - val_r_square: -0.0915\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3956 - mse: 0.4173 - mape: 121.6837 - r_square: 0.5339 - val_loss: 0.9462 - val_mse: 1.3565 - val_mape: 86.0166 - val_r_square: -0.0814\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3672 - mse: 0.3535 - mape: 102.9610 - r_square: 0.6056 - val_loss: 0.9364 - val_mse: 1.3310 - val_mape: 85.2803 - val_r_square: -0.0634\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3735 - mse: 0.3777 - mape: 118.9805 - r_square: 0.5754 - val_loss: 0.9225 - val_mse: 1.3001 - val_mape: 84.0211 - val_r_square: -0.0413\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3518 - mse: 0.3375 - mape: 119.0537 - r_square: 0.6239 - val_loss: 0.9101 - val_mse: 1.2719 - val_mape: 83.0622 - val_r_square: -0.0205\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3319 - mse: 0.3161 - mape: 108.1999 - r_square: 0.6480 - val_loss: 0.8970 - val_mse: 1.2411 - val_mape: 81.9778 - val_r_square: 0.0015\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3372 - mse: 0.3201 - mape: 114.8148 - r_square: 0.6400 - val_loss: 0.8856 - val_mse: 1.2178 - val_mape: 80.9988 - val_r_square: 0.0182\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3242 - mse: 0.2886 - mape: 116.8515 - r_square: 0.6772 - val_loss: 0.8772 - val_mse: 1.1980 - val_mape: 80.5919 - val_r_square: 0.0321\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3235 - mse: 0.3125 - mape: 122.7414 - r_square: 0.6497 - val_loss: 0.8711 - val_mse: 1.1864 - val_mape: 79.8745 - val_r_square: 0.0408\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2923 - mse: 0.2492 - mape: 114.6967 - r_square: 0.7231 - val_loss: 0.8641 - val_mse: 1.1698 - val_mape: 79.1664 - val_r_square: 0.0528\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3248 - mse: 0.3097 - mape: 137.1257 - r_square: 0.6538 - val_loss: 0.8613 - val_mse: 1.1603 - val_mape: 79.1772 - val_r_square: 0.0591\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2899 - mse: 0.2469 - mape: 120.6929 - r_square: 0.7243 - val_loss: 0.8569 - val_mse: 1.1496 - val_mape: 79.0662 - val_r_square: 0.0669\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2865 - mse: 0.2438 - mape: 129.7545 - r_square: 0.7279 - val_loss: 0.8486 - val_mse: 1.1299 - val_mape: 78.3506 - val_r_square: 0.0817\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2741 - mse: 0.2383 - mape: 113.1329 - r_square: 0.7363 - val_loss: 0.8413 - val_mse: 1.1129 - val_mape: 77.6916 - val_r_square: 0.0934\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2793 - mse: 0.2273 - mape: 123.6332 - r_square: 0.7479 - val_loss: 0.8357 - val_mse: 1.1001 - val_mape: 77.2845 - val_r_square: 0.1026\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2496 - mse: 0.1961 - mape: 123.1283 - r_square: 0.7829 - val_loss: 0.8315 - val_mse: 1.0888 - val_mape: 77.1986 - val_r_square: 0.1103\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2534 - mse: 0.1965 - mape: 122.1710 - r_square: 0.7823 - val_loss: 0.8250 - val_mse: 1.0742 - val_mape: 76.6572 - val_r_square: 0.1205\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2566 - mse: 0.2000 - mape: 121.8176 - r_square: 0.7787 - val_loss: 0.8203 - val_mse: 1.0655 - val_mape: 76.2418 - val_r_square: 0.1259\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2389 - mse: 0.1943 - mape: 109.7642 - r_square: 0.7836 - val_loss: 0.8151 - val_mse: 1.0521 - val_mape: 76.0054 - val_r_square: 0.1354\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2276 - mse: 0.1771 - mape: 112.3782 - r_square: 0.8045 - val_loss: 0.8126 - val_mse: 1.0416 - val_mape: 76.2899 - val_r_square: 0.1429\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2208 - mse: 0.1611 - mape: 97.5434 - r_square: 0.8212 - val_loss: 0.8072 - val_mse: 1.0223 - val_mape: 76.4569 - val_r_square: 0.1576\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2274 - mse: 0.1642 - mape: 110.0996 - r_square: 0.8177 - val_loss: 0.8043 - val_mse: 1.0100 - val_mape: 76.9071 - val_r_square: 0.1673\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2415 - mse: 0.2153 - mape: 115.7150 - r_square: 0.7625 - val_loss: 0.8061 - val_mse: 1.0136 - val_mape: 77.3411 - val_r_square: 0.1651\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2462 - mse: 0.2075 - mape: 108.7655 - r_square: 0.7712 - val_loss: 0.8039 - val_mse: 1.0105 - val_mape: 77.1222 - val_r_square: 0.1667\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2019 - mse: 0.1306 - mape: 109.2770 - r_square: 0.8566 - val_loss: 0.8033 - val_mse: 1.0107 - val_mape: 77.0799 - val_r_square: 0.1656\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2004 - mse: 0.1322 - mape: 105.4305 - r_square: 0.8544 - val_loss: 0.7950 - val_mse: 0.9913 - val_mape: 76.4639 - val_r_square: 0.1794\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2080 - mse: 0.1388 - mape: 99.8099 - r_square: 0.8469 - val_loss: 0.7874 - val_mse: 0.9686 - val_mape: 76.4116 - val_r_square: 0.1955\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2237 - mse: 0.1888 - mape: 115.9601 - r_square: 0.7933 - val_loss: 0.7902 - val_mse: 0.9686 - val_mape: 77.5932 - val_r_square: 0.1949\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1840 - mse: 0.1175 - mape: 99.8439 - r_square: 0.8712 - val_loss: 0.7969 - val_mse: 0.9820 - val_mape: 78.8425 - val_r_square: 0.1837\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2051 - mse: 0.1454 - mape: 112.2686 - r_square: 0.8408 - val_loss: 0.7913 - val_mse: 0.9791 - val_mape: 77.5417 - val_r_square: 0.1858\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1888 - mse: 0.1247 - mape: 103.6373 - r_square: 0.8642 - val_loss: 0.7901 - val_mse: 0.9839 - val_mape: 76.7416 - val_r_square: 0.1812\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1760 - mse: 0.1210 - mape: 108.2305 - r_square: 0.8683 - val_loss: 0.7880 - val_mse: 0.9819 - val_mape: 76.3045 - val_r_square: 0.1832\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2007 - mse: 0.1544 - mape: 101.6650 - r_square: 0.8294 - val_loss: 0.7854 - val_mse: 0.9723 - val_mape: 76.3624 - val_r_square: 0.1906\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1756 - mse: 0.1110 - mape: 96.4630 - r_square: 0.8781 - val_loss: 0.7880 - val_mse: 0.9745 - val_mape: 76.8801 - val_r_square: 0.1889\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1804 - mse: 0.1231 - mape: 108.1614 - r_square: 0.8671 - val_loss: 0.7841 - val_mse: 0.9670 - val_mape: 76.4192 - val_r_square: 0.1951\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1625 - mse: 0.0987 - mape: 91.1811 - r_square: 0.8926 - val_loss: 0.7833 - val_mse: 0.9685 - val_mape: 76.0549 - val_r_square: 0.1937\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1805 - mse: 0.1126 - mape: 100.0777 - r_square: 0.8771 - val_loss: 0.7863 - val_mse: 0.9818 - val_mape: 75.8098 - val_r_square: 0.1837\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1805 - mse: 0.1383 - mape: 85.9133 - r_square: 0.8469 - val_loss: 0.7826 - val_mse: 0.9751 - val_mape: 75.4402 - val_r_square: 0.1893\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1911 - mse: 0.1300 - mape: 93.7960 - r_square: 0.8576 - val_loss: 0.7793 - val_mse: 0.9672 - val_mape: 75.3013 - val_r_square: 0.1951\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2048 - mse: 0.1726 - mape: 96.3504 - r_square: 0.8116 - val_loss: 0.7758 - val_mse: 0.9553 - val_mape: 75.4471 - val_r_square: 0.2045\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1610 - mse: 0.0982 - mape: 88.7092 - r_square: 0.8921 - val_loss: 0.7760 - val_mse: 0.9540 - val_mape: 75.7512 - val_r_square: 0.2053\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1729 - mse: 0.1062 - mape: 92.4547 - r_square: 0.8840 - val_loss: 0.7839 - val_mse: 0.9674 - val_mape: 77.0554 - val_r_square: 0.1943\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1591 - mse: 0.0892 - mape: 83.8434 - r_square: 0.9025 - val_loss: 0.7871 - val_mse: 0.9730 - val_mape: 77.6344 - val_r_square: 0.1900\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1702 - mse: 0.1101 - mape: 100.6366 - r_square: 0.8803 - val_loss: 0.7833 - val_mse: 0.9669 - val_mape: 77.2309 - val_r_square: 0.1936\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1568 - mse: 0.1099 - mape: 86.7515 - r_square: 0.8823 - val_loss: 0.7734 - val_mse: 0.9469 - val_mape: 76.1729 - val_r_square: 0.2070\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1666 - mse: 0.1093 - mape: 83.9219 - r_square: 0.8811 - val_loss: 0.7685 - val_mse: 0.9377 - val_mape: 75.5452 - val_r_square: 0.2122\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1518 - mse: 0.0828 - mape: 97.5018 - r_square: 0.9100 - val_loss: 0.7735 - val_mse: 0.9511 - val_mape: 76.2171 - val_r_square: 0.2004\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1754 - mse: 0.1182 - mape: 92.1277 - r_square: 0.8709 - val_loss: 0.7795 - val_mse: 0.9658 - val_mape: 76.5836 - val_r_square: 0.1895\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1588 - mse: 0.1186 - mape: 82.9165 - r_square: 0.8722 - val_loss: 0.7831 - val_mse: 0.9738 - val_mape: 76.6788 - val_r_square: 0.1841\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1563 - mse: 0.0968 - mape: 93.5680 - r_square: 0.8956 - val_loss: 0.7811 - val_mse: 0.9705 - val_mape: 76.3179 - val_r_square: 0.1875\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1697 - mse: 0.1096 - mape: 86.8702 - r_square: 0.8811 - val_loss: 0.7771 - val_mse: 0.9638 - val_mape: 75.8652 - val_r_square: 0.1935\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1560 - mse: 0.0963 - mape: 87.3883 - r_square: 0.8924 - val_loss: 0.7785 - val_mse: 0.9657 - val_mape: 76.3277 - val_r_square: 0.1927\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1416 - mse: 0.0803 - mape: 78.8429 - r_square: 0.9123 - val_loss: 0.7857 - val_mse: 0.9782 - val_mape: 77.6293 - val_r_square: 0.1836\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1610 - mse: 0.1143 - mape: 81.0525 - r_square: 0.8756 - val_loss: 0.7962 - val_mse: 1.0014 - val_mape: 78.7036 - val_r_square: 0.1663\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1393 - mse: 0.0854 - mape: 81.2510 - r_square: 0.9082 - val_loss: 0.7960 - val_mse: 1.0049 - val_mape: 78.2399 - val_r_square: 0.1647\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1389 - mse: 0.0772 - mape: 104.6570 - r_square: 0.9165 - val_loss: 0.7944 - val_mse: 1.0066 - val_mape: 77.4357 - val_r_square: 0.1649\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 16)                2880      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,061\n",
      "Trainable params: 3,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define an LSTM model with Dropout\n",
    "lstm_model = Sequential([\n",
    "    LSTM(16, activation=\"tanh\", input_shape=(1, n_features)),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(n_labels)  # Predict 5 indices\n",
    "])\n",
    "\n",
    "# Compile\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\", \"mape\", RSquare()])\n",
    "\n",
    "# Train with validation\n",
    "lstm_model.fit(X_train, y_train, epochs=200, batch_size=8, validation_data=(X_val, y_val),\n",
    "               callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Summary\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f0bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=2.0460103>,\n",
       " 'mae': <tf.Tensor: shape=(), dtype=float32, numpy=1.1040316>,\n",
       " 'mape': <tf.Tensor: shape=(), dtype=float32, numpy=84.136955>,\n",
       " 'r_square': <tf.Tensor: shape=(), dtype=float32, numpy=-0.59095705>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.get_metrics_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a50d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
