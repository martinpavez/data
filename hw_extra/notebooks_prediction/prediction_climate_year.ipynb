{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERA Monthly Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "SEED = 42\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, GRU, Conv1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\Desktop\\data\\hw_extra\n"
     ]
    }
   ],
   "source": [
    "# Add the folder to the Python path\n",
    "\n",
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())\n",
    "\n",
    "FIRST_YEAR= 1972\n",
    "FREQUENCY= \"monthly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.abspath(\"functions/\") #INPUT_PATH)#'path_to_your_folder')  # Replace with the actual folder path\n",
    "sys.path.insert(0, folder_path)\n",
    "\n",
    "from Predictions import (\n",
    "    PredictionExperiment,\n",
    "    PredictionModel,\n",
    "    SERA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = [\"HWN\", \"HWF\", \"HWD\", \"HWM\", \"HWA\"]\n",
    "bounds = (-1.1692892810242344, -0.30647585455315646, 4.561547586528888, 6.499969486244418)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>season</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_6.parquet</td>\n",
       "      <td>6</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_7.parquet</td>\n",
       "      <td>7</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_6.parquet</td>\n",
       "      <td>6</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_7.parquet</td>\n",
       "      <td>7</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                       filename  season   \n",
       "0   6e47cb06   predictor_6e47cb06_1.parquet       1  \\\n",
       "1   6e47cb06   predictor_6e47cb06_2.parquet       2   \n",
       "2   6e47cb06   predictor_6e47cb06_3.parquet       3   \n",
       "3   6e47cb06   predictor_6e47cb06_4.parquet       4   \n",
       "4   6e47cb06   predictor_6e47cb06_5.parquet       5   \n",
       "5   6e47cb06   predictor_6e47cb06_6.parquet       6   \n",
       "6   6e47cb06   predictor_6e47cb06_7.parquet       7   \n",
       "7   6e47cb06   predictor_6e47cb06_8.parquet       8   \n",
       "8   6e47cb06   predictor_6e47cb06_9.parquet       9   \n",
       "9   6e47cb06  predictor_6e47cb06_10.parquet      10   \n",
       "10  6e47cb06  predictor_6e47cb06_11.parquet      11   \n",
       "11  6e47cb06  predictor_6e47cb06_12.parquet      12   \n",
       "12  5cb3fa02   predictor_5cb3fa02_1.parquet       1   \n",
       "13  5cb3fa02   predictor_5cb3fa02_2.parquet       2   \n",
       "14  5cb3fa02   predictor_5cb3fa02_3.parquet       3   \n",
       "15  5cb3fa02   predictor_5cb3fa02_4.parquet       4   \n",
       "16  5cb3fa02   predictor_5cb3fa02_5.parquet       5   \n",
       "17  5cb3fa02   predictor_5cb3fa02_6.parquet       6   \n",
       "18  5cb3fa02   predictor_5cb3fa02_7.parquet       7   \n",
       "19  5cb3fa02   predictor_5cb3fa02_8.parquet       8   \n",
       "20  5cb3fa02   predictor_5cb3fa02_9.parquet       9   \n",
       "21  5cb3fa02  predictor_5cb3fa02_10.parquet      10   \n",
       "22  5cb3fa02  predictor_5cb3fa02_11.parquet      11   \n",
       "23  5cb3fa02  predictor_5cb3fa02_12.parquet      12   \n",
       "\n",
       "                                              indices  \n",
       "0   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "1   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "2   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "3   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "4   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "5   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "6   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "7   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "8   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "9   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "10  df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "11  df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "12  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "13  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "14  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "15  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "16  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "17  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "18  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "19  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "20  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "21  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "22  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "23  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region=\"california\"\n",
    "metadata_path = f\"data/climate_features/{region}/metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.reset_index(inplace=True, drop=True)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(f\"data/sera_results/{region}_results/results.csv\")\n",
    "ids_results = results[\"id_data\"].unique()\n",
    "id_experiments = metadata[\"id\"].unique()\n",
    "ids_to_execute = [id for id in id_experiments if id not in ids_results]\n",
    "print(len(ids_to_execute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 6e47cb06 iter 1\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 56ms/step - loss: 17.2137 - val_loss: 23.4238\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.6438 - val_loss: 20.5593\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.7915 - val_loss: 18.9949\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1822 - val_loss: 18.0989\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.6377 - val_loss: 17.6344\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.6546 - val_loss: 17.5739\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.3493 - val_loss: 17.5211\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1042 - val_loss: 17.5799\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1391 - val_loss: 17.5156\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6745 - val_loss: 17.4095\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3677 - val_loss: 17.3472\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4926 - val_loss: 17.2137\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3995 - val_loss: 17.4043\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5704 - val_loss: 17.3200\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9397 - val_loss: 17.3619\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2957 - val_loss: 17.3206\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9157 - val_loss: 17.2515\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9910 - val_loss: 17.3659\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6775 - val_loss: 17.2858\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7729 - val_loss: 17.4366\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2264 - val_loss: 17.3090\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7514 - val_loss: 17.2095\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5786 - val_loss: 17.1757\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2480 - val_loss: 17.1989\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5481 - val_loss: 17.3654\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4178 - val_loss: 17.2865\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4791 - val_loss: 17.1533\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9719 - val_loss: 17.3343\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9246 - val_loss: 17.2761\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0640 - val_loss: 17.5081\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3321 - val_loss: 17.5168\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9109 - val_loss: 17.4499\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6337 - val_loss: 17.5297\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6126 - val_loss: 17.5503\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4137 - val_loss: 17.3762\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.7353 - val_loss: 17.7033\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6365 - val_loss: 17.6406\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.0031 - val_loss: 17.7201\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3851 - val_loss: 17.7320\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2856 - val_loss: 17.8770\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5841 - val_loss: 18.1336\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2596 - val_loss: 17.9637\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1445 - val_loss: 18.0713\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3912 - val_loss: 17.9080\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6590 - val_loss: 17.9289\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9706 - val_loss: 18.3174\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4040 - val_loss: 18.4718\n",
      "18/18 [==============================] - 0s 986us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 880us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 972us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 757us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 752us/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 54ms/step - loss: 16.9352 - val_loss: 20.8687\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.6593 - val_loss: 18.8844\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.4831 - val_loss: 17.3099\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.7199 - val_loss: 16.4584\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.3440 - val_loss: 16.0344\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9831 - val_loss: 15.9131\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6785 - val_loss: 16.2576\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5198 - val_loss: 16.3665\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2869 - val_loss: 16.7202\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0869 - val_loss: 16.7777\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0429 - val_loss: 16.9188\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8071 - val_loss: 16.7953\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6685 - val_loss: 17.2105\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4990 - val_loss: 17.3001\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4139 - val_loss: 17.4968\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4613 - val_loss: 17.5649\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1163 - val_loss: 17.9054\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9122 - val_loss: 17.7860\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9417 - val_loss: 17.7175\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.0414 - val_loss: 17.8070\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8181 - val_loss: 17.9854\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9407 - val_loss: 17.9268\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6984 - val_loss: 18.0825\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6633 - val_loss: 17.9911\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1970 - val_loss: 18.2921\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1581 - val_loss: 18.2339\n",
      "18/18 [==============================] - 0s 861us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 723us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 952us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 751us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 760us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 784us/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 44ms/step - loss: 17.9122 - val_loss: 20.9898\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.8060 - val_loss: 19.5229\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.9491 - val_loss: 18.6584\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.3384 - val_loss: 18.0714\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.9222 - val_loss: 17.6998\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2903 - val_loss: 17.4647\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.4875 - val_loss: 17.2780\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.5285 - val_loss: 17.3312\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2228 - val_loss: 17.2851\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9707 - val_loss: 17.3050\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6248 - val_loss: 17.3479\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.0368 - val_loss: 17.3205\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5077 - val_loss: 17.5041\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3088 - val_loss: 17.6403\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2580 - val_loss: 17.7681\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4715 - val_loss: 17.8320\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2538 - val_loss: 17.8648\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0453 - val_loss: 17.9963\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5812 - val_loss: 18.0107\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4159 - val_loss: 18.0897\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9492 - val_loss: 18.2564\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1098 - val_loss: 18.4026\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6043 - val_loss: 18.4734\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3084 - val_loss: 18.2788\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7940 - val_loss: 18.4255\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7759 - val_loss: 18.4556\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5967 - val_loss: 18.3715\n",
      "18/18 [==============================] - 0s 943us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 622us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 810us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 549us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 793us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 769us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 705us/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 45ms/step - loss: 20.6863 - val_loss: 17.9759\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.9294 - val_loss: 16.0786\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.2376 - val_loss: 15.1929\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 15.2650 - val_loss: 14.8311\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.4322 - val_loss: 14.5811\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.2706 - val_loss: 14.6369\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.6118 - val_loss: 14.8783\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 13.1021 - val_loss: 14.9227\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2402 - val_loss: 15.1499\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.8614 - val_loss: 15.3187\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 12.7124 - val_loss: 15.2657\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.8534 - val_loss: 15.2358\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3289 - val_loss: 15.4672\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 12.1849 - val_loss: 15.4647\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0234 - val_loss: 15.5714\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0074 - val_loss: 15.5091\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9424 - val_loss: 15.7468\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5696 - val_loss: 15.7652\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 11.7897 - val_loss: 15.6877\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9126 - val_loss: 15.8916\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9813 - val_loss: 15.8173\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 11.8965 - val_loss: 15.8050\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7506 - val_loss: 15.8101\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7721 - val_loss: 15.8993\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7318 - val_loss: 15.9197\n",
      "18/18 [==============================] - 0s 680us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 709us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 716us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 909us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 348us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 710us/step\n",
      "Executing 5cb3fa02 iter 2\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 47ms/step - loss: 19.9876 - val_loss: 22.8760\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18.1042 - val_loss: 21.8129\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.9049 - val_loss: 20.6623\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.0126 - val_loss: 19.3515\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.9530 - val_loss: 17.9355\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.1485 - val_loss: 16.3396\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1429 - val_loss: 14.9870\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4480 - val_loss: 14.0548\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9188 - val_loss: 13.3242\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2401 - val_loss: 12.7876\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9161 - val_loss: 12.3048\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6462 - val_loss: 11.8714\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3275 - val_loss: 11.8788\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2797 - val_loss: 11.7188\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0055 - val_loss: 11.6870\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9225 - val_loss: 11.6380\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7905 - val_loss: 11.5994\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6110 - val_loss: 11.5697\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5124 - val_loss: 11.4224\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4939 - val_loss: 11.3197\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4304 - val_loss: 11.1309\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2478 - val_loss: 11.2299\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0285 - val_loss: 11.1400\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8912 - val_loss: 10.9433\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4317 - val_loss: 10.9317\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4548 - val_loss: 10.8408\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8577 - val_loss: 10.9297\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4735 - val_loss: 10.9082\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5642 - val_loss: 10.9456\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.8700 - val_loss: 10.9766\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.2375 - val_loss: 10.8675\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1767 - val_loss: 10.7375\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6927 - val_loss: 10.8501\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9658 - val_loss: 10.7889\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9820 - val_loss: 10.7201\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0314 - val_loss: 10.9359\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1191 - val_loss: 11.0532\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7298 - val_loss: 11.2669\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5552 - val_loss: 11.0239\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7670 - val_loss: 10.7304\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6653 - val_loss: 10.9206\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7647 - val_loss: 10.7256\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5734 - val_loss: 10.8937\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5435 - val_loss: 11.1389\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5377 - val_loss: 10.9939\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1986 - val_loss: 10.7672\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3930 - val_loss: 11.2211\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3172 - val_loss: 10.9568\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0805 - val_loss: 11.2808\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.4472 - val_loss: 11.3380\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1353 - val_loss: 11.3832\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.8599 - val_loss: 11.3196\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3601 - val_loss: 11.3094\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1049 - val_loss: 11.4258\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1383 - val_loss: 11.4662\n",
      "18/18 [==============================] - 0s 847us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 724us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 809us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 766us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 487us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 722us/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 51ms/step - loss: 17.2299 - val_loss: 21.3918\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.0406 - val_loss: 19.5379\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.6094 - val_loss: 17.4383\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2102 - val_loss: 15.6668\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0721 - val_loss: 14.2968\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4545 - val_loss: 13.4435\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8870 - val_loss: 13.0624\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4768 - val_loss: 12.8307\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4626 - val_loss: 12.6584\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0964 - val_loss: 12.5309\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6976 - val_loss: 12.3334\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6407 - val_loss: 12.1056\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3099 - val_loss: 12.2109\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1412 - val_loss: 12.0698\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8888 - val_loss: 12.0605\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1108 - val_loss: 11.9080\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4578 - val_loss: 11.8655\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4206 - val_loss: 11.9304\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1235 - val_loss: 11.8651\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.8792 - val_loss: 11.8916\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1838 - val_loss: 11.5902\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7955 - val_loss: 11.6229\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7953 - val_loss: 11.6728\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3904 - val_loss: 11.6038\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3261 - val_loss: 11.7077\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3509 - val_loss: 11.6666\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3924 - val_loss: 11.7406\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1871 - val_loss: 11.7126\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0996 - val_loss: 11.7482\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.5028 - val_loss: 11.9305\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.7846 - val_loss: 11.7688\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.7648 - val_loss: 11.8008\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.6879 - val_loss: 11.5325\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.3224 - val_loss: 11.8688\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.5190 - val_loss: 11.2486\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.5621 - val_loss: 11.7852\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.4941 - val_loss: 12.0230\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.2795 - val_loss: 11.8955\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1521 - val_loss: 11.8962\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6677 - val_loss: 11.5547\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1693 - val_loss: 12.0162\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7192 - val_loss: 12.0106\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9447 - val_loss: 11.7020\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7748 - val_loss: 12.0432\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1834 - val_loss: 11.7916\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6483 - val_loss: 12.0528\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 5.6990 - val_loss: 12.0068\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7532 - val_loss: 12.0506\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4267 - val_loss: 12.3877\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.3265 - val_loss: 12.2953\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.3137 - val_loss: 12.4887\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4299 - val_loss: 12.1002\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.2549 - val_loss: 12.2153\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6362 - val_loss: 12.3399\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.5023 - val_loss: 12.1829\n",
      "18/18 [==============================] - 0s 914us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 803us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "19/19 [==============================] - 0s 873us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 806us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 825us/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 46ms/step - loss: 20.5440 - val_loss: 24.0787\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.8903 - val_loss: 21.1610\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.2214 - val_loss: 18.8905\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.8954 - val_loss: 17.2560\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.7840 - val_loss: 16.0759\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2059 - val_loss: 15.1859\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5085 - val_loss: 14.6985\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4233 - val_loss: 14.3076\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7791 - val_loss: 14.1288\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6227 - val_loss: 13.9894\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2941 - val_loss: 13.7497\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4184 - val_loss: 13.5490\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5631 - val_loss: 13.7870\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4736 - val_loss: 13.6619\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3765 - val_loss: 13.7115\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2513 - val_loss: 13.4464\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8835 - val_loss: 13.7454\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1048 - val_loss: 13.8596\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8106 - val_loss: 13.5143\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1565 - val_loss: 13.6700\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5338 - val_loss: 13.2500\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3013 - val_loss: 13.5412\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3014 - val_loss: 13.4948\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9867 - val_loss: 13.3188\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2203 - val_loss: 13.6375\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8623 - val_loss: 13.0726\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4823 - val_loss: 13.1166\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7056 - val_loss: 13.0532\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0864 - val_loss: 12.8263\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9271 - val_loss: 13.0197\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4057 - val_loss: 12.7466\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0352 - val_loss: 12.4902\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.8760 - val_loss: 12.5428\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6349 - val_loss: 12.3868\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9426 - val_loss: 11.9805\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.2535 - val_loss: 12.9745\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5301 - val_loss: 13.0440\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.2170 - val_loss: 12.6805\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3483 - val_loss: 12.2485\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.9276 - val_loss: 12.1663\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0255 - val_loss: 12.4466\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0510 - val_loss: 12.3379\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7068 - val_loss: 12.4728\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7538 - val_loss: 12.3713\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7634 - val_loss: 11.9050\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.5392 - val_loss: 11.9240\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6288 - val_loss: 12.1622\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0178 - val_loss: 11.4189\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7258 - val_loss: 12.0106\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.2897 - val_loss: 11.7889\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3306 - val_loss: 12.5004\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1859 - val_loss: 12.3504\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1356 - val_loss: 12.6889\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1035 - val_loss: 12.3183\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.4242 - val_loss: 12.6674\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6434 - val_loss: 12.2770\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.4702 - val_loss: 12.9761\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.4340 - val_loss: 11.9978\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9192 - val_loss: 12.2160\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1910 - val_loss: 12.2853\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.0140 - val_loss: 12.7155\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3612 - val_loss: 11.8167\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1169 - val_loss: 12.2406\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3488 - val_loss: 13.0395\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.0351 - val_loss: 12.0808\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6799 - val_loss: 12.4918\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9689 - val_loss: 12.5957\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9174 - val_loss: 12.6162\n",
      "18/18 [==============================] - 0s 846us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 893us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 829us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 856us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 828us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 761us/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 47ms/step - loss: 20.3441 - val_loss: 22.0882\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.7644 - val_loss: 20.0158\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.2787 - val_loss: 17.7343\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.1968 - val_loss: 16.4010\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.8654 - val_loss: 14.8044\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7777 - val_loss: 14.0132\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6649 - val_loss: 13.7435\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4285 - val_loss: 13.6799\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6020 - val_loss: 13.6063\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3348 - val_loss: 13.5600\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6562 - val_loss: 13.3326\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9894 - val_loss: 13.0825\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.7095 - val_loss: 13.2142\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9934 - val_loss: 13.2426\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7676 - val_loss: 13.2222\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0321 - val_loss: 13.3291\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8140 - val_loss: 13.3544\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6792 - val_loss: 13.4431\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9242 - val_loss: 13.2551\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7061 - val_loss: 13.2894\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0230 - val_loss: 13.2083\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0165 - val_loss: 13.3596\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8935 - val_loss: 13.1235\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5673 - val_loss: 13.1716\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.6856 - val_loss: 13.1856\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4277 - val_loss: 13.1094\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7531 - val_loss: 12.9713\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9679 - val_loss: 13.0541\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9242 - val_loss: 13.0841\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5883 - val_loss: 13.1359\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9573 - val_loss: 12.9561\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.8467 - val_loss: 13.1509\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9123 - val_loss: 12.9659\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9043 - val_loss: 13.0524\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.5698 - val_loss: 13.1304\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6768 - val_loss: 13.0198\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.2180 - val_loss: 13.0841\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1302 - val_loss: 12.9224\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.4523 - val_loss: 12.5930\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1242 - val_loss: 12.5254\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.5308 - val_loss: 12.5620\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.8082 - val_loss: 12.4954\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.1846 - val_loss: 12.4932\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6337 - val_loss: 12.6028\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.9819 - val_loss: 12.5641\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6291 - val_loss: 12.3623\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.8515 - val_loss: 12.4691\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.8080 - val_loss: 12.4514\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.5771 - val_loss: 12.5496\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3140 - val_loss: 12.3863\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7051 - val_loss: 12.3962\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6809 - val_loss: 12.5914\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1778 - val_loss: 12.4389\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.9335 - val_loss: 12.3481\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.7924 - val_loss: 12.1074\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3789 - val_loss: 12.3461\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.6078 - val_loss: 11.9961\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1903 - val_loss: 12.0669\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9295 - val_loss: 12.1231\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1360 - val_loss: 12.0868\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3328 - val_loss: 12.0631\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.8899 - val_loss: 11.8365\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.8456 - val_loss: 11.8924\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.8138 - val_loss: 11.8581\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7572 - val_loss: 11.8485\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.9527 - val_loss: 12.0008\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.3004 - val_loss: 11.8334\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1157 - val_loss: 12.0619\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6988 - val_loss: 11.7861\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7225 - val_loss: 11.9472\n",
      "Epoch 71/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7784 - val_loss: 12.3000\n",
      "Epoch 72/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7180 - val_loss: 11.5918\n",
      "Epoch 73/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.8318 - val_loss: 11.9254\n",
      "Epoch 74/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4302 - val_loss: 11.8202\n",
      "Epoch 75/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.8680 - val_loss: 11.8794\n",
      "Epoch 76/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.2498 - val_loss: 11.5647\n",
      "Epoch 77/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.2527 - val_loss: 11.8931\n",
      "Epoch 78/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.5185 - val_loss: 12.1368\n",
      "Epoch 79/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4652 - val_loss: 11.9406\n",
      "Epoch 80/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.5667 - val_loss: 12.1398\n",
      "Epoch 81/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.3826 - val_loss: 12.6359\n",
      "Epoch 82/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4548 - val_loss: 11.9248\n",
      "Epoch 83/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.8100 - val_loss: 12.5220\n",
      "Epoch 84/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.0523 - val_loss: 12.3508\n",
      "Epoch 85/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.1010 - val_loss: 12.5270\n",
      "Epoch 86/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.5250 - val_loss: 12.3408\n",
      "Epoch 87/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.6797 - val_loss: 12.2479\n",
      "Epoch 88/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.4937 - val_loss: 12.1478\n",
      "Epoch 89/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.2643 - val_loss: 12.5407\n",
      "Epoch 90/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.7000 - val_loss: 12.3967\n",
      "Epoch 91/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.3701 - val_loss: 12.3356\n",
      "Epoch 92/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 5.3217 - val_loss: 12.2019\n",
      "Epoch 93/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 4.9987 - val_loss: 11.9664\n",
      "Epoch 94/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 5.4572 - val_loss: 12.0954\n",
      "Epoch 95/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.0677 - val_loss: 12.5628\n",
      "Epoch 96/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 5.5742 - val_loss: 12.3325\n",
      "18/18 [==============================] - 0s 706us/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 588us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 722us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 729us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 704us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 773us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 496us/step\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for id in id_experiments:\n",
    "    k+=1\n",
    "    print(\"Executing\",id, \"iter\", k)\n",
    "    data = {1: pd.read_parquet(f\"data/climate_features/{region}/predictor_{id}_year.parquet\")}\n",
    "    rnn16_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    lstm16_model = Sequential([\n",
    "    LSTM(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    cnn_rnn_model = Sequential([\n",
    "        Conv1D(16, kernel_size=1, activation=\"relu\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Reshape((1, 16)),  # Back to time dimension\n",
    "        SimpleRNN(8, activation=\"tanh\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    lp_model = Sequential([\n",
    "        Flatten(input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    # assert len(regressors) == len(name_regressors)\n",
    "    regressors =  [rnn16_model, lstm16_model, cnn_rnn_model, lp_model]\n",
    "    name_regressors =  [\"RNN16\", \"LSTM16\", \"CNNRNN16\", \"MLP16\"]\n",
    "    assert len(regressors) == len(name_regressors)\n",
    "    experiment_1 = PredictionExperiment(data, indices_of_interest, regressors, name_regressors, 60, id, loss_fn=SERA(bounds=bounds,T=100))\n",
    "    experiment_1.execute_experiment()\n",
    "    experiment_1.get_metrics(\"r2\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"TSCV\", show=False)\n",
    "\n",
    "    #experiment_1.top_results(\"r2\", 5, stage=\"prediction\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    #experiment_1.top_results(\"cv_r2\", 5, stage=\"CV\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    experiment_1.save_results(f\"data/sera_results_year/{region}_results/results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>season</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                       filename  season   \n",
       "0    978f49d7   predictor_978f49d7_1.parquet       1  \\\n",
       "1    978f49d7   predictor_978f49d7_2.parquet       2   \n",
       "2    978f49d7   predictor_978f49d7_3.parquet       3   \n",
       "3    978f49d7   predictor_978f49d7_4.parquet       4   \n",
       "4    978f49d7   predictor_978f49d7_5.parquet       5   \n",
       "..        ...                            ...     ...   \n",
       "247  458d357c   predictor_458d357c_8.parquet       8   \n",
       "248  458d357c   predictor_458d357c_9.parquet       9   \n",
       "249  458d357c  predictor_458d357c_10.parquet      10   \n",
       "250  458d357c  predictor_458d357c_11.parquet      11   \n",
       "251  458d357c  predictor_458d357c_12.parquet      12   \n",
       "\n",
       "                                               indices  \n",
       "0    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "1    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "2    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "3    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "4    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "..                                                 ...  \n",
       "247  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "248  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "249  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "250  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "251  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region=\"chile\"\n",
    "metadata = pd.read_csv(f\"data/climate_features/{region}/metadata.csv\")\n",
    "metadata.reset_index(inplace=True, drop=True)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(f\"data/climate_results/{region}_results/results.csv\")\n",
    "ids_results = results[\"id_data\"].unique()\n",
    "id_experiments = metadata[\"id\"].unique()\n",
    "ids_to_execute = [id for id in id_experiments if id not in ids_results]\n",
    "print(len(ids_to_execute))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 978f49d7 iter 1\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 13s 44ms/step - loss: 19.0550 - val_loss: 25.4534\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.5619 - val_loss: 23.5846\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.4949 - val_loss: 22.0016\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.0654 - val_loss: 20.8384\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.4029 - val_loss: 19.8389\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.6308 - val_loss: 18.8708\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3784 - val_loss: 18.2170\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.3668 - val_loss: 17.6655\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.4458 - val_loss: 17.2979\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6386 - val_loss: 17.2480\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1291 - val_loss: 17.0279\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.0203 - val_loss: 17.1514\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.7070 - val_loss: 17.0209\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.7736 - val_loss: 16.9418\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9565 - val_loss: 16.9581\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9459 - val_loss: 16.8296\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9906 - val_loss: 17.0884\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6072 - val_loss: 17.1413\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9712 - val_loss: 17.0687\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.8393 - val_loss: 17.0814\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6476 - val_loss: 17.1020\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0971 - val_loss: 17.2014\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4958 - val_loss: 17.2533\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1879 - val_loss: 17.2576\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8323 - val_loss: 17.3991\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7914 - val_loss: 17.2363\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6745 - val_loss: 17.4120\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8140 - val_loss: 17.3688\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3239 - val_loss: 17.4581\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5809 - val_loss: 17.4668\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1069 - val_loss: 17.7076\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4173 - val_loss: 17.6403\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1747 - val_loss: 17.8724\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1513 - val_loss: 17.9609\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4477 - val_loss: 17.7658\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3571 - val_loss: 18.0037\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 802us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 750us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 760us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 49ms/step - loss: 18.6980 - val_loss: 26.1245\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18.0209 - val_loss: 24.9807\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.2355 - val_loss: 23.3894\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.3954 - val_loss: 21.8217\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.6380 - val_loss: 20.4283\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.8951 - val_loss: 19.1056\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.1109 - val_loss: 18.4042\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.5759 - val_loss: 17.7712\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2540 - val_loss: 17.5066\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9468 - val_loss: 17.5091\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6442 - val_loss: 17.4217\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3856 - val_loss: 17.3388\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0862 - val_loss: 17.2439\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9802 - val_loss: 17.2581\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6036 - val_loss: 17.3423\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2318 - val_loss: 17.3278\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1141 - val_loss: 17.6237\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1411 - val_loss: 17.4830\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9534 - val_loss: 17.4432\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1210 - val_loss: 17.4648\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.7606 - val_loss: 17.7253\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3468 - val_loss: 17.5516\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3504 - val_loss: 17.5527\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3635 - val_loss: 18.0365\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3799 - val_loss: 17.9639\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2192 - val_loss: 17.9240\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1820 - val_loss: 18.1155\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7723 - val_loss: 17.9038\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8339 - val_loss: 18.2140\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4485 - val_loss: 18.2516\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7206 - val_loss: 18.4969\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8010 - val_loss: 18.4442\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4678 - val_loss: 18.4325\n",
      "18/18 [==============================] - 0s 915us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "19/19 [==============================] - 0s 845us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 827us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 803us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 44ms/step - loss: 19.3980 - val_loss: 21.8859\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.7090 - val_loss: 19.3762\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.3898 - val_loss: 17.8606\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.8687 - val_loss: 17.3243\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.0834 - val_loss: 16.9893\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.9241 - val_loss: 16.5697\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.8055 - val_loss: 16.6411\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.8180 - val_loss: 16.5730\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.5773 - val_loss: 16.7332\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9074 - val_loss: 16.5356\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9520 - val_loss: 16.6808\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1865 - val_loss: 16.7607\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1914 - val_loss: 16.4368\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4778 - val_loss: 16.6542\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2973 - val_loss: 16.7706\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9764 - val_loss: 16.7737\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8772 - val_loss: 17.0467\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8937 - val_loss: 16.9286\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2136 - val_loss: 16.9639\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3270 - val_loss: 17.1143\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7948 - val_loss: 17.0653\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4672 - val_loss: 17.2179\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1171 - val_loss: 17.2117\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9532 - val_loss: 17.8638\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1784 - val_loss: 17.3213\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2223 - val_loss: 17.2370\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9803 - val_loss: 17.4341\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8787 - val_loss: 17.4122\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.0607 - val_loss: 17.7574\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8006 - val_loss: 17.9199\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8475 - val_loss: 17.9838\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4012 - val_loss: 17.7998\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2265 - val_loss: 17.4052\n",
      "18/18 [==============================] - 0s 832us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 730us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 746us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 777us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 497us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 43ms/step - loss: 19.3562 - val_loss: 25.9132\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18.1063 - val_loss: 24.6155\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.2050 - val_loss: 23.4461\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.7434 - val_loss: 22.4933\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.8910 - val_loss: 21.6710\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.7441 - val_loss: 21.0224\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.0937 - val_loss: 20.3252\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.5518 - val_loss: 19.6771\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.2100 - val_loss: 18.9238\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.2652 - val_loss: 18.8390\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.6561 - val_loss: 18.5739\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.4496 - val_loss: 18.4393\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1566 - val_loss: 18.0640\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.8638 - val_loss: 18.0164\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.7678 - val_loss: 17.9811\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4810 - val_loss: 17.8516\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5956 - val_loss: 17.8913\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3457 - val_loss: 17.8324\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2029 - val_loss: 17.6737\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5937 - val_loss: 17.5618\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6554 - val_loss: 17.6913\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6459 - val_loss: 17.5257\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1060 - val_loss: 17.1823\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9431 - val_loss: 17.3648\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8024 - val_loss: 17.4757\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4147 - val_loss: 17.2875\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1749 - val_loss: 17.3527\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3309 - val_loss: 16.8914\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1718 - val_loss: 17.0482\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6331 - val_loss: 16.9789\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3121 - val_loss: 16.7505\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5027 - val_loss: 16.6811\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5161 - val_loss: 16.8170\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9733 - val_loss: 17.1043\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5673 - val_loss: 17.0669\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0160 - val_loss: 17.2003\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0126 - val_loss: 17.1210\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2583 - val_loss: 17.1674\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1632 - val_loss: 16.8928\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0326 - val_loss: 16.8394\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8804 - val_loss: 16.6608\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3867 - val_loss: 17.1698\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5886 - val_loss: 17.3623\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6927 - val_loss: 17.5852\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5279 - val_loss: 17.3949\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6291 - val_loss: 17.4417\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0156 - val_loss: 17.1774\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0222 - val_loss: 17.1235\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7007 - val_loss: 16.9093\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0815 - val_loss: 16.9769\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8476 - val_loss: 16.8567\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6347 - val_loss: 17.6771\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4143 - val_loss: 17.1208\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0582 - val_loss: 17.2114\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7164 - val_loss: 17.5538\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2327 - val_loss: 17.4045\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7614 - val_loss: 17.4920\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.6650 - val_loss: 17.6387\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5920 - val_loss: 17.9167\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7268 - val_loss: 17.5249\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7051 - val_loss: 17.8674\n",
      "18/18 [==============================] - 0s 719us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "19/19 [==============================] - 0s 858us/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "19/19 [==============================] - 0s 794us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "19/19 [==============================] - 0s 736us/step\n",
      "Executing 69ae08a8 iter 2\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 45ms/step - loss: 20.4968 - val_loss: 26.9021\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18.3931 - val_loss: 24.8743\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.9533 - val_loss: 23.0438\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.2021 - val_loss: 21.6569\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.2633 - val_loss: 20.6496\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.2163 - val_loss: 19.5877\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.6959 - val_loss: 19.3174\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1776 - val_loss: 18.6884\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5816 - val_loss: 18.4454\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.7516 - val_loss: 18.4645\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1615 - val_loss: 18.1889\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4341 - val_loss: 18.1652\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6757 - val_loss: 18.1448\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1456 - val_loss: 18.1690\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1802 - val_loss: 18.0922\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8363 - val_loss: 17.9978\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8360 - val_loss: 18.0008\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.0496 - val_loss: 18.0607\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5934 - val_loss: 18.1341\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5185 - val_loss: 18.0575\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4465 - val_loss: 18.1528\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0861 - val_loss: 18.0232\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8741 - val_loss: 17.9889\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7362 - val_loss: 18.2925\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0545 - val_loss: 18.2232\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8214 - val_loss: 18.2087\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6933 - val_loss: 18.6402\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4255 - val_loss: 18.5624\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4722 - val_loss: 18.7279\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7857 - val_loss: 18.5833\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1546 - val_loss: 18.4840\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5895 - val_loss: 18.6350\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8416 - val_loss: 18.8513\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8802 - val_loss: 18.7550\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9968 - val_loss: 18.9045\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9586 - val_loss: 19.0455\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8949 - val_loss: 18.8895\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8521 - val_loss: 18.8016\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.6464 - val_loss: 18.7385\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5183 - val_loss: 18.6591\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5435 - val_loss: 18.6137\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1740 - val_loss: 19.0219\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4174 - val_loss: 19.3176\n",
      "18/18 [==============================] - 0s 797us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 762us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 826us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 814us/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "19/19 [==============================] - 0s 771us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 859us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 48ms/step - loss: 18.9188 - val_loss: 26.2402\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.8794 - val_loss: 24.5131\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.8477 - val_loss: 22.3734\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.7273 - val_loss: 20.4453\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5901 - val_loss: 19.3751\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7692 - val_loss: 18.4842\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.8640 - val_loss: 18.3366\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.3023 - val_loss: 18.3179\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6594 - val_loss: 18.4289\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4188 - val_loss: 18.6337\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8929 - val_loss: 18.8900\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6337 - val_loss: 18.9028\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6032 - val_loss: 18.8491\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8497 - val_loss: 19.0332\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6789 - val_loss: 19.2762\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4955 - val_loss: 18.9965\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0460 - val_loss: 19.2550\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2770 - val_loss: 19.0839\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.6259 - val_loss: 19.0049\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5177 - val_loss: 19.2757\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4154 - val_loss: 19.2230\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1552 - val_loss: 19.4315\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9117 - val_loss: 19.2987\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.7632 - val_loss: 19.7103\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6891 - val_loss: 19.1297\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.3576 - val_loss: 19.3678\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0186 - val_loss: 19.5172\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 6.9498 - val_loss: 19.6584\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "19/19 [==============================] - 0s 161us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 923us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 45ms/step - loss: 21.2771 - val_loss: 30.9587\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.2906 - val_loss: 26.1507\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.4124 - val_loss: 23.7525\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.9153 - val_loss: 22.5454\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.5623 - val_loss: 21.8707\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2352 - val_loss: 21.5289\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2026 - val_loss: 21.7794\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6002 - val_loss: 21.5101\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6538 - val_loss: 21.8583\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0273 - val_loss: 21.6196\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9823 - val_loss: 22.0038\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9050 - val_loss: 21.6231\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9591 - val_loss: 21.1642\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4162 - val_loss: 21.6943\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8691 - val_loss: 21.3106\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4198 - val_loss: 20.7247\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6831 - val_loss: 21.2025\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4918 - val_loss: 21.4775\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4172 - val_loss: 20.5073\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7682 - val_loss: 21.4204\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2173 - val_loss: 21.0109\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7734 - val_loss: 21.5013\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6963 - val_loss: 21.3240\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3747 - val_loss: 22.0901\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3836 - val_loss: 20.6622\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4558 - val_loss: 21.6002\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7220 - val_loss: 21.1723\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5865 - val_loss: 22.2320\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9114 - val_loss: 22.6175\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8554 - val_loss: 22.3928\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4172 - val_loss: 21.2962\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.2692 - val_loss: 22.4074\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0981 - val_loss: 21.1862\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.3749 - val_loss: 21.8672\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0508 - val_loss: 23.7578\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.3848 - val_loss: 21.8381\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1392 - val_loss: 22.4631\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5283 - val_loss: 22.0765\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.6991 - val_loss: 21.9371\n",
      "18/18 [==============================] - 0s 815us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 982us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 880us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 794us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 754us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 13s 43ms/step - loss: 19.2605 - val_loss: 25.8662\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.7539 - val_loss: 23.4004\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.6033 - val_loss: 22.0811\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.1087 - val_loss: 21.0103\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.0289 - val_loss: 20.5101\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.3767 - val_loss: 19.9848\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2011 - val_loss: 19.8420\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.8899 - val_loss: 19.7318\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3635 - val_loss: 19.7451\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4542 - val_loss: 19.9436\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1207 - val_loss: 19.7689\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5748 - val_loss: 19.4229\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7132 - val_loss: 19.4993\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3849 - val_loss: 19.6864\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2586 - val_loss: 19.4627\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2172 - val_loss: 19.4711\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8951 - val_loss: 19.4883\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.0378 - val_loss: 19.5356\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2936 - val_loss: 19.6550\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6055 - val_loss: 19.2327\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1912 - val_loss: 19.6039\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4602 - val_loss: 19.6935\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7595 - val_loss: 19.7647\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9460 - val_loss: 19.9269\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0199 - val_loss: 19.8804\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4984 - val_loss: 19.9065\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3788 - val_loss: 19.9885\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0559 - val_loss: 20.0125\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4882 - val_loss: 20.0429\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8205 - val_loss: 20.0360\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1248 - val_loss: 20.0474\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0274 - val_loss: 20.1718\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9859 - val_loss: 19.9801\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9724 - val_loss: 20.1107\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5431 - val_loss: 20.4265\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8948 - val_loss: 20.2404\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.6472 - val_loss: 20.2584\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7224 - val_loss: 20.4472\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.2667 - val_loss: 20.4329\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8864 - val_loss: 20.3517\n",
      "18/18 [==============================] - 0s 484us/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 801us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 594us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 715us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "19/19 [==============================] - 0s 850us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 776us/step\n",
      "Executing 1b939ac5 iter 3\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 48ms/step - loss: 20.1805 - val_loss: 28.6555\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.8592 - val_loss: 25.1411\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.0936 - val_loss: 23.0927\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6764 - val_loss: 21.7436\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7807 - val_loss: 21.3264\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1844 - val_loss: 20.5629\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.9580 - val_loss: 20.6472\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4207 - val_loss: 20.5001\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8116 - val_loss: 20.5499\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9987 - val_loss: 20.6568\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4403 - val_loss: 20.6690\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2389 - val_loss: 20.3080\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4777 - val_loss: 20.2777\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8863 - val_loss: 20.5921\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.0847 - val_loss: 20.6957\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6077 - val_loss: 20.0386\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6747 - val_loss: 20.3934\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3607 - val_loss: 20.6715\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9611 - val_loss: 20.6580\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2694 - val_loss: 20.6739\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3403 - val_loss: 20.6347\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9901 - val_loss: 21.0882\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5616 - val_loss: 21.3539\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3889 - val_loss: 21.9746\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3252 - val_loss: 21.1091\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0736 - val_loss: 21.4582\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6711 - val_loss: 21.8754\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1593 - val_loss: 21.9840\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2749 - val_loss: 22.4573\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.1758 - val_loss: 22.4859\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6388 - val_loss: 22.8755\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8194 - val_loss: 23.7039\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.0251 - val_loss: 23.3685\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.0523 - val_loss: 23.5778\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0557 - val_loss: 23.0831\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4531 - val_loss: 24.1238\n",
      "18/18 [==============================] - 0s 876us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 870us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 796us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 939us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 49ms/step - loss: 18.9155 - val_loss: 26.5196\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.7652 - val_loss: 25.2454\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.7225 - val_loss: 23.6708\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.6031 - val_loss: 21.9741\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2880 - val_loss: 20.6551\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.3337 - val_loss: 19.4815\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6601 - val_loss: 18.8141\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9252 - val_loss: 18.4668\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5582 - val_loss: 18.3947\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1477 - val_loss: 18.5015\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6819 - val_loss: 18.4809\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4496 - val_loss: 18.4862\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2260 - val_loss: 18.5042\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7503 - val_loss: 18.5979\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6036 - val_loss: 18.8164\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6269 - val_loss: 18.5871\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8797 - val_loss: 18.8913\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9142 - val_loss: 18.9451\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3597 - val_loss: 19.0247\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4093 - val_loss: 19.1077\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.1165 - val_loss: 19.2437\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3038 - val_loss: 19.4900\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.7390 - val_loss: 19.4014\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3235 - val_loss: 19.6925\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.5976 - val_loss: 19.5423\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.4306 - val_loss: 19.7246\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.0036 - val_loss: 19.9806\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.9465 - val_loss: 20.1435\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.6546 - val_loss: 20.7955\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "19/19 [==============================] - 0s 784us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 543us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 904us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 985us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 765us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 46ms/step - loss: 18.4391 - val_loss: 22.3361\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.3197 - val_loss: 20.2344\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.2906 - val_loss: 19.2812\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.8421 - val_loss: 19.0409\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.9158 - val_loss: 18.8430\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.9379 - val_loss: 18.4496\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.5149 - val_loss: 18.8347\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.1108 - val_loss: 18.9707\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.8755 - val_loss: 19.0241\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9184 - val_loss: 18.9372\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6721 - val_loss: 19.1254\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.2473 - val_loss: 18.8991\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7299 - val_loss: 18.3116\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1867 - val_loss: 18.8769\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5475 - val_loss: 18.6962\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4172 - val_loss: 18.4015\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3288 - val_loss: 18.7550\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1731 - val_loss: 18.8003\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9427 - val_loss: 18.2726\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6191 - val_loss: 18.6428\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6765 - val_loss: 18.3979\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6611 - val_loss: 18.8767\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5053 - val_loss: 18.8139\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0984 - val_loss: 19.1043\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2826 - val_loss: 18.5374\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0406 - val_loss: 17.8926\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3714 - val_loss: 18.5989\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6663 - val_loss: 19.1652\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4367 - val_loss: 19.2003\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5376 - val_loss: 19.3046\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5455 - val_loss: 18.8440\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3087 - val_loss: 19.4192\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9594 - val_loss: 18.5635\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1346 - val_loss: 18.7638\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7594 - val_loss: 19.3435\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0877 - val_loss: 18.7379\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8491 - val_loss: 19.4596\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9789 - val_loss: 18.6610\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5211 - val_loss: 18.9289\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4718 - val_loss: 19.3022\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0206 - val_loss: 19.5095\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1264 - val_loss: 19.1773\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4275 - val_loss: 19.0680\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.0006 - val_loss: 19.9094\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8211 - val_loss: 19.3088\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.0958 - val_loss: 19.3738\n",
      "18/18 [==============================] - 0s 832us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 952us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 447us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 43ms/step - loss: 20.9509 - val_loss: 25.1262\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.0507 - val_loss: 22.2924\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.6964 - val_loss: 20.0092\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.8816 - val_loss: 18.9797\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.0236 - val_loss: 18.3830\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.4529 - val_loss: 18.0481\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6047 - val_loss: 18.0750\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3570 - val_loss: 17.8938\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.4532 - val_loss: 18.2743\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6954 - val_loss: 18.5096\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3394 - val_loss: 18.7328\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1376 - val_loss: 18.7598\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6512 - val_loss: 18.4706\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4257 - val_loss: 18.6946\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0481 - val_loss: 18.9650\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5664 - val_loss: 18.6154\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6761 - val_loss: 18.9050\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4049 - val_loss: 19.0575\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7244 - val_loss: 18.9115\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.5077 - val_loss: 19.2006\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2563 - val_loss: 19.4910\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3767 - val_loss: 19.4347\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1596 - val_loss: 19.4599\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9041 - val_loss: 19.8578\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5484 - val_loss: 19.6340\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8713 - val_loss: 19.1831\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7657 - val_loss: 19.7271\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4350 - val_loss: 19.6990\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 667us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 667us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 745us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 796us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 739us/step\n",
      "Executing 50a3f070 iter 4\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 84ms/step - loss: 19.7663 - val_loss: 26.7905\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.7108 - val_loss: 24.4405\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.7858 - val_loss: 22.5973\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.7066 - val_loss: 21.1797\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.3870 - val_loss: 20.2264\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.5405 - val_loss: 19.3356\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3820 - val_loss: 19.0403\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9939 - val_loss: 18.8191\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7012 - val_loss: 18.5210\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1103 - val_loss: 18.6785\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2855 - val_loss: 18.4303\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8037 - val_loss: 18.3035\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8686 - val_loss: 18.1788\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.7186 - val_loss: 18.3513\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9176 - val_loss: 18.4540\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.6056 - val_loss: 18.2483\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.3982 - val_loss: 18.3737\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1965 - val_loss: 18.3081\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9207 - val_loss: 18.3034\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0902 - val_loss: 18.2118\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7119 - val_loss: 18.2703\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8722 - val_loss: 18.1307\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7562 - val_loss: 18.4592\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8064 - val_loss: 18.6668\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0982 - val_loss: 18.5766\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.6127 - val_loss: 18.5035\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5388 - val_loss: 18.7992\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0359 - val_loss: 18.7364\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1148 - val_loss: 19.4177\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.0683 - val_loss: 18.9736\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8731 - val_loss: 19.2686\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.1240 - val_loss: 19.2670\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.4635 - val_loss: 19.0264\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.1991 - val_loss: 19.4793\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.9004 - val_loss: 19.3553\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6939 - val_loss: 19.3894\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.8465 - val_loss: 19.1707\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.7687 - val_loss: 18.8068\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 8.5937 - val_loss: 18.8004\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 7.9359 - val_loss: 18.8004\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.2943 - val_loss: 18.9716\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8898 - val_loss: 18.7525\n",
      "18/18 [==============================] - 0s 995us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "19/19 [==============================] - 0s 790us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 802us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 823us/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "19/19 [==============================] - 0s 674us/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "19/19 [==============================] - 0s 477us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 50ms/step - loss: 18.7644 - val_loss: 26.0861\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.5540 - val_loss: 24.4178\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.3564 - val_loss: 22.5252\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.2272 - val_loss: 20.8860\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2410 - val_loss: 19.7518\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.4718 - val_loss: 18.6967\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.6450 - val_loss: 18.1092\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1633 - val_loss: 17.6341\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4725 - val_loss: 17.3360\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.0482 - val_loss: 17.2952\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6526 - val_loss: 17.1935\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2030 - val_loss: 17.1440\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0768 - val_loss: 17.0444\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4295 - val_loss: 17.2625\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2791 - val_loss: 17.4999\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1053 - val_loss: 17.1772\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0184 - val_loss: 17.7373\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7479 - val_loss: 17.9647\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.2860 - val_loss: 18.0291\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5074 - val_loss: 18.3953\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3337 - val_loss: 18.4194\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8678 - val_loss: 18.6979\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.7076 - val_loss: 18.8195\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.5653 - val_loss: 19.2375\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.6414 - val_loss: 19.0488\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.0034 - val_loss: 19.2081\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3694 - val_loss: 19.5259\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.0158 - val_loss: 19.5218\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.1870 - val_loss: 19.9430\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.6696 - val_loss: 19.6850\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.7177 - val_loss: 19.4762\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.7848 - val_loss: 20.1222\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.6592 - val_loss: 19.7041\n",
      "18/18 [==============================] - 0s 940us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 267us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "19/19 [==============================] - 0s 851us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 841us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "19/19 [==============================] - 0s 951us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 45ms/step - loss: 19.3774 - val_loss: 25.1397\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.0203 - val_loss: 22.3290\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.5045 - val_loss: 20.7955\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.6109 - val_loss: 20.0991\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.9937 - val_loss: 19.7264\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.4515 - val_loss: 19.6464\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.0492 - val_loss: 20.0048\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.0093 - val_loss: 19.9135\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.6444 - val_loss: 20.3711\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1433 - val_loss: 20.3123\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.1251 - val_loss: 20.5905\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8121 - val_loss: 19.9085\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1312 - val_loss: 20.0550\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3373 - val_loss: 20.6896\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8163 - val_loss: 20.5606\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.8135 - val_loss: 19.7381\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5318 - val_loss: 21.0398\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5016 - val_loss: 20.7884\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3923 - val_loss: 19.8438\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1983 - val_loss: 20.5177\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1400 - val_loss: 20.2159\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0964 - val_loss: 20.6487\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8679 - val_loss: 21.3190\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2980 - val_loss: 22.0209\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4649 - val_loss: 20.4402\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9509 - val_loss: 21.1860\n",
      "18/18 [==============================] - 0s 796us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 826us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 893us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 446us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 771us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 44ms/step - loss: 20.8846 - val_loss: 23.7638\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18.2123 - val_loss: 21.6097\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.6810 - val_loss: 19.9357\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.7404 - val_loss: 18.9226\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.4882 - val_loss: 18.1218\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.1258 - val_loss: 16.9849\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2216 - val_loss: 16.7563\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.7039 - val_loss: 16.5228\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.9833 - val_loss: 16.5791\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9547 - val_loss: 16.6520\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9344 - val_loss: 16.7964\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.7819 - val_loss: 16.9769\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5816 - val_loss: 16.8595\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.1758 - val_loss: 17.0842\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8099 - val_loss: 16.8201\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.6114 - val_loss: 16.7497\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5248 - val_loss: 16.9414\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4314 - val_loss: 17.0365\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.4288 - val_loss: 17.0384\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5551 - val_loss: 17.4991\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1414 - val_loss: 17.6057\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7860 - val_loss: 18.0978\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9233 - val_loss: 18.0383\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2018 - val_loss: 18.5235\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.4769 - val_loss: 18.2755\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7128 - val_loss: 18.1840\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.9027 - val_loss: 18.4950\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3566 - val_loss: 18.7032\n",
      "18/18 [==============================] - 0s 693us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "19/19 [==============================] - 0s 723us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 839us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 577us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 790us/step\n",
      "Executing 4d17ba1a iter 5\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 22s 59ms/step - loss: 21.2413 - val_loss: 28.2559\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.5086 - val_loss: 24.7790\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.5708 - val_loss: 22.4869\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.0123 - val_loss: 20.2939\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.4382 - val_loss: 19.0264\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.2622 - val_loss: 17.8872\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.1200 - val_loss: 17.3467\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9285 - val_loss: 17.1364\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3175 - val_loss: 17.1057\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.1293 - val_loss: 17.3143\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9383 - val_loss: 17.1814\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9230 - val_loss: 17.2576\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7848 - val_loss: 17.2605\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.6689 - val_loss: 17.3823\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3579 - val_loss: 17.5192\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2146 - val_loss: 17.3747\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1150 - val_loss: 17.4882\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0378 - val_loss: 17.7102\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8629 - val_loss: 17.8156\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8385 - val_loss: 17.7587\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9842 - val_loss: 17.9556\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6561 - val_loss: 18.2312\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6426 - val_loss: 18.2632\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6025 - val_loss: 18.5429\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4490 - val_loss: 18.6503\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0105 - val_loss: 18.6252\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8999 - val_loss: 18.7929\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2121 - val_loss: 18.9125\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9678 - val_loss: 19.1864\n",
      "18/18 [==============================] - 0s 941us/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "19/19 [==============================] - 0s 775us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 779us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 647us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "19/19 [==============================] - 0s 856us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 50ms/step - loss: 18.7339 - val_loss: 26.0600\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.8155 - val_loss: 24.5655\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.6124 - val_loss: 22.4053\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.3363 - val_loss: 20.3823\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0722 - val_loss: 18.8683\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.2701 - val_loss: 17.6685\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.5215 - val_loss: 17.2205\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2120 - val_loss: 17.0071\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7611 - val_loss: 17.0186\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4470 - val_loss: 17.2076\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1510 - val_loss: 17.3255\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8719 - val_loss: 17.4515\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6724 - val_loss: 17.5433\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3501 - val_loss: 17.7057\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2319 - val_loss: 17.8121\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3312 - val_loss: 17.8058\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7631 - val_loss: 18.1282\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0158 - val_loss: 18.4574\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5084 - val_loss: 18.6279\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6459 - val_loss: 18.8006\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2741 - val_loss: 19.2887\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0530 - val_loss: 19.5317\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9598 - val_loss: 19.4716\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8745 - val_loss: 19.7376\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8114 - val_loss: 20.0401\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6482 - val_loss: 20.0149\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6525 - val_loss: 20.1357\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3947 - val_loss: 20.3189\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 929us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 891us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 799us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 834us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 901us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 45ms/step - loss: 18.0660 - val_loss: 20.2136\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.1028 - val_loss: 17.2121\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3041 - val_loss: 16.1718\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6592 - val_loss: 15.8201\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1421 - val_loss: 15.6774\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.0318 - val_loss: 15.2203\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.0665 - val_loss: 15.4432\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.5190 - val_loss: 15.5058\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1666 - val_loss: 15.8163\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.3894 - val_loss: 16.1036\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1095 - val_loss: 16.5135\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2460 - val_loss: 15.9588\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.2200 - val_loss: 15.8542\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9298 - val_loss: 16.3331\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1230 - val_loss: 16.4798\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1126 - val_loss: 16.0595\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1135 - val_loss: 16.6506\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4967 - val_loss: 16.4907\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9758 - val_loss: 16.2396\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5065 - val_loss: 16.3770\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7012 - val_loss: 16.2836\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5346 - val_loss: 16.8427\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3374 - val_loss: 16.9149\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3882 - val_loss: 17.3452\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2308 - val_loss: 16.6668\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8625 - val_loss: 16.5961\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 903us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 857us/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "19/19 [==============================] - 0s 796us/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "19/19 [==============================] - 0s 745us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 940us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 45ms/step - loss: 20.6886 - val_loss: 24.7434\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.9901 - val_loss: 22.3192\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.3861 - val_loss: 20.6828\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.5914 - val_loss: 19.6451\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15.0253 - val_loss: 19.0478\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.2690 - val_loss: 18.3899\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.8483 - val_loss: 18.1696\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.4229 - val_loss: 17.9457\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.0833 - val_loss: 17.6430\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.2821 - val_loss: 17.7954\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3416 - val_loss: 17.7850\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4060 - val_loss: 17.5568\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12.3145 - val_loss: 17.3564\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.9656 - val_loss: 17.3822\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7672 - val_loss: 17.4831\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.4863 - val_loss: 17.5527\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.3287 - val_loss: 17.3801\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.8516 - val_loss: 17.6770\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.9452 - val_loss: 17.7423\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6343 - val_loss: 17.6551\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.7626 - val_loss: 17.7360\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5510 - val_loss: 18.2064\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.5570 - val_loss: 17.8398\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.1886 - val_loss: 18.0345\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2064 - val_loss: 18.0328\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1320 - val_loss: 18.1016\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.0843 - val_loss: 18.3163\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 10.2331 - val_loss: 18.3204\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.8846 - val_loss: 18.5311\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.3434 - val_loss: 18.3902\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5152 - val_loss: 18.2450\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.7456 - val_loss: 18.1886\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 9.2293 - val_loss: 18.3733\n",
      "18/18 [==============================] - 0s 764us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 752us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 733us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 735us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "19/19 [==============================] - 0s 719us/step\n",
      "Executing 3adff093 iter 6\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 47ms/step - loss: 19.1103 - val_loss: 26.0739\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.8861 - val_loss: 24.5614\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.1119 - val_loss: 23.4043\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.3797 - val_loss: 22.4391\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.8169 - val_loss: 21.7111\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.5747 - val_loss: 20.8427\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.2148 - val_loss: 20.4240\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.9542 - val_loss: 19.9747\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6854 - val_loss: 19.3918\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6593 - val_loss: 19.2346\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2939 - val_loss: 18.9435\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3534 - val_loss: 18.8449\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4636 - val_loss: 18.6001\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2695 - val_loss: 18.4586\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3746 - val_loss: 18.3816\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2805 - val_loss: 18.2952\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2676 - val_loss: 18.3573\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6154 - val_loss: 18.3389\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3225 - val_loss: 18.0892\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2306 - val_loss: 18.0488\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3618 - val_loss: 18.0870\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3231 - val_loss: 18.0341\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2990 - val_loss: 17.9404\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3592 - val_loss: 18.0175\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9913 - val_loss: 18.1052\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2298 - val_loss: 17.8951\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9448 - val_loss: 17.9836\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3111 - val_loss: 18.1066\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0043 - val_loss: 18.2367\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9324 - val_loss: 18.1865\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0837 - val_loss: 18.2988\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2494 - val_loss: 18.1750\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8639 - val_loss: 18.1802\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8149 - val_loss: 18.2488\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9952 - val_loss: 18.3021\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1004 - val_loss: 18.4078\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1289 - val_loss: 18.3146\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8968 - val_loss: 18.3935\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0677 - val_loss: 18.3115\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8465 - val_loss: 18.1939\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5708 - val_loss: 18.1129\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6690 - val_loss: 18.2422\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7709 - val_loss: 18.2154\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5622 - val_loss: 18.1355\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8230 - val_loss: 18.0763\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6882 - val_loss: 18.1628\n",
      "18/18 [==============================] - 0s 842us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 987us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 887us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 840us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 817us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 18.6302 - val_loss: 26.0884\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.8927 - val_loss: 24.7045\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.1414 - val_loss: 23.1064\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.3965 - val_loss: 21.4782\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.6874 - val_loss: 20.1867\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.3210 - val_loss: 19.0308\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.0384 - val_loss: 18.5363\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.8996 - val_loss: 18.1480\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.7679 - val_loss: 17.8576\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.7150 - val_loss: 17.7719\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5815 - val_loss: 17.6066\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6071 - val_loss: 17.5699\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.5062 - val_loss: 17.4217\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.4847 - val_loss: 17.4408\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4049 - val_loss: 17.3930\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4667 - val_loss: 17.3422\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3699 - val_loss: 17.5049\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3969 - val_loss: 17.5026\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2915 - val_loss: 17.4758\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3162 - val_loss: 17.4307\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2771 - val_loss: 17.4949\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0921 - val_loss: 17.6013\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1765 - val_loss: 17.5040\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0986 - val_loss: 17.5708\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1428 - val_loss: 17.7085\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9748 - val_loss: 17.6769\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8973 - val_loss: 17.7511\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8586 - val_loss: 17.7911\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9449 - val_loss: 17.9085\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9048 - val_loss: 17.9545\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7135 - val_loss: 18.0776\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8498 - val_loss: 18.0443\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8198 - val_loss: 18.2045\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6556 - val_loss: 18.3467\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7463 - val_loss: 18.3776\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6362 - val_loss: 18.5144\n",
      "18/18 [==============================] - 0s 824us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "19/19 [==============================] - 0s 853us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 788us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 892us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 47ms/step - loss: 18.7086 - val_loss: 22.2197\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.4599 - val_loss: 20.1801\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.8195 - val_loss: 19.2131\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.3990 - val_loss: 18.6851\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.1624 - val_loss: 18.5942\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.1484 - val_loss: 18.2896\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6973 - val_loss: 18.5201\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.7706 - val_loss: 18.5885\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5199 - val_loss: 18.6880\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4997 - val_loss: 19.0456\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.0048 - val_loss: 19.3967\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5128 - val_loss: 19.4616\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3068 - val_loss: 19.2812\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4628 - val_loss: 19.4533\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3688 - val_loss: 19.2655\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1564 - val_loss: 19.3528\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0330 - val_loss: 19.8163\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1653 - val_loss: 19.5972\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1380 - val_loss: 19.4644\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9097 - val_loss: 19.6083\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8862 - val_loss: 19.8192\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9256 - val_loss: 20.0085\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0842 - val_loss: 19.6796\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6248 - val_loss: 20.0458\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7800 - val_loss: 20.2376\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7910 - val_loss: 19.9963\n",
      "18/18 [==============================] - 0s 816us/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "19/19 [==============================] - 0s 284us/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "19/19 [==============================] - 0s 790us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 779us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 46ms/step - loss: 18.9034 - val_loss: 25.0876\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17.3944 - val_loss: 22.7170\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16.1049 - val_loss: 21.1730\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.9216 - val_loss: 20.2677\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.3417 - val_loss: 19.6851\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.3074 - val_loss: 19.1787\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.0124 - val_loss: 18.8662\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.7818 - val_loss: 18.6999\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.7207 - val_loss: 18.4937\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.4724 - val_loss: 18.4281\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4548 - val_loss: 18.2539\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5907 - val_loss: 18.2006\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3016 - val_loss: 17.9807\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4274 - val_loss: 17.9231\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4478 - val_loss: 17.8037\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3720 - val_loss: 17.7303\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3685 - val_loss: 17.8263\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.5167 - val_loss: 17.6495\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.4183 - val_loss: 17.5704\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2999 - val_loss: 17.5520\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.3308 - val_loss: 17.5919\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14.1596 - val_loss: 17.6191\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.3058 - val_loss: 17.4434\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1660 - val_loss: 17.5058\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.0895 - val_loss: 17.5497\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1188 - val_loss: 17.4542\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0129 - val_loss: 17.5374\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0670 - val_loss: 17.4384\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1359 - val_loss: 17.5892\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.0183 - val_loss: 17.4979\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9910 - val_loss: 17.6473\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0334 - val_loss: 17.5908\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8735 - val_loss: 17.6443\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7172 - val_loss: 17.7452\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9250 - val_loss: 17.7192\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7621 - val_loss: 17.8085\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9486 - val_loss: 17.8293\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7262 - val_loss: 17.8957\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.7734 - val_loss: 17.7915\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6442 - val_loss: 17.7887\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7531 - val_loss: 17.7765\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5888 - val_loss: 18.1261\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0239 - val_loss: 18.1313\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1591 - val_loss: 18.1683\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13.4808 - val_loss: 18.1623\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5251 - val_loss: 18.0979\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8217 - val_loss: 18.3061\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.2004 - val_loss: 18.3621\n",
      "18/18 [==============================] - 0s 697us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 668us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 538us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 581us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 888us/step\n",
      "Executing b33fc639 iter 7\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 48ms/step - loss: 17.6743 - val_loss: 23.1933\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.2317 - val_loss: 21.3086\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.8919 - val_loss: 19.4625\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.1122 - val_loss: 18.7995\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5023 - val_loss: 18.5748\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.0000 - val_loss: 18.2010\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7783 - val_loss: 18.2308\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.6264 - val_loss: 18.1184\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7402 - val_loss: 18.0914\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4510 - val_loss: 18.3140\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2428 - val_loss: 18.2813\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8379 - val_loss: 18.2266\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2856 - val_loss: 18.1479\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8673 - val_loss: 18.0488\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5065 - val_loss: 18.1156\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2318 - val_loss: 18.1581\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5511 - val_loss: 18.2622\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8261 - val_loss: 18.2448\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5887 - val_loss: 18.0205\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6619 - val_loss: 18.0267\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2863 - val_loss: 18.2622\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8214 - val_loss: 18.3508\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3286 - val_loss: 18.2950\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9601 - val_loss: 18.3767\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2346 - val_loss: 18.3771\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7840 - val_loss: 18.0458\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8952 - val_loss: 18.2415\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8625 - val_loss: 18.2625\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8600 - val_loss: 18.7716\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6301 - val_loss: 18.3847\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7176 - val_loss: 18.1391\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9989 - val_loss: 18.2980\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4212 - val_loss: 18.5633\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4643 - val_loss: 18.5825\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7879 - val_loss: 18.5173\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5568 - val_loss: 18.5810\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9688 - val_loss: 18.7005\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0992 - val_loss: 18.7856\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7747 - val_loss: 18.6162\n",
      "18/18 [==============================] - 0s 882us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 873us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 769us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 54ms/step - loss: 18.7624 - val_loss: 26.2586\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.9453 - val_loss: 25.0326\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.0562 - val_loss: 23.8651\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.1460 - val_loss: 22.5896\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.0272 - val_loss: 20.9125\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8940 - val_loss: 19.2331\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.0128 - val_loss: 18.3047\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.8486 - val_loss: 17.7436\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.5344 - val_loss: 17.5783\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1703 - val_loss: 17.6348\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9804 - val_loss: 17.5076\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7206 - val_loss: 17.6112\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7331 - val_loss: 17.5322\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4145 - val_loss: 17.5883\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3770 - val_loss: 17.6560\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3618 - val_loss: 17.7149\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9829 - val_loss: 17.8030\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8979 - val_loss: 17.9885\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8702 - val_loss: 17.9687\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8188 - val_loss: 17.8064\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3482 - val_loss: 17.9921\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3951 - val_loss: 18.1431\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0224 - val_loss: 17.8534\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2931 - val_loss: 17.9957\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0072 - val_loss: 18.0542\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8386 - val_loss: 17.7566\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0507 - val_loss: 17.9808\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7066 - val_loss: 17.8764\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6238 - val_loss: 18.1747\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1404 - val_loss: 17.9984\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5682 - val_loss: 17.8071\n",
      "18/18 [==============================] - 0s 882us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "19/19 [==============================] - 0s 866us/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "19/19 [==============================] - 0s 972us/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "19/19 [==============================] - 0s 296us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 835us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 46ms/step - loss: 20.6631 - val_loss: 26.9328\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.2713 - val_loss: 23.5060\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.7803 - val_loss: 21.3509\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.4443 - val_loss: 20.1311\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3403 - val_loss: 19.4088\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.9689 - val_loss: 18.7486\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.7815 - val_loss: 18.7282\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6143 - val_loss: 18.5703\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.2981 - val_loss: 18.9984\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1678 - val_loss: 18.7881\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.8544 - val_loss: 18.8542\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7389 - val_loss: 18.8869\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1104 - val_loss: 18.7246\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4247 - val_loss: 18.9947\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.0078 - val_loss: 18.8041\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7329 - val_loss: 18.8836\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.5992 - val_loss: 18.7619\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8533 - val_loss: 18.6943\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6507 - val_loss: 18.3764\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1924 - val_loss: 18.4690\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3503 - val_loss: 18.3294\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.0263 - val_loss: 18.5179\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1084 - val_loss: 18.2430\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5818 - val_loss: 18.8102\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6148 - val_loss: 18.2848\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7386 - val_loss: 18.0035\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5475 - val_loss: 18.5393\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4148 - val_loss: 18.5513\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3751 - val_loss: 18.5344\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1560 - val_loss: 18.7072\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4194 - val_loss: 18.0855\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9772 - val_loss: 18.4142\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8154 - val_loss: 17.9694\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7450 - val_loss: 18.1949\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6577 - val_loss: 18.5668\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8627 - val_loss: 18.7412\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7609 - val_loss: 18.7349\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9662 - val_loss: 18.5051\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5392 - val_loss: 18.2243\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6217 - val_loss: 18.7114\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3807 - val_loss: 19.3871\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3712 - val_loss: 19.0408\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2818 - val_loss: 19.4163\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1398 - val_loss: 19.5904\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2454 - val_loss: 19.1923\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3933 - val_loss: 19.2322\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0686 - val_loss: 19.7486\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6440 - val_loss: 18.9490\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4742 - val_loss: 19.2267\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5127 - val_loss: 19.6433\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9128 - val_loss: 19.6826\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3809 - val_loss: 19.2460\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7089 - val_loss: 19.7709\n",
      "18/18 [==============================] - 0s 866us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 841us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 848us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 454us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 834us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 843us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 22.2705 - val_loss: 29.3400\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 19.0390 - val_loss: 26.5530\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.8602 - val_loss: 25.0554\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.0888 - val_loss: 23.9051\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.4992 - val_loss: 22.9885\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.9115 - val_loss: 22.1166\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.5040 - val_loss: 21.3821\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.1604 - val_loss: 20.7903\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6863 - val_loss: 20.1540\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0862 - val_loss: 19.7043\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0315 - val_loss: 19.1636\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.6054 - val_loss: 18.8951\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.2103 - val_loss: 18.5225\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.1379 - val_loss: 18.3006\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7268 - val_loss: 18.0591\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.6332 - val_loss: 17.8711\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.6439 - val_loss: 17.8850\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1391 - val_loss: 17.8853\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9773 - val_loss: 17.6750\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7652 - val_loss: 17.5814\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4964 - val_loss: 17.5003\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4833 - val_loss: 17.7020\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4547 - val_loss: 17.4787\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3037 - val_loss: 17.7125\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3630 - val_loss: 17.8173\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 11.0975 - val_loss: 17.4710\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9688 - val_loss: 17.7185\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1795 - val_loss: 17.5521\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8104 - val_loss: 17.8259\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7405 - val_loss: 17.6440\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3288 - val_loss: 17.6920\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6194 - val_loss: 17.8114\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7434 - val_loss: 17.5916\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2352 - val_loss: 17.7915\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9196 - val_loss: 17.9349\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1371 - val_loss: 17.7384\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6437 - val_loss: 17.5409\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3915 - val_loss: 17.6688\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9800 - val_loss: 17.4444\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6984 - val_loss: 17.5385\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7656 - val_loss: 17.2911\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3991 - val_loss: 17.7408\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8312 - val_loss: 17.8997\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4398 - val_loss: 17.7161\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6891 - val_loss: 17.5327\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1493 - val_loss: 17.8511\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2979 - val_loss: 17.6686\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5155 - val_loss: 17.4212\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4297 - val_loss: 17.6746\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9832 - val_loss: 17.7533\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1553 - val_loss: 17.4227\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0126 - val_loss: 17.6822\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0940 - val_loss: 17.5910\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8273 - val_loss: 17.7505\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1873 - val_loss: 18.0286\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6749 - val_loss: 17.4904\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2573 - val_loss: 17.6111\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4945 - val_loss: 17.9547\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0183 - val_loss: 17.7816\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4224 - val_loss: 17.8534\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5934 - val_loss: 18.0437\n",
      "18/18 [==============================] - 0s 769us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 747us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 751us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 645us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 797us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 710us/step\n",
      "Executing 511854f2 iter 8\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 49ms/step - loss: 20.0192 - val_loss: 26.6255\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.7339 - val_loss: 23.8231\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.6085 - val_loss: 21.3211\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.2078 - val_loss: 19.4064\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.3541 - val_loss: 18.3976\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9644 - val_loss: 17.6262\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4322 - val_loss: 17.1932\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.3823 - val_loss: 16.9132\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3135 - val_loss: 17.1312\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4333 - val_loss: 17.1949\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4952 - val_loss: 17.2582\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7915 - val_loss: 17.2950\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8613 - val_loss: 17.1162\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8527 - val_loss: 17.1546\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4494 - val_loss: 17.2628\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6370 - val_loss: 16.9068\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3600 - val_loss: 17.3932\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5118 - val_loss: 17.4779\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5898 - val_loss: 17.5017\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2413 - val_loss: 17.4121\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9807 - val_loss: 17.4316\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1152 - val_loss: 17.4938\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1700 - val_loss: 17.5634\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1100 - val_loss: 17.6707\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8264 - val_loss: 17.8303\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7042 - val_loss: 17.6943\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5166 - val_loss: 17.9640\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6092 - val_loss: 18.0880\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8563 - val_loss: 18.4506\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5429 - val_loss: 18.4916\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5877 - val_loss: 18.2880\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4799 - val_loss: 18.5946\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1997 - val_loss: 18.7011\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1819 - val_loss: 18.7103\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4354 - val_loss: 18.8297\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3606 - val_loss: 19.1133\n",
      "18/18 [==============================] - 0s 832us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 988us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 840us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 767us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 55ms/step - loss: 17.9366 - val_loss: 25.1549\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.5759 - val_loss: 22.7911\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.1321 - val_loss: 20.4069\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.8776 - val_loss: 18.8798\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9056 - val_loss: 18.1909\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3978 - val_loss: 17.5849\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.0397 - val_loss: 17.5040\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.6614 - val_loss: 17.4834\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2055 - val_loss: 17.6185\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3289 - val_loss: 17.8794\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9416 - val_loss: 17.8792\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7212 - val_loss: 17.9682\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9156 - val_loss: 17.8745\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2906 - val_loss: 17.9555\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4332 - val_loss: 18.0903\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9990 - val_loss: 18.0164\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0243 - val_loss: 18.2702\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0315 - val_loss: 18.3430\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4340 - val_loss: 18.3532\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7806 - val_loss: 18.4069\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6603 - val_loss: 18.6501\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1016 - val_loss: 18.7076\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1211 - val_loss: 18.6395\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1371 - val_loss: 18.9211\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9532 - val_loss: 18.8988\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6489 - val_loss: 18.7424\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4699 - val_loss: 18.8597\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4214 - val_loss: 19.0506\n",
      "18/18 [==============================] - 0s 941us/step\n",
      "2/2 [==============================] - 0s 631us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 866us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 883us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 841us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 792us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 534us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 50ms/step - loss: 20.6396 - val_loss: 28.6290\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.2131 - val_loss: 24.3355\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.6095 - val_loss: 22.2281\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.6583 - val_loss: 21.1066\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.9814 - val_loss: 20.4981\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.5318 - val_loss: 20.0703\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.3497 - val_loss: 20.1364\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9412 - val_loss: 19.9340\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.7228 - val_loss: 20.1553\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.7953 - val_loss: 20.0274\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.9809 - val_loss: 19.9676\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.6631 - val_loss: 19.5669\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8140 - val_loss: 19.4168\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2748 - val_loss: 19.8887\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7258 - val_loss: 19.6776\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5374 - val_loss: 19.6677\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4145 - val_loss: 19.9565\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4278 - val_loss: 19.9066\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2743 - val_loss: 19.5909\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6455 - val_loss: 19.8912\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8394 - val_loss: 19.8443\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5836 - val_loss: 20.1086\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6073 - val_loss: 19.8605\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2926 - val_loss: 20.3547\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2908 - val_loss: 19.8982\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2112 - val_loss: 19.3584\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4062 - val_loss: 19.6517\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0044 - val_loss: 20.1566\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4934 - val_loss: 20.6532\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9188 - val_loss: 20.3448\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5946 - val_loss: 19.6112\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2096 - val_loss: 21.0955\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4952 - val_loss: 19.6534\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4843 - val_loss: 20.9987\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.8654 - val_loss: 20.9518\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3269 - val_loss: 20.3538\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9194 - val_loss: 21.0105\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0142 - val_loss: 20.3520\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7504 - val_loss: 19.8955\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4449 - val_loss: 20.5170\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3220 - val_loss: 20.5759\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4583 - val_loss: 20.5517\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3397 - val_loss: 21.0501\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2567 - val_loss: 21.6195\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5456 - val_loss: 21.0013\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3472 - val_loss: 21.6305\n",
      "18/18 [==============================] - 0s 873us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 643us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 828us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 876us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 863us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 872us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 47ms/step - loss: 20.5986 - val_loss: 27.8833\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 18.7898 - val_loss: 26.1414\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.8208 - val_loss: 24.9773\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.2056 - val_loss: 24.0253\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.5076 - val_loss: 23.2159\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.7381 - val_loss: 22.2756\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.9561 - val_loss: 21.4812\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.3089 - val_loss: 20.6706\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.0778 - val_loss: 19.9792\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.9754 - val_loss: 19.3169\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.6714 - val_loss: 18.7801\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.0458 - val_loss: 18.4453\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9340 - val_loss: 18.0597\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.8186 - val_loss: 17.9902\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6789 - val_loss: 17.8798\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7174 - val_loss: 17.8685\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3034 - val_loss: 17.9308\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.5509 - val_loss: 17.8272\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.9916 - val_loss: 17.8262\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5312 - val_loss: 17.8231\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8212 - val_loss: 17.8823\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6171 - val_loss: 17.7408\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4467 - val_loss: 17.7113\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3872 - val_loss: 17.7382\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1791 - val_loss: 17.7291\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2975 - val_loss: 17.6861\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4812 - val_loss: 17.8061\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1153 - val_loss: 17.7513\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4233 - val_loss: 17.8753\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3989 - val_loss: 18.0616\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4923 - val_loss: 18.1138\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7373 - val_loss: 17.8540\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7666 - val_loss: 17.7147\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4748 - val_loss: 17.7040\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2362 - val_loss: 18.0168\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3398 - val_loss: 18.4780\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3274 - val_loss: 18.6406\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0732 - val_loss: 18.4922\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6529 - val_loss: 18.4314\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4173 - val_loss: 18.7653\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0436 - val_loss: 18.6297\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.1439 - val_loss: 18.7949\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4296 - val_loss: 18.8927\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4400 - val_loss: 18.9962\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1464 - val_loss: 19.1244\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6626 - val_loss: 19.3537\n",
      "18/18 [==============================] - 0s 779us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 754us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 768us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 854us/step\n",
      "Executing 9bd58418 iter 9\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 50ms/step - loss: 22.3413 - val_loss: 27.7913\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 18.5527 - val_loss: 24.1292\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.8101 - val_loss: 21.9074\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.9969 - val_loss: 20.4652\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.3318 - val_loss: 19.5354\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.5582 - val_loss: 18.7086\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8637 - val_loss: 18.1726\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5041 - val_loss: 17.7097\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1023 - val_loss: 17.4430\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0387 - val_loss: 17.2334\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8309 - val_loss: 16.9751\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5840 - val_loss: 16.5783\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2342 - val_loss: 16.4574\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8047 - val_loss: 16.4927\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1258 - val_loss: 16.1501\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7425 - val_loss: 15.7800\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9752 - val_loss: 15.8062\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8781 - val_loss: 16.0143\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4350 - val_loss: 15.8790\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3497 - val_loss: 15.6909\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3440 - val_loss: 15.5809\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7753 - val_loss: 15.6092\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1522 - val_loss: 15.3464\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9982 - val_loss: 15.4621\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0095 - val_loss: 15.4902\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6370 - val_loss: 15.2247\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7088 - val_loss: 15.1673\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6554 - val_loss: 15.7991\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0495 - val_loss: 15.5345\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2090 - val_loss: 15.2393\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3695 - val_loss: 14.9090\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.2448 - val_loss: 15.2294\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3021 - val_loss: 15.0533\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6528 - val_loss: 15.3313\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0108 - val_loss: 15.1440\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1912 - val_loss: 15.3091\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.4978 - val_loss: 15.7340\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7068 - val_loss: 15.4412\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6642 - val_loss: 14.9520\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7391 - val_loss: 15.3455\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0500 - val_loss: 15.1266\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.9054 - val_loss: 15.3605\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0339 - val_loss: 15.6875\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3623 - val_loss: 15.7680\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.5078 - val_loss: 15.5637\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6208 - val_loss: 15.7083\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.8041 - val_loss: 15.4481\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0144 - val_loss: 15.6735\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0568 - val_loss: 15.5726\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2452 - val_loss: 15.7188\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0856 - val_loss: 15.8123\n",
      "18/18 [==============================] - 0s 867us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 421us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 878us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 884us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 901us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 19s 56ms/step - loss: 18.6150 - val_loss: 26.1601\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.4949 - val_loss: 24.1178\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.0460 - val_loss: 21.9119\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.7891 - val_loss: 19.9469\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.5853 - val_loss: 18.4415\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4761 - val_loss: 17.2467\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7573 - val_loss: 16.7153\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2355 - val_loss: 16.4086\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1327 - val_loss: 16.2511\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7725 - val_loss: 16.3311\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3074 - val_loss: 16.1867\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0105 - val_loss: 16.1146\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9649 - val_loss: 15.9295\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2775 - val_loss: 15.8454\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3124 - val_loss: 15.8198\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9039 - val_loss: 15.5756\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8690 - val_loss: 15.6801\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6708 - val_loss: 15.6562\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6562 - val_loss: 15.3478\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4380 - val_loss: 15.2768\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9629 - val_loss: 15.1696\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7283 - val_loss: 15.0458\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7311 - val_loss: 15.0772\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.3480 - val_loss: 15.3613\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.5252 - val_loss: 15.0100\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0689 - val_loss: 15.1251\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0609 - val_loss: 15.3118\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.8000 - val_loss: 15.4614\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.5729 - val_loss: 15.5625\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.3729 - val_loss: 15.4828\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.2461 - val_loss: 15.5820\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.3940 - val_loss: 15.9986\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.1406 - val_loss: 15.7667\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.8813 - val_loss: 15.6816\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.6330 - val_loss: 16.2088\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.8132 - val_loss: 16.1392\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.8155 - val_loss: 16.4422\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.4883 - val_loss: 16.4250\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.3295 - val_loss: 16.5398\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.4084 - val_loss: 16.5193\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.1705 - val_loss: 16.7634\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.1774 - val_loss: 16.0957\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 4.9712 - val_loss: 17.0710\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.0077 - val_loss: 16.9784\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 4.9853 - val_loss: 16.9318\n",
      "18/18 [==============================] - 0s 882us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 932us/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "19/19 [==============================] - 0s 931us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 792us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 906us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 54ms/step - loss: 21.1332 - val_loss: 25.3929\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.1292 - val_loss: 22.2649\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.2919 - val_loss: 20.3347\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.2041 - val_loss: 18.9437\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.3897 - val_loss: 18.2267\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.8235 - val_loss: 17.5154\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.7583 - val_loss: 17.2941\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4489 - val_loss: 17.2519\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.1510 - val_loss: 17.2167\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.0739 - val_loss: 16.9571\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9092 - val_loss: 17.0689\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2985 - val_loss: 16.5367\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8685 - val_loss: 16.2019\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7021 - val_loss: 16.1047\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3842 - val_loss: 15.9062\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1326 - val_loss: 15.2938\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6506 - val_loss: 15.4282\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6863 - val_loss: 15.5012\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4796 - val_loss: 14.9467\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1647 - val_loss: 14.8380\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9965 - val_loss: 14.7433\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9805 - val_loss: 14.7886\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9402 - val_loss: 14.7809\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3922 - val_loss: 14.5872\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2921 - val_loss: 13.9731\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1330 - val_loss: 14.3010\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0744 - val_loss: 14.3291\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9460 - val_loss: 14.6438\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8204 - val_loss: 14.1139\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.5206 - val_loss: 14.5292\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6789 - val_loss: 14.0163\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6076 - val_loss: 13.9602\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6510 - val_loss: 14.0182\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.3944 - val_loss: 13.6856\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0428 - val_loss: 14.2434\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.3481 - val_loss: 13.9803\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.2389 - val_loss: 14.2216\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.7615 - val_loss: 13.9510\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.8834 - val_loss: 13.7920\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.1517 - val_loss: 13.7955\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.8084 - val_loss: 14.2598\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.6511 - val_loss: 13.6176\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.5871 - val_loss: 13.8772\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.4226 - val_loss: 14.2597\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.2735 - val_loss: 14.0004\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.4896 - val_loss: 14.1612\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.2857 - val_loss: 14.0104\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.9032 - val_loss: 13.9753\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.3419 - val_loss: 13.8055\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.8726 - val_loss: 13.5539\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.3883 - val_loss: 13.8218\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.9977 - val_loss: 13.6736\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.7010 - val_loss: 14.1524\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.6350 - val_loss: 13.8161\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.7808 - val_loss: 14.3486\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.4913 - val_loss: 14.0406\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.0021 - val_loss: 14.0166\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.6135 - val_loss: 13.7493\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.7193 - val_loss: 13.7622\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.7269 - val_loss: 14.2954\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.8323 - val_loss: 14.1719\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.5886 - val_loss: 13.8117\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.3882 - val_loss: 13.7433\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.6511 - val_loss: 13.8682\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.3558 - val_loss: 13.6144\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.7211 - val_loss: 14.2950\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.3514 - val_loss: 13.6099\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 4.9819 - val_loss: 14.6583\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.3012 - val_loss: 14.1147\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 5.0122 - val_loss: 14.0551\n",
      "18/18 [==============================] - 0s 913us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 861us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 986us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 870us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 863us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 48ms/step - loss: 23.5062 - val_loss: 28.7866\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 18.4270 - val_loss: 25.0274\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.7923 - val_loss: 22.9804\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.8867 - val_loss: 21.4725\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.4824 - val_loss: 20.1068\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.8267 - val_loss: 18.8084\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.7064 - val_loss: 18.0320\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.3842 - val_loss: 17.6200\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.2479 - val_loss: 16.9909\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.0875 - val_loss: 16.7948\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3861 - val_loss: 16.5760\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7775 - val_loss: 16.5362\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4459 - val_loss: 16.3007\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7856 - val_loss: 16.1819\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2810 - val_loss: 16.1887\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1343 - val_loss: 16.0086\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3560 - val_loss: 15.9260\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5692 - val_loss: 15.9647\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6231 - val_loss: 15.6835\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2920 - val_loss: 15.6140\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.4763 - val_loss: 15.2948\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6104 - val_loss: 15.5393\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9975 - val_loss: 15.5963\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.5532 - val_loss: 15.7973\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.9982 - val_loss: 15.6565\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4382 - val_loss: 15.4113\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1391 - val_loss: 15.3594\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.9519 - val_loss: 15.7448\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7501 - val_loss: 15.6134\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.5791 - val_loss: 15.8405\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3532 - val_loss: 15.8877\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.4665 - val_loss: 16.2392\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.4637 - val_loss: 16.0096\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.4851 - val_loss: 15.3494\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2713 - val_loss: 15.9631\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3285 - val_loss: 16.2530\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8280 - val_loss: 16.3514\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2891 - val_loss: 16.0016\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.4519 - val_loss: 16.3861\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.1276 - val_loss: 16.5412\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3746 - val_loss: 16.2854\n",
      "18/18 [==============================] - 0s 783us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 716us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 866us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 742us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 732us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 584us/step\n",
      "Executing d7101242 iter 10\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 52ms/step - loss: 19.1026 - val_loss: 24.3364\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.3876 - val_loss: 21.6621\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.6404 - val_loss: 19.1112\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.1514 - val_loss: 17.0727\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.2264 - val_loss: 15.6990\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.5632 - val_loss: 14.6846\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2342 - val_loss: 14.2783\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2870 - val_loss: 14.2074\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3595 - val_loss: 14.0926\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8603 - val_loss: 14.0354\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7006 - val_loss: 14.0390\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2319 - val_loss: 14.0586\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2045 - val_loss: 14.0909\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1332 - val_loss: 14.0830\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8208 - val_loss: 14.0862\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1754 - val_loss: 14.0477\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8030 - val_loss: 14.1177\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1880 - val_loss: 14.0747\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4060 - val_loss: 14.0075\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4108 - val_loss: 13.9372\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8711 - val_loss: 14.1486\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6251 - val_loss: 14.2576\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5614 - val_loss: 14.0479\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4529 - val_loss: 14.1429\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3425 - val_loss: 14.2425\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0901 - val_loss: 14.1506\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3030 - val_loss: 14.3093\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1613 - val_loss: 14.0970\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3398 - val_loss: 14.4187\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1900 - val_loss: 14.3229\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8242 - val_loss: 14.2883\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2998 - val_loss: 14.2432\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1443 - val_loss: 14.2545\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6602 - val_loss: 14.3554\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0101 - val_loss: 14.3112\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0477 - val_loss: 14.4073\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9048 - val_loss: 14.4152\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6814 - val_loss: 14.4000\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8300 - val_loss: 14.2511\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4253 - val_loss: 14.4531\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 941us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 902us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 880us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 852us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 909us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 55ms/step - loss: 18.0342 - val_loss: 24.1625\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.4011 - val_loss: 21.3311\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.7636 - val_loss: 18.6627\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.2689 - val_loss: 16.9978\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3619 - val_loss: 16.0872\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7260 - val_loss: 15.2561\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2590 - val_loss: 14.8921\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0377 - val_loss: 14.7591\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.8792 - val_loss: 14.5318\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5912 - val_loss: 14.5643\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2941 - val_loss: 14.5235\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2629 - val_loss: 14.3968\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4866 - val_loss: 14.2025\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8837 - val_loss: 14.1396\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9830 - val_loss: 13.9619\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7963 - val_loss: 13.9996\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4536 - val_loss: 14.0795\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3650 - val_loss: 13.9182\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3601 - val_loss: 13.9282\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2596 - val_loss: 14.0303\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1273 - val_loss: 13.9296\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3102 - val_loss: 13.8390\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0431 - val_loss: 13.6598\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2343 - val_loss: 14.0057\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8439 - val_loss: 14.0306\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9262 - val_loss: 13.7620\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5175 - val_loss: 13.9612\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6398 - val_loss: 13.7979\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7994 - val_loss: 14.2267\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5985 - val_loss: 14.1531\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4504 - val_loss: 14.0054\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6426 - val_loss: 13.9311\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2632 - val_loss: 13.9280\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9567 - val_loss: 14.1889\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5040 - val_loss: 14.0240\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2725 - val_loss: 14.2233\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2576 - val_loss: 14.2064\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3523 - val_loss: 14.2864\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1399 - val_loss: 14.2487\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1466 - val_loss: 14.4922\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1510 - val_loss: 14.1889\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8663 - val_loss: 14.4759\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7962 - val_loss: 14.5278\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 901us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 951us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 876us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 928us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 51ms/step - loss: 17.4296 - val_loss: 21.2371\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.3841 - val_loss: 18.9784\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.0784 - val_loss: 17.5926\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.4669 - val_loss: 16.6693\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3326 - val_loss: 16.0363\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3774 - val_loss: 15.6366\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9490 - val_loss: 15.2923\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5315 - val_loss: 14.9627\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7743 - val_loss: 14.9158\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5078 - val_loss: 14.7355\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3307 - val_loss: 14.6604\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2509 - val_loss: 14.4917\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4747 - val_loss: 14.3866\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9704 - val_loss: 14.3851\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3378 - val_loss: 14.3215\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2813 - val_loss: 14.2049\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1855 - val_loss: 14.3310\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3111 - val_loss: 14.3912\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9152 - val_loss: 14.2116\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8530 - val_loss: 14.4409\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9409 - val_loss: 14.5023\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9284 - val_loss: 14.7965\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7340 - val_loss: 14.5689\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8515 - val_loss: 14.9069\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6423 - val_loss: 14.7052\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3531 - val_loss: 14.8080\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6414 - val_loss: 15.1916\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2895 - val_loss: 15.0977\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0881 - val_loss: 15.6527\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1067 - val_loss: 15.6135\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2765 - val_loss: 15.4565\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0391 - val_loss: 16.0644\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7800 - val_loss: 15.6186\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1693 - val_loss: 16.1035\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5089 - val_loss: 16.2071\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2834 - val_loss: 16.1515\n",
      "18/18 [==============================] - 0s 859us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 901us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 875us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 853us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 884us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 910us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 48ms/step - loss: 19.7780 - val_loss: 27.3947\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.7895 - val_loss: 25.6287\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 16.3463 - val_loss: 24.2329\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.7051 - val_loss: 22.7170\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.2336 - val_loss: 21.1347\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13.3345 - val_loss: 19.7868\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.5164 - val_loss: 19.0102\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.4491 - val_loss: 18.1767\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.1625 - val_loss: 17.3175\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8164 - val_loss: 17.1391\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4489 - val_loss: 16.8094\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3911 - val_loss: 16.7145\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6378 - val_loss: 16.4171\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3034 - val_loss: 16.3234\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.2880 - val_loss: 15.9694\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8904 - val_loss: 15.7736\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6684 - val_loss: 15.7537\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7165 - val_loss: 15.7993\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3010 - val_loss: 15.6394\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0285 - val_loss: 15.7266\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3809 - val_loss: 15.5648\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2361 - val_loss: 15.5857\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4288 - val_loss: 15.3277\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.8208 - val_loss: 15.5002\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3235 - val_loss: 15.6938\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.4220 - val_loss: 15.2615\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9125 - val_loss: 15.4359\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9697 - val_loss: 15.1902\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1884 - val_loss: 15.8452\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7364 - val_loss: 15.3439\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0832 - val_loss: 15.4691\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1368 - val_loss: 15.2782\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6599 - val_loss: 15.1829\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0958 - val_loss: 15.4363\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2633 - val_loss: 15.3022\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7928 - val_loss: 15.4732\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6648 - val_loss: 15.5425\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7700 - val_loss: 15.7135\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1585 - val_loss: 15.3863\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1605 - val_loss: 15.4845\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5593 - val_loss: 15.5215\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0904 - val_loss: 16.0725\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9113 - val_loss: 15.7895\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9186 - val_loss: 15.8790\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1049 - val_loss: 15.6069\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5659 - val_loss: 15.8899\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8383 - val_loss: 15.6612\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9383 - val_loss: 15.4902\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3067 - val_loss: 15.3333\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.2780 - val_loss: 15.4056\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.6551 - val_loss: 15.4793\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2411 - val_loss: 15.7320\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4778 - val_loss: 15.4775\n",
      "18/18 [==============================] - 0s 815us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 713us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 820us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 786us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 908us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 801us/step\n",
      "Executing 3832cbd6 iter 11\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 51ms/step - loss: 18.3629 - val_loss: 22.7049\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.9425 - val_loss: 19.4929\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.0516 - val_loss: 16.7286\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9316 - val_loss: 15.5747\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4359 - val_loss: 14.8705\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7757 - val_loss: 14.2262\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.6083 - val_loss: 13.9919\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.2719 - val_loss: 13.8404\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1562 - val_loss: 13.6690\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7792 - val_loss: 13.6232\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0229 - val_loss: 13.6001\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0452 - val_loss: 13.6655\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5791 - val_loss: 13.6135\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5137 - val_loss: 13.4967\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3180 - val_loss: 13.4829\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3986 - val_loss: 13.5162\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3336 - val_loss: 13.4636\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5617 - val_loss: 13.3870\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3092 - val_loss: 13.3988\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9370 - val_loss: 13.3898\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7212 - val_loss: 13.4151\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0754 - val_loss: 13.4715\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8858 - val_loss: 13.3864\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0579 - val_loss: 13.4465\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3823 - val_loss: 13.4293\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9763 - val_loss: 13.3844\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0887 - val_loss: 13.4567\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0344 - val_loss: 13.3956\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0218 - val_loss: 13.5303\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4596 - val_loss: 13.4000\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0659 - val_loss: 13.3958\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0425 - val_loss: 13.3079\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9102 - val_loss: 13.3184\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5779 - val_loss: 13.4005\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7394 - val_loss: 13.3711\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0194 - val_loss: 13.3797\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2133 - val_loss: 13.4175\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8144 - val_loss: 13.3850\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6389 - val_loss: 13.4141\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5259 - val_loss: 13.4774\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7423 - val_loss: 13.4694\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3716 - val_loss: 13.5411\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6567 - val_loss: 13.5813\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3758 - val_loss: 13.4862\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2440 - val_loss: 13.4161\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3577 - val_loss: 13.4410\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3552 - val_loss: 13.4764\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6292 - val_loss: 13.3614\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2300 - val_loss: 13.3353\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7378 - val_loss: 13.4356\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1150 - val_loss: 13.3258\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1145 - val_loss: 13.4244\n",
      "18/18 [==============================] - 0s 892us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 920us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 853us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 990us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 81ms/step - loss: 18.7727 - val_loss: 26.6592\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.0950 - val_loss: 25.6005\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.4621 - val_loss: 24.3045\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.5204 - val_loss: 22.4784\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.1326 - val_loss: 20.2411\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.4938 - val_loss: 17.8410\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.1622 - val_loss: 16.4634\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5005 - val_loss: 15.5553\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1537 - val_loss: 15.0273\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9073 - val_loss: 14.7168\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5901 - val_loss: 14.3895\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3786 - val_loss: 14.2413\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6730 - val_loss: 13.9758\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2605 - val_loss: 13.8813\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1252 - val_loss: 13.7534\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0803 - val_loss: 13.6922\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8840 - val_loss: 13.6526\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2534 - val_loss: 13.5647\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8569 - val_loss: 13.4882\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9736 - val_loss: 13.4169\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7942 - val_loss: 13.4903\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8798 - val_loss: 13.5416\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7671 - val_loss: 13.3286\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7189 - val_loss: 13.4301\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5857 - val_loss: 13.3581\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6009 - val_loss: 13.1460\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4160 - val_loss: 13.2022\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4265 - val_loss: 13.2055\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5875 - val_loss: 13.2900\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1134 - val_loss: 13.2278\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4313 - val_loss: 13.1908\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5929 - val_loss: 13.2135\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1850 - val_loss: 13.1441\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9987 - val_loss: 13.1207\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0753 - val_loss: 13.0931\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3961 - val_loss: 13.0428\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3844 - val_loss: 13.1321\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1767 - val_loss: 13.1698\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9750 - val_loss: 13.0428\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0046 - val_loss: 12.9993\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9766 - val_loss: 13.0099\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5328 - val_loss: 13.1474\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2020 - val_loss: 13.0871\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7264 - val_loss: 13.0248\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7287 - val_loss: 12.8531\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5702 - val_loss: 12.8173\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8112 - val_loss: 12.8209\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5442 - val_loss: 12.7962\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6341 - val_loss: 12.7500\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7303 - val_loss: 12.8663\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4648 - val_loss: 12.7005\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5264 - val_loss: 12.7696\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4447 - val_loss: 12.6751\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2304 - val_loss: 12.8527\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5594 - val_loss: 12.9417\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5278 - val_loss: 12.7722\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3979 - val_loss: 12.8917\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3494 - val_loss: 12.9054\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1916 - val_loss: 12.7802\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2217 - val_loss: 12.7875\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0729 - val_loss: 12.8342\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0520 - val_loss: 12.7462\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1032 - val_loss: 12.8658\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9966 - val_loss: 12.9579\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9161 - val_loss: 12.7896\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0867 - val_loss: 12.7165\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4607 - val_loss: 12.7396\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3003 - val_loss: 12.8672\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9364 - val_loss: 12.8435\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3830 - val_loss: 12.8633\n",
      "Epoch 71/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9579 - val_loss: 12.7582\n",
      "Epoch 72/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8387 - val_loss: 12.8749\n",
      "Epoch 73/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1245 - val_loss: 12.7830\n",
      "18/18 [==============================] - 0s 840us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 905us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 763us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 899us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 924us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 51ms/step - loss: 21.8928 - val_loss: 27.5830\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.1982 - val_loss: 22.6703\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.0099 - val_loss: 20.0646\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.0349 - val_loss: 18.5745\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.7469 - val_loss: 17.5951\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.4852 - val_loss: 16.9502\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2780 - val_loss: 16.4361\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2825 - val_loss: 15.9783\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8640 - val_loss: 15.9297\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8734 - val_loss: 15.6393\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9883 - val_loss: 15.4170\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0397 - val_loss: 15.0848\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6474 - val_loss: 14.8481\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7486 - val_loss: 14.7008\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6109 - val_loss: 14.5643\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0879 - val_loss: 14.4572\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2997 - val_loss: 14.5879\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2937 - val_loss: 14.2290\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2356 - val_loss: 14.1052\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7415 - val_loss: 14.2307\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9970 - val_loss: 14.0359\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9291 - val_loss: 14.1155\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9554 - val_loss: 14.1270\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5209 - val_loss: 14.2791\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9189 - val_loss: 13.8999\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4913 - val_loss: 13.7901\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7551 - val_loss: 14.0559\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6366 - val_loss: 13.9669\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4186 - val_loss: 14.2655\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7141 - val_loss: 14.1327\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6244 - val_loss: 13.9922\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4007 - val_loss: 14.1883\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3701 - val_loss: 13.8433\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3240 - val_loss: 13.9393\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3734 - val_loss: 14.1801\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5334 - val_loss: 14.0366\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2765 - val_loss: 14.1181\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4582 - val_loss: 13.9869\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3833 - val_loss: 14.0228\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2990 - val_loss: 14.0164\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0734 - val_loss: 14.0439\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3219 - val_loss: 13.9662\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3005 - val_loss: 14.3912\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0208 - val_loss: 14.1402\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2296 - val_loss: 14.0107\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5913 - val_loss: 14.2119\n",
      "18/18 [==============================] - 0s 883us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 947us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 805us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 890us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 849us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 49ms/step - loss: 18.8732 - val_loss: 27.4105\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 17.3890 - val_loss: 24.8948\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.8569 - val_loss: 22.3945\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6382 - val_loss: 19.9653\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.5286 - val_loss: 18.4434\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.9598 - val_loss: 17.3289\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3445 - val_loss: 16.7975\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.0189 - val_loss: 16.4465\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.6965 - val_loss: 16.0753\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.4448 - val_loss: 15.7043\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7731 - val_loss: 15.5597\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9449 - val_loss: 15.3277\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7394 - val_loss: 15.1554\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6919 - val_loss: 15.3084\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.7076 - val_loss: 15.0009\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.1278 - val_loss: 15.0152\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3207 - val_loss: 15.0093\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6646 - val_loss: 14.9117\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1449 - val_loss: 14.8470\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2227 - val_loss: 14.7911\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.5067 - val_loss: 14.7878\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4509 - val_loss: 14.9806\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1600 - val_loss: 14.9328\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3883 - val_loss: 15.0159\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3600 - val_loss: 15.1208\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8962 - val_loss: 14.7942\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6238 - val_loss: 14.8152\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5555 - val_loss: 14.7608\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6989 - val_loss: 14.9803\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7606 - val_loss: 14.7239\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8311 - val_loss: 14.6286\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3273 - val_loss: 14.6625\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.6385 - val_loss: 14.7454\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6674 - val_loss: 14.8438\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9677 - val_loss: 14.8177\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2976 - val_loss: 14.9184\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.1331 - val_loss: 14.9333\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4143 - val_loss: 14.9045\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8053 - val_loss: 14.6998\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3858 - val_loss: 14.7662\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8599 - val_loss: 14.7058\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3555 - val_loss: 15.1018\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.5016 - val_loss: 14.8857\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.0805 - val_loss: 14.8765\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.0018 - val_loss: 14.7202\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2008 - val_loss: 14.8338\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2946 - val_loss: 14.9254\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8982 - val_loss: 14.7952\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1428 - val_loss: 14.6621\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9045 - val_loss: 14.9049\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2466 - val_loss: 14.6594\n",
      "18/18 [==============================] - 0s 777us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 712us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 810us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 834us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 638us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 772us/step\n",
      "Executing 3df87a13 iter 12\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 52ms/step - loss: 20.9532 - val_loss: 27.8082\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.4992 - val_loss: 25.0115\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.5917 - val_loss: 22.7944\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.5451 - val_loss: 20.9255\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.3303 - val_loss: 19.2798\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.4912 - val_loss: 17.8747\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.9847 - val_loss: 16.9694\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2606 - val_loss: 16.2159\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.8981 - val_loss: 15.6908\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5859 - val_loss: 15.5946\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4770 - val_loss: 15.3580\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1444 - val_loss: 15.3160\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0765 - val_loss: 15.1436\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7050 - val_loss: 15.1147\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6915 - val_loss: 15.3939\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5470 - val_loss: 15.1372\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1937 - val_loss: 15.2056\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1704 - val_loss: 15.2697\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2840 - val_loss: 15.3590\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0303 - val_loss: 15.2901\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8633 - val_loss: 15.3837\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0891 - val_loss: 15.3867\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7020 - val_loss: 15.4085\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6972 - val_loss: 15.4535\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6807 - val_loss: 15.3889\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6292 - val_loss: 15.3224\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5106 - val_loss: 15.2682\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2348 - val_loss: 15.4820\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5118 - val_loss: 15.6182\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1761 - val_loss: 15.8926\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1202 - val_loss: 15.8732\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2682 - val_loss: 15.8447\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1449 - val_loss: 15.7967\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0890 - val_loss: 15.7668\n",
      "18/18 [==============================] - 0s 921us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 920us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 880us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 879us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 822us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 55ms/step - loss: 18.6098 - val_loss: 25.7644\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.6785 - val_loss: 24.0472\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.5782 - val_loss: 21.6120\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.0382 - val_loss: 19.1318\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.6796 - val_loss: 17.3923\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.8192 - val_loss: 15.9418\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9722 - val_loss: 15.2390\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4732 - val_loss: 14.9978\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0349 - val_loss: 14.8234\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.7868 - val_loss: 14.7548\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4052 - val_loss: 14.7613\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2149 - val_loss: 14.7220\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2220 - val_loss: 14.4377\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8063 - val_loss: 14.4885\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6821 - val_loss: 14.4848\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6776 - val_loss: 14.4165\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2957 - val_loss: 14.5224\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3457 - val_loss: 14.6519\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9460 - val_loss: 14.4027\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1042 - val_loss: 14.4149\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0439 - val_loss: 14.7309\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9627 - val_loss: 14.6802\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8558 - val_loss: 14.6580\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8305 - val_loss: 14.9058\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8910 - val_loss: 14.8807\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5356 - val_loss: 14.7352\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2878 - val_loss: 14.7307\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.4058 - val_loss: 14.8494\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2551 - val_loss: 15.2080\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0116 - val_loss: 15.3642\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0505 - val_loss: 15.1811\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.2999 - val_loss: 15.0389\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9564 - val_loss: 15.2120\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6729 - val_loss: 15.2366\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9729 - val_loss: 15.3906\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8271 - val_loss: 15.7515\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.9702 - val_loss: 15.6348\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.0208 - val_loss: 15.4199\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.3850 - val_loss: 15.2957\n",
      "18/18 [==============================] - 0s 931us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 645us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 933us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 645us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 874us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 922us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 50ms/step - loss: 22.9387 - val_loss: 28.5700\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 18.8231 - val_loss: 24.6567\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.1940 - val_loss: 22.2010\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.6482 - val_loss: 20.7225\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.0188 - val_loss: 19.7749\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.3813 - val_loss: 18.9167\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.9598 - val_loss: 18.2319\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.5751 - val_loss: 17.5116\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.6434 - val_loss: 17.1376\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3327 - val_loss: 16.7352\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4106 - val_loss: 16.4658\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.1270 - val_loss: 16.1927\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1710 - val_loss: 15.6341\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3006 - val_loss: 15.4060\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9975 - val_loss: 15.2244\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3931 - val_loss: 15.0353\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4851 - val_loss: 15.0622\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3972 - val_loss: 14.9800\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5202 - val_loss: 14.7284\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9692 - val_loss: 14.7334\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0241 - val_loss: 14.6733\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0562 - val_loss: 14.6848\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8954 - val_loss: 14.5995\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6011 - val_loss: 14.8007\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7075 - val_loss: 14.4685\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3623 - val_loss: 14.3947\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7226 - val_loss: 14.7277\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2921 - val_loss: 14.6293\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5538 - val_loss: 14.8248\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5462 - val_loss: 14.9429\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2383 - val_loss: 14.7272\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1905 - val_loss: 14.6925\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0613 - val_loss: 14.5808\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2538 - val_loss: 14.7452\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1366 - val_loss: 15.4235\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3105 - val_loss: 15.0045\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1091 - val_loss: 14.8839\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0922 - val_loss: 15.0274\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1697 - val_loss: 14.9152\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9374 - val_loss: 14.7947\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8063 - val_loss: 15.3247\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6924 - val_loss: 15.1639\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5817 - val_loss: 15.8137\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5219 - val_loss: 15.6648\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8502 - val_loss: 15.6065\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8270 - val_loss: 15.9969\n",
      "18/18 [==============================] - 0s 875us/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 898us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 900us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 699us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 14s 49ms/step - loss: 18.0124 - val_loss: 24.5040\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 15.9397 - val_loss: 21.9074\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14.6621 - val_loss: 19.6202\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.9669 - val_loss: 18.8008\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12.9182 - val_loss: 18.3531\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.3801 - val_loss: 17.4997\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.7953 - val_loss: 17.4003\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9919 - val_loss: 17.2907\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.9527 - val_loss: 17.1948\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.3352 - val_loss: 16.9871\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 11.3845 - val_loss: 16.5704\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6927 - val_loss: 16.3203\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9875 - val_loss: 16.1340\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.2771 - val_loss: 16.2015\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.6067 - val_loss: 16.0664\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 10.3575 - val_loss: 16.0284\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.9237 - val_loss: 15.9078\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.7562 - val_loss: 15.7589\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5756 - val_loss: 15.5695\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7643 - val_loss: 15.5601\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.1220 - val_loss: 15.6973\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2112 - val_loss: 15.7070\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0515 - val_loss: 15.5092\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.8975 - val_loss: 15.3894\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.3544 - val_loss: 15.4368\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0623 - val_loss: 15.1785\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 9.2570 - val_loss: 15.3290\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7329 - val_loss: 15.1462\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3595 - val_loss: 15.6638\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8079 - val_loss: 15.5078\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7435 - val_loss: 15.3756\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8032 - val_loss: 15.2933\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.9559 - val_loss: 15.2392\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.1840 - val_loss: 15.3076\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3813 - val_loss: 15.4105\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7139 - val_loss: 15.4492\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3254 - val_loss: 15.3996\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.7438 - val_loss: 15.4255\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3861 - val_loss: 15.2790\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1932 - val_loss: 15.1982\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8355 - val_loss: 15.1727\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.9691 - val_loss: 15.1088\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.5867 - val_loss: 15.0279\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.0663 - val_loss: 15.4912\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.9114 - val_loss: 15.1089\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6016 - val_loss: 15.2617\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.2017 - val_loss: 15.1113\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.3725 - val_loss: 15.2763\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8052 - val_loss: 15.5170\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.3137 - val_loss: 15.4347\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.6908 - val_loss: 15.3207\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 8.0711 - val_loss: 15.3647\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2959 - val_loss: 15.2562\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8905 - val_loss: 15.1590\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.5425 - val_loss: 15.5143\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.8747 - val_loss: 15.2385\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.4378 - val_loss: 15.3439\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1085 - val_loss: 15.2946\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.6993 - val_loss: 15.1075\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.7183 - val_loss: 14.9312\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.8325 - val_loss: 15.1096\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.6769 - val_loss: 15.0847\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.2190 - val_loss: 15.4943\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2393 - val_loss: 15.2851\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 6.7473 - val_loss: 15.1898\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2437 - val_loss: 15.1706\n",
      "Epoch 67/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3339 - val_loss: 15.2701\n",
      "Epoch 68/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3696 - val_loss: 15.3883\n",
      "Epoch 69/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0717 - val_loss: 15.1699\n",
      "Epoch 70/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.3903 - val_loss: 15.4216\n",
      "Epoch 71/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.4432 - val_loss: 15.1935\n",
      "Epoch 72/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2501 - val_loss: 15.3349\n",
      "Epoch 73/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.1590 - val_loss: 15.1717\n",
      "Epoch 74/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.8687 - val_loss: 15.2294\n",
      "Epoch 75/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.1625 - val_loss: 15.1650\n",
      "Epoch 76/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 7.0010 - val_loss: 15.4361\n",
      "Epoch 77/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.5512 - val_loss: 15.1613\n",
      "Epoch 78/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.2283 - val_loss: 15.3161\n",
      "Epoch 79/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 6.7957 - val_loss: 15.1870\n",
      "Epoch 80/200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 7.0647 - val_loss: 15.3695\n",
      "18/18 [==============================] - 0s 771us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 803us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 767us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 722us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 724us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "Executing 30ab9bad iter 13\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 51ms/step - loss: 19.5942 - val_loss: 22.8707\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.3409 - val_loss: 20.3685\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 15.5677 - val_loss: 18.0112\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.2756 - val_loss: 16.1848\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.1195 - val_loss: 14.7832\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.4742 - val_loss: 13.9790\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.9327 - val_loss: 13.6401\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.7168 - val_loss: 13.4308\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.6273 - val_loss: 13.2496\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4489 - val_loss: 13.2443\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9202 - val_loss: 13.2515\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.9762 - val_loss: 13.2025\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1725 - val_loss: 13.0700\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3914 - val_loss: 12.9700\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6033 - val_loss: 12.9136\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.5248 - val_loss: 12.9325\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3994 - val_loss: 12.8525\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2156 - val_loss: 12.9638\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4457 - val_loss: 12.8104\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4964 - val_loss: 12.9269\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1988 - val_loss: 12.8888\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5477 - val_loss: 12.9418\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2160 - val_loss: 12.8810\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.2044 - val_loss: 13.1260\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1766 - val_loss: 13.0745\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0332 - val_loss: 12.8653\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9401 - val_loss: 12.8698\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8784 - val_loss: 12.8950\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5594 - val_loss: 13.1068\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.3973 - val_loss: 13.0238\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7794 - val_loss: 13.0179\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1084 - val_loss: 12.9772\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6041 - val_loss: 12.9177\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4088 - val_loss: 12.9484\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6180 - val_loss: 13.0585\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5871 - val_loss: 13.3128\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.6873 - val_loss: 13.1064\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4179 - val_loss: 13.1554\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2900 - val_loss: 13.0528\n",
      "18/18 [==============================] - 0s 707us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 979us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 768us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 887us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 19s 57ms/step - loss: 18.5159 - val_loss: 25.9446\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.4680 - val_loss: 24.2039\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 16.1815 - val_loss: 21.8738\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.8142 - val_loss: 19.6162\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 13.5454 - val_loss: 17.8298\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.8133 - val_loss: 16.4376\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.0773 - val_loss: 15.7299\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.4739 - val_loss: 15.2949\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.1865 - val_loss: 15.1137\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0115 - val_loss: 14.9155\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.6289 - val_loss: 14.7886\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4911 - val_loss: 14.6496\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.4511 - val_loss: 14.5602\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9597 - val_loss: 14.5504\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.1965 - val_loss: 14.6134\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9430 - val_loss: 14.4597\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5918 - val_loss: 14.4809\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.9770 - val_loss: 14.5064\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7267 - val_loss: 14.4195\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8031 - val_loss: 14.4313\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5665 - val_loss: 14.5696\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.5252 - val_loss: 14.5138\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2498 - val_loss: 14.5979\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3002 - val_loss: 14.8216\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4815 - val_loss: 14.6688\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1223 - val_loss: 14.5325\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9476 - val_loss: 14.4895\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0196 - val_loss: 14.5550\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6076 - val_loss: 14.8203\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9776 - val_loss: 14.8309\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7533 - val_loss: 14.7903\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8252 - val_loss: 14.9911\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6347 - val_loss: 14.8185\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5396 - val_loss: 14.6787\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7373 - val_loss: 14.8188\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9626 - val_loss: 15.0747\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7707 - val_loss: 15.0225\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3543 - val_loss: 15.0116\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.5754 - val_loss: 14.9435\n",
      "18/18 [==============================] - 0s 979us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 920us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 994us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 971us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 55ms/step - loss: 17.4197 - val_loss: 22.8015\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.2607 - val_loss: 19.3888\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.9775 - val_loss: 17.4901\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.7080 - val_loss: 16.5040\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.6951 - val_loss: 16.0206\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.2830 - val_loss: 15.5773\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.2878 - val_loss: 15.2466\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1217 - val_loss: 14.9472\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.0799 - val_loss: 14.8862\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4988 - val_loss: 14.6438\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3870 - val_loss: 14.6440\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3474 - val_loss: 14.3463\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5874 - val_loss: 14.2354\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8859 - val_loss: 14.2389\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6531 - val_loss: 14.1203\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5778 - val_loss: 14.0315\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3657 - val_loss: 14.0418\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5039 - val_loss: 13.9790\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5400 - val_loss: 13.6930\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9600 - val_loss: 13.7208\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2474 - val_loss: 13.7689\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0700 - val_loss: 13.8304\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9433 - val_loss: 13.6664\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9367 - val_loss: 13.8061\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9382 - val_loss: 13.5331\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9610 - val_loss: 13.5031\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0351 - val_loss: 13.5355\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6881 - val_loss: 13.5159\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7051 - val_loss: 13.7122\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5907 - val_loss: 13.5886\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5240 - val_loss: 13.5000\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7240 - val_loss: 13.4370\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1967 - val_loss: 13.2343\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5997 - val_loss: 13.1736\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3002 - val_loss: 13.4590\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5923 - val_loss: 13.4091\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4825 - val_loss: 13.4036\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5429 - val_loss: 13.5122\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4658 - val_loss: 13.2956\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1477 - val_loss: 13.3113\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9708 - val_loss: 13.4889\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7940 - val_loss: 13.2962\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2148 - val_loss: 13.4274\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8798 - val_loss: 13.6276\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9127 - val_loss: 13.3685\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8142 - val_loss: 13.5258\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5221 - val_loss: 13.4918\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3134 - val_loss: 13.2382\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2552 - val_loss: 13.5060\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4672 - val_loss: 13.5822\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7188 - val_loss: 13.4855\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3808 - val_loss: 13.3464\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7736 - val_loss: 13.5265\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4003 - val_loss: 13.7088\n",
      "18/18 [==============================] - 0s 921us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 875us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 819us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "19/19 [==============================] - 0s 835us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 887us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 888us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 49ms/step - loss: 15.4317 - val_loss: 20.5798\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.5221 - val_loss: 19.0493\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.8556 - val_loss: 18.0421\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.9203 - val_loss: 17.5768\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 12.2706 - val_loss: 17.2365\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.4442 - val_loss: 16.7600\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.7213 - val_loss: 16.4696\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.4894 - val_loss: 16.2451\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3317 - val_loss: 15.8422\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.9109 - val_loss: 15.5088\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.5347 - val_loss: 15.3640\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7579 - val_loss: 15.4109\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8916 - val_loss: 15.2456\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5824 - val_loss: 15.2765\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6320 - val_loss: 15.1939\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9233 - val_loss: 15.0210\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1494 - val_loss: 15.0944\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.6002 - val_loss: 15.1610\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4120 - val_loss: 15.0727\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3856 - val_loss: 15.0604\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6278 - val_loss: 15.0801\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1612 - val_loss: 15.1721\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9774 - val_loss: 15.2305\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.3210 - val_loss: 15.1515\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.7073 - val_loss: 15.1811\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7327 - val_loss: 15.1504\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 10.0123 - val_loss: 15.1422\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4798 - val_loss: 15.0096\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8072 - val_loss: 15.3106\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4723 - val_loss: 15.2282\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.4037 - val_loss: 15.2892\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.8484 - val_loss: 15.1434\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6062 - val_loss: 15.1817\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1865 - val_loss: 15.2754\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0897 - val_loss: 15.1335\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.9844 - val_loss: 15.3351\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.2981 - val_loss: 15.4366\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6827 - val_loss: 15.4688\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.1006 - val_loss: 15.3768\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.7281 - val_loss: 15.4523\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3552 - val_loss: 15.3326\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.1751 - val_loss: 15.6582\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7132 - val_loss: 15.7380\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.8556 - val_loss: 15.8203\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 9.0652 - val_loss: 15.7115\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6172 - val_loss: 15.4719\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 8.6529 - val_loss: 15.4615\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9403 - val_loss: 15.5866\n",
      "18/18 [==============================] - 0s 789us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 809us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 893us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 838us/step\n",
      "Executing 311dd366 iter 14\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 57ms/step - loss: 21.3595 - val_loss: 24.5942\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 18.2176 - val_loss: 21.6996\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.2149 - val_loss: 19.1491\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.2019 - val_loss: 17.3623\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.2994 - val_loss: 15.9022\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.7641 - val_loss: 14.8161\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.9579 - val_loss: 14.2400\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.8792 - val_loss: 14.0407\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.9731 - val_loss: 13.7918\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1184 - val_loss: 13.8860\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7617 - val_loss: 13.9586\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0252 - val_loss: 13.8645\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.6911 - val_loss: 13.7511\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6266 - val_loss: 13.6870\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6369 - val_loss: 13.6968\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6544 - val_loss: 13.5362\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0345 - val_loss: 13.6425\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2562 - val_loss: 13.7742\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8518 - val_loss: 13.7352\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0724 - val_loss: 13.6642\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8266 - val_loss: 13.8667\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4775 - val_loss: 13.8940\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4082 - val_loss: 14.0596\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6106 - val_loss: 14.1262\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6525 - val_loss: 14.1172\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1335 - val_loss: 14.1173\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1549 - val_loss: 14.1088\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2280 - val_loss: 14.1944\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3591 - val_loss: 14.2274\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6538 - val_loss: 14.5093\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2495 - val_loss: 14.4006\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2422 - val_loss: 14.5861\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2358 - val_loss: 14.7186\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8005 - val_loss: 14.6073\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3020 - val_loss: 14.8051\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9637 - val_loss: 14.8077\n",
      "18/18 [==============================] - 0s 966us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 389us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 949us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 947us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 969us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 19s 59ms/step - loss: 18.1925 - val_loss: 25.2384\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 17.0765 - val_loss: 23.2733\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.5338 - val_loss: 20.3106\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.2079 - val_loss: 17.6204\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.5280 - val_loss: 15.7845\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7975 - val_loss: 14.5950\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2127 - val_loss: 14.2199\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0271 - val_loss: 14.1715\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5459 - val_loss: 14.0146\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5309 - val_loss: 14.1280\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3416 - val_loss: 14.2146\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0663 - val_loss: 14.2282\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9647 - val_loss: 14.1790\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6784 - val_loss: 14.2181\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3264 - val_loss: 14.4451\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6367 - val_loss: 14.3047\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0927 - val_loss: 14.5203\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3308 - val_loss: 14.8456\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 8.7951 - val_loss: 14.6296\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 8.8328 - val_loss: 14.7330\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8966 - val_loss: 14.9206\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7811 - val_loss: 14.8627\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7784 - val_loss: 14.9177\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6719 - val_loss: 15.2076\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1248 - val_loss: 15.2103\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8478 - val_loss: 15.3082\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.1623 - val_loss: 15.2408\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2727 - val_loss: 15.6183\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8580 - val_loss: 15.7159\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 55ms/step - loss: 19.4113 - val_loss: 23.8745\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.7984 - val_loss: 20.5649\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.0478 - val_loss: 18.1690\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.3486 - val_loss: 16.7239\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.4243 - val_loss: 15.8256\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7878 - val_loss: 15.0862\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.4050 - val_loss: 14.8231\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.0314 - val_loss: 14.5065\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6923 - val_loss: 14.3357\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3460 - val_loss: 14.2076\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1076 - val_loss: 14.1743\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8033 - val_loss: 13.8543\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1592 - val_loss: 13.5894\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4536 - val_loss: 13.5864\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8296 - val_loss: 13.5097\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7497 - val_loss: 13.5007\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6621 - val_loss: 13.6186\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8011 - val_loss: 13.4855\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6786 - val_loss: 13.1407\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4915 - val_loss: 13.1587\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5505 - val_loss: 13.2463\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5340 - val_loss: 13.2387\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5465 - val_loss: 13.0091\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0776 - val_loss: 13.3516\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9605 - val_loss: 12.9821\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5953 - val_loss: 13.0327\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2820 - val_loss: 13.0804\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6730 - val_loss: 13.1679\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9070 - val_loss: 13.3107\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8462 - val_loss: 13.6371\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5768 - val_loss: 13.4412\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7919 - val_loss: 13.4707\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4790 - val_loss: 13.4129\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5263 - val_loss: 13.4135\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3914 - val_loss: 13.4808\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9022 - val_loss: 13.3986\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5703 - val_loss: 13.5473\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4979 - val_loss: 13.8130\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4739 - val_loss: 13.5581\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3265 - val_loss: 13.7575\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.1508 - val_loss: 13.7704\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1044 - val_loss: 13.6601\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1438 - val_loss: 13.7649\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2977 - val_loss: 13.9774\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0218 - val_loss: 13.9686\n",
      "18/18 [==============================] - 0s 890us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 856us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 909us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 869us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 978us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 51ms/step - loss: 20.6768 - val_loss: 27.0726\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 17.9327 - val_loss: 24.0391\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.3860 - val_loss: 21.1039\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.9014 - val_loss: 18.7369\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.4487 - val_loss: 17.1108\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.4570 - val_loss: 15.9972\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.6301 - val_loss: 15.5199\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.6018 - val_loss: 15.2888\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 11.0040 - val_loss: 15.1256\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8794 - val_loss: 15.1833\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.6524 - val_loss: 15.1986\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3220 - val_loss: 15.2205\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2931 - val_loss: 15.2543\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5961 - val_loss: 15.3114\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7524 - val_loss: 15.3632\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7584 - val_loss: 15.2617\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6536 - val_loss: 15.3154\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4764 - val_loss: 15.5037\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3489 - val_loss: 15.3209\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4407 - val_loss: 15.3728\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3030 - val_loss: 15.4698\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3765 - val_loss: 15.6658\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2365 - val_loss: 15.7082\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9707 - val_loss: 15.7662\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9041 - val_loss: 15.7395\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9015 - val_loss: 15.8252\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6813 - val_loss: 15.7967\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8068 - val_loss: 15.9743\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9431 - val_loss: 15.9473\n",
      "18/18 [==============================] - 0s 844us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 763us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 851us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 726us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 819us/step\n",
      "Executing 8c95fd00 iter 15\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 56ms/step - loss: 17.3094 - val_loss: 21.1416\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.5288 - val_loss: 18.8797\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.4979 - val_loss: 17.3565\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.7980 - val_loss: 16.3302\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5108 - val_loss: 15.6037\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.2717 - val_loss: 14.9000\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.7427 - val_loss: 14.5890\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.5968 - val_loss: 14.2928\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1526 - val_loss: 14.0567\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8670 - val_loss: 14.1453\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2011 - val_loss: 14.0809\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0204 - val_loss: 14.0431\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5980 - val_loss: 13.7817\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4960 - val_loss: 13.8556\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7289 - val_loss: 13.8701\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3056 - val_loss: 13.8636\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4334 - val_loss: 13.8064\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0780 - val_loss: 13.7701\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8440 - val_loss: 13.6935\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2815 - val_loss: 13.7731\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2765 - val_loss: 13.7355\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6466 - val_loss: 13.6342\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9215 - val_loss: 13.5861\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0415 - val_loss: 13.7204\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1428 - val_loss: 13.6482\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5789 - val_loss: 13.6913\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8767 - val_loss: 13.7076\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6473 - val_loss: 13.7281\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4267 - val_loss: 14.0106\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5457 - val_loss: 13.9312\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5350 - val_loss: 13.7539\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5280 - val_loss: 13.7279\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3737 - val_loss: 13.7441\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8072 - val_loss: 13.9088\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1441 - val_loss: 14.2209\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4257 - val_loss: 14.1030\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9667 - val_loss: 13.9927\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2841 - val_loss: 13.8455\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8417 - val_loss: 13.8912\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4601 - val_loss: 13.9668\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1875 - val_loss: 13.8357\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6177 - val_loss: 13.8197\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9982 - val_loss: 13.7385\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 922us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 896us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 20s 61ms/step - loss: 18.7243 - val_loss: 26.1731\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 17.9927 - val_loss: 24.5948\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 17.3543 - val_loss: 22.6843\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.4124 - val_loss: 20.2401\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.1163 - val_loss: 18.0174\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8944 - val_loss: 16.0909\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7116 - val_loss: 15.1608\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9150 - val_loss: 14.6017\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6506 - val_loss: 14.4039\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3423 - val_loss: 14.3501\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8815 - val_loss: 14.3850\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5604 - val_loss: 14.3320\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4157 - val_loss: 14.1115\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9897 - val_loss: 14.0822\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9370 - val_loss: 14.1572\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7388 - val_loss: 13.9639\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6211 - val_loss: 14.0653\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8814 - val_loss: 14.0911\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6871 - val_loss: 13.9830\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7546 - val_loss: 14.0463\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4323 - val_loss: 14.2107\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3981 - val_loss: 14.1520\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3297 - val_loss: 14.2948\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3743 - val_loss: 14.3439\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6028 - val_loss: 14.0456\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0717 - val_loss: 14.2112\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1404 - val_loss: 14.1359\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7770 - val_loss: 14.4238\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8028 - val_loss: 14.5045\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5461 - val_loss: 14.6581\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0345 - val_loss: 14.4220\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8812 - val_loss: 14.5418\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6725 - val_loss: 14.5248\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4630 - val_loss: 14.3638\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5619 - val_loss: 14.5753\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7710 - val_loss: 15.0893\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 975us/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "19/19 [==============================] - 0s 963us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 20.9132 - val_loss: 26.7764\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.7050 - val_loss: 23.1260\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.9192 - val_loss: 20.6132\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.0276 - val_loss: 18.9111\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.6423 - val_loss: 17.7668\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.5573 - val_loss: 16.9548\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5880 - val_loss: 16.5594\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5761 - val_loss: 16.1259\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1736 - val_loss: 16.1156\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.0070 - val_loss: 15.6320\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.8349 - val_loss: 15.4553\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3566 - val_loss: 15.1041\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8396 - val_loss: 14.7639\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9329 - val_loss: 14.7876\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7195 - val_loss: 14.4423\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4818 - val_loss: 14.0929\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5438 - val_loss: 14.2161\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5628 - val_loss: 14.0549\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2495 - val_loss: 13.8230\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1188 - val_loss: 13.7702\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3795 - val_loss: 13.9439\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0941 - val_loss: 14.0121\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0651 - val_loss: 13.6920\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7576 - val_loss: 13.8735\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9696 - val_loss: 13.5419\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7329 - val_loss: 13.4523\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9920 - val_loss: 13.7399\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5910 - val_loss: 13.6521\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6479 - val_loss: 13.7821\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6402 - val_loss: 13.7454\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4446 - val_loss: 13.5759\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5695 - val_loss: 13.6549\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2641 - val_loss: 13.5546\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2035 - val_loss: 13.4547\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1624 - val_loss: 13.7976\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5780 - val_loss: 13.7469\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5995 - val_loss: 13.6599\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4578 - val_loss: 13.6852\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2578 - val_loss: 13.5344\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2684 - val_loss: 13.9158\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8676 - val_loss: 13.8393\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1177 - val_loss: 13.7267\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1248 - val_loss: 13.9309\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8157 - val_loss: 14.2235\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9070 - val_loss: 14.0823\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0239 - val_loss: 13.9592\n",
      "18/18 [==============================] - 0s 966us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 563us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 905us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 973us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 52ms/step - loss: 16.2200 - val_loss: 19.8388\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 14.9351 - val_loss: 18.7799\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.6139 - val_loss: 18.0059\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.3074 - val_loss: 17.6558\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.6970 - val_loss: 17.1112\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.3900 - val_loss: 16.5692\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.9590 - val_loss: 16.4995\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7409 - val_loss: 16.0532\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.4835 - val_loss: 15.8720\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.8896 - val_loss: 15.7162\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9218 - val_loss: 15.3001\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1616 - val_loss: 14.9689\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0361 - val_loss: 14.6220\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.6930 - val_loss: 14.2616\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3649 - val_loss: 14.2608\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0769 - val_loss: 14.0457\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9494 - val_loss: 13.8486\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2878 - val_loss: 13.8510\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6198 - val_loss: 13.7484\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5043 - val_loss: 13.7807\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8032 - val_loss: 13.9184\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9441 - val_loss: 13.8815\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8337 - val_loss: 13.8522\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5766 - val_loss: 13.8465\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9724 - val_loss: 13.7144\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2651 - val_loss: 13.7276\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8208 - val_loss: 13.7475\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4332 - val_loss: 13.6958\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4667 - val_loss: 13.8058\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3417 - val_loss: 13.7575\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5630 - val_loss: 13.7097\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2667 - val_loss: 13.7805\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9372 - val_loss: 13.8687\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9514 - val_loss: 13.9436\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2362 - val_loss: 13.8715\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5428 - val_loss: 14.1468\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9756 - val_loss: 14.2840\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4246 - val_loss: 14.1980\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7142 - val_loss: 14.1797\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6464 - val_loss: 14.0716\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4471 - val_loss: 14.1488\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0419 - val_loss: 14.2615\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8315 - val_loss: 14.3697\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7806 - val_loss: 14.7628\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2870 - val_loss: 14.6277\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9984 - val_loss: 14.6982\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4433 - val_loss: 14.4802\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4760 - val_loss: 14.4888\n",
      "18/18 [==============================] - 0s 930us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 812us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 869us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 843us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 854us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Executing 9f8163e4 iter 16\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 98ms/step - loss: 21.4990 - val_loss: 27.9038\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 18.5632 - val_loss: 25.2992\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.8599 - val_loss: 22.7818\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.2589 - val_loss: 20.8223\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.2604 - val_loss: 19.2249\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.1655 - val_loss: 17.6236\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5528 - val_loss: 16.8480\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1651 - val_loss: 16.3071\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.8306 - val_loss: 15.7663\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3470 - val_loss: 15.5575\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.4630 - val_loss: 15.3270\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2152 - val_loss: 15.0282\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2763 - val_loss: 14.7680\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8957 - val_loss: 14.5003\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3052 - val_loss: 14.4186\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6027 - val_loss: 14.2327\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1348 - val_loss: 14.2665\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2879 - val_loss: 14.2469\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0959 - val_loss: 13.9485\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1251 - val_loss: 13.8595\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2963 - val_loss: 13.9166\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0415 - val_loss: 13.8537\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8234 - val_loss: 13.7567\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6072 - val_loss: 13.8112\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5766 - val_loss: 13.8447\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5034 - val_loss: 13.8069\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2962 - val_loss: 13.8989\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1386 - val_loss: 13.8094\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0082 - val_loss: 13.9599\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9855 - val_loss: 13.8784\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0943 - val_loss: 13.9729\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3403 - val_loss: 14.0024\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5323 - val_loss: 13.9315\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6710 - val_loss: 13.7823\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1404 - val_loss: 13.7737\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2103 - val_loss: 14.0917\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5420 - val_loss: 14.0364\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7960 - val_loss: 13.9544\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9231 - val_loss: 13.9474\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3314 - val_loss: 14.0996\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9085 - val_loss: 14.0573\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1312 - val_loss: 14.1259\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3142 - val_loss: 14.0632\n",
      "18/18 [==============================] - 0s 969us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 957us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 952us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 62ms/step - loss: 18.5418 - val_loss: 25.5787\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 17.3755 - val_loss: 23.7429\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.1869 - val_loss: 21.5371\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.0164 - val_loss: 19.3952\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 13.6519 - val_loss: 17.4511\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.0797 - val_loss: 15.8405\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.8605 - val_loss: 14.9790\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3802 - val_loss: 14.5398\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8628 - val_loss: 14.1584\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5512 - val_loss: 14.1211\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 10.1876 - val_loss: 14.0321\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 10.1729 - val_loss: 13.9913\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9182 - val_loss: 13.8885\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6755 - val_loss: 13.8995\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1691 - val_loss: 13.9375\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0975 - val_loss: 13.8488\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8888 - val_loss: 14.0373\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0918 - val_loss: 14.3231\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4625 - val_loss: 14.1217\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2650 - val_loss: 14.2532\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7303 - val_loss: 14.4281\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4874 - val_loss: 14.4486\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2880 - val_loss: 14.4879\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 8.6221 - val_loss: 14.6698\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4732 - val_loss: 14.7132\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1013 - val_loss: 14.7278\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8244 - val_loss: 14.7893\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8090 - val_loss: 14.9551\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.6627 - val_loss: 15.2002\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.3895 - val_loss: 15.3516\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.6618 - val_loss: 15.3471\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.6247 - val_loss: 15.3948\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.2410 - val_loss: 15.4592\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 6.9021 - val_loss: 15.4112\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.3098 - val_loss: 15.5594\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.5454 - val_loss: 15.7283\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 22.0574 - val_loss: 27.1798\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.2231 - val_loss: 22.0190\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.9422 - val_loss: 19.4205\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8813 - val_loss: 18.2645\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.9583 - val_loss: 17.2975\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.2734 - val_loss: 16.5698\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 12.1843 - val_loss: 16.2095\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6677 - val_loss: 15.7508\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1229 - val_loss: 15.5236\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9454 - val_loss: 15.4328\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4271 - val_loss: 15.3762\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9257 - val_loss: 15.0607\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0064 - val_loss: 14.8202\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3900 - val_loss: 14.9065\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9895 - val_loss: 14.7155\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6930 - val_loss: 14.4443\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7631 - val_loss: 14.6450\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4416 - val_loss: 14.6202\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4163 - val_loss: 14.3858\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1116 - val_loss: 14.3761\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0956 - val_loss: 14.4715\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0140 - val_loss: 14.5501\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 9.0143 - val_loss: 14.4926\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6222 - val_loss: 14.7190\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6250 - val_loss: 14.3513\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5621 - val_loss: 14.4941\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0798 - val_loss: 14.6054\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5089 - val_loss: 14.6258\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5901 - val_loss: 14.8576\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2783 - val_loss: 14.8967\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6455 - val_loss: 14.5950\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2172 - val_loss: 14.8305\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8342 - val_loss: 14.7402\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0709 - val_loss: 14.7964\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8649 - val_loss: 15.1878\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4721 - val_loss: 15.1324\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3998 - val_loss: 15.3172\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.9616 - val_loss: 15.3879\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.9464 - val_loss: 15.2666\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.7423 - val_loss: 15.3175\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.7250 - val_loss: 15.8693\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.4978 - val_loss: 15.4806\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.6309 - val_loss: 15.5167\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.4191 - val_loss: 16.1064\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.7218 - val_loss: 15.8487\n",
      "18/18 [==============================] - 0s 957us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 902us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 891us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1000us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 18.5954 - val_loss: 23.7414\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.3343 - val_loss: 22.1574\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.0972 - val_loss: 19.5582\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.8042 - val_loss: 17.7070\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.6878 - val_loss: 16.4567\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.9114 - val_loss: 15.3775\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.2308 - val_loss: 15.1468\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.8615 - val_loss: 15.0580\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3997 - val_loss: 14.9397\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.4962 - val_loss: 14.8278\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0572 - val_loss: 14.8018\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2899 - val_loss: 14.7941\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1458 - val_loss: 14.6910\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6034 - val_loss: 14.6427\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3328 - val_loss: 14.6404\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2048 - val_loss: 14.5430\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1176 - val_loss: 14.5027\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6781 - val_loss: 14.5942\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7847 - val_loss: 14.5139\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8968 - val_loss: 14.5659\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5767 - val_loss: 14.8382\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5159 - val_loss: 14.5807\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4905 - val_loss: 14.7683\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3810 - val_loss: 14.8170\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7941 - val_loss: 14.8952\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9127 - val_loss: 14.8408\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0477 - val_loss: 14.7458\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8214 - val_loss: 15.0492\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2206 - val_loss: 15.0466\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9008 - val_loss: 15.1196\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8925 - val_loss: 15.0585\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6741 - val_loss: 15.0120\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6166 - val_loss: 15.0910\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5301 - val_loss: 15.1951\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7968 - val_loss: 15.0682\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7749 - val_loss: 15.0337\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2219 - val_loss: 15.0499\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 829us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 999us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 842us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "Executing 4effa258 iter 17\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 57ms/step - loss: 20.5090 - val_loss: 24.6945\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 18.1118 - val_loss: 22.6556\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.7304 - val_loss: 21.2896\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.0872 - val_loss: 20.0670\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.0537 - val_loss: 19.0093\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.9468 - val_loss: 18.2129\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5439 - val_loss: 17.9153\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3031 - val_loss: 17.5757\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4689 - val_loss: 17.3811\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6556 - val_loss: 17.2942\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2047 - val_loss: 17.0566\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1449 - val_loss: 16.7628\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8774 - val_loss: 16.4108\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5016 - val_loss: 16.4526\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2686 - val_loss: 16.3891\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3308 - val_loss: 16.1851\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2065 - val_loss: 16.2288\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0919 - val_loss: 16.2918\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6171 - val_loss: 16.2916\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3660 - val_loss: 16.2327\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6664 - val_loss: 16.3505\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5693 - val_loss: 16.4800\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2150 - val_loss: 16.3277\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0763 - val_loss: 16.4028\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2752 - val_loss: 16.5481\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9595 - val_loss: 16.6208\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5374 - val_loss: 16.8658\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5957 - val_loss: 17.0697\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6708 - val_loss: 17.0339\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3661 - val_loss: 17.0058\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2159 - val_loss: 16.9732\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8213 - val_loss: 17.3348\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6941 - val_loss: 17.2025\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2899 - val_loss: 17.1183\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1389 - val_loss: 17.4197\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5778 - val_loss: 17.4554\n",
      "18/18 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 915us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 990us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 60ms/step - loss: 18.3558 - val_loss: 24.4181\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.4485 - val_loss: 22.0211\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.5038 - val_loss: 20.0229\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.4579 - val_loss: 19.0928\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.6547 - val_loss: 18.7725\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1700 - val_loss: 18.4234\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3996 - val_loss: 18.4624\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.0500 - val_loss: 18.4509\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2087 - val_loss: 18.5564\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5217 - val_loss: 18.8346\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 10.2999 - val_loss: 18.9771\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 9.9305 - val_loss: 19.0476\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5989 - val_loss: 19.1255\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5799 - val_loss: 19.1909\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2460 - val_loss: 19.4570\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9385 - val_loss: 19.2229\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5955 - val_loss: 19.6914\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6927 - val_loss: 19.7184\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3823 - val_loss: 19.6245\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5389 - val_loss: 19.7802\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2369 - val_loss: 19.6508\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8125 - val_loss: 19.8733\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.5752 - val_loss: 19.9405\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.3957 - val_loss: 20.4533\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.4335 - val_loss: 19.7717\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.0361 - val_loss: 20.1275\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 573us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 985us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 56ms/step - loss: 20.4174 - val_loss: 26.2782\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.1710 - val_loss: 22.6761\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.9240 - val_loss: 20.6997\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.0870 - val_loss: 19.7085\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8737 - val_loss: 19.2441\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8340 - val_loss: 18.9292\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.3404 - val_loss: 19.1790\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.0091 - val_loss: 19.1073\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7719 - val_loss: 19.7673\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7675 - val_loss: 19.5923\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3351 - val_loss: 19.9426\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.2332 - val_loss: 19.9926\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2398 - val_loss: 19.5453\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6085 - val_loss: 20.1158\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3266 - val_loss: 20.0554\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8391 - val_loss: 19.8687\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9643 - val_loss: 20.1501\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9237 - val_loss: 20.6523\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6144 - val_loss: 20.0174\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1777 - val_loss: 20.5172\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5088 - val_loss: 20.1858\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1461 - val_loss: 20.6303\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1205 - val_loss: 20.4009\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6328 - val_loss: 21.1871\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6564 - val_loss: 20.4276\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4113 - val_loss: 20.6720\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 999us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 973us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 986us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 52ms/step - loss: 22.7791 - val_loss: 29.7806\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 19.6725 - val_loss: 27.1956\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 18.4221 - val_loss: 25.7227\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.7557 - val_loss: 24.7187\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.2004 - val_loss: 23.9774\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.9011 - val_loss: 23.2938\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.5992 - val_loss: 22.7634\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.3290 - val_loss: 22.2450\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.1485 - val_loss: 21.7465\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.9847 - val_loss: 21.3806\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.8009 - val_loss: 20.9574\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.5907 - val_loss: 20.7100\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.4642 - val_loss: 20.3859\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.2962 - val_loss: 20.2264\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.1865 - val_loss: 20.0136\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.0485 - val_loss: 19.8840\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.8647 - val_loss: 19.7363\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.5542 - val_loss: 19.6937\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.4859 - val_loss: 19.5806\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.2164 - val_loss: 19.5028\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.7599 - val_loss: 19.3452\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.2475 - val_loss: 19.3550\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.1638 - val_loss: 19.0107\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.8529 - val_loss: 19.3888\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.4097 - val_loss: 19.2902\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.0714 - val_loss: 19.2489\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.8473 - val_loss: 19.1897\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3956 - val_loss: 19.2106\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1638 - val_loss: 19.0436\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7497 - val_loss: 19.1178\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4471 - val_loss: 19.1239\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2080 - val_loss: 19.4805\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0696 - val_loss: 19.5666\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7327 - val_loss: 19.1661\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5130 - val_loss: 19.3185\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7553 - val_loss: 19.0471\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7153 - val_loss: 18.7234\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5512 - val_loss: 18.6965\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2789 - val_loss: 18.7480\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8465 - val_loss: 18.9805\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2039 - val_loss: 18.3614\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7265 - val_loss: 18.6098\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5028 - val_loss: 19.3573\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4828 - val_loss: 19.0787\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4598 - val_loss: 18.5870\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5580 - val_loss: 18.4189\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.1269 - val_loss: 18.7711\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9103 - val_loss: 18.8823\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0619 - val_loss: 18.4481\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.8772 - val_loss: 19.0150\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9953 - val_loss: 19.4488\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9950 - val_loss: 18.7277\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2718 - val_loss: 19.1262\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.1362 - val_loss: 19.2613\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.4651 - val_loss: 20.0428\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.8568 - val_loss: 19.2394\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.6675 - val_loss: 19.3553\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.5571 - val_loss: 19.3328\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.4684 - val_loss: 18.8879\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.4656 - val_loss: 19.0716\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.3135 - val_loss: 19.6032\n",
      "18/18 [==============================] - 0s 941us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 611us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 829us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 911us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 894us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 820us/step\n",
      "Executing 13a24caf iter 18\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 15s 55ms/step - loss: 22.4275 - val_loss: 26.3272\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 19.2049 - val_loss: 24.1742\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.3394 - val_loss: 22.7814\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.8912 - val_loss: 21.9739\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.2066 - val_loss: 21.2936\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.6869 - val_loss: 20.1228\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.7250 - val_loss: 19.5056\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.2457 - val_loss: 18.9719\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.2268 - val_loss: 18.7662\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.1457 - val_loss: 18.6529\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.4086 - val_loss: 18.3892\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1686 - val_loss: 18.3440\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.4197 - val_loss: 18.3050\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7689 - val_loss: 18.2297\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5585 - val_loss: 18.3195\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7443 - val_loss: 18.1239\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1449 - val_loss: 18.2850\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4287 - val_loss: 18.5900\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2909 - val_loss: 18.6174\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.8007 - val_loss: 18.4026\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1861 - val_loss: 18.5024\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7970 - val_loss: 18.7161\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8816 - val_loss: 18.5388\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2533 - val_loss: 18.6102\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9049 - val_loss: 18.8383\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5761 - val_loss: 18.6941\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4220 - val_loss: 19.0202\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6698 - val_loss: 18.8085\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7982 - val_loss: 19.0012\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2049 - val_loss: 19.0313\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5070 - val_loss: 19.1324\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3361 - val_loss: 19.3662\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0549 - val_loss: 19.3721\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1970 - val_loss: 19.5016\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5565 - val_loss: 19.4438\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3062 - val_loss: 19.5717\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 835us/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 976us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 61ms/step - loss: 18.0818 - val_loss: 24.8832\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.6810 - val_loss: 22.7601\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 15.1262 - val_loss: 20.2340\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.9530 - val_loss: 18.5912\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.8358 - val_loss: 17.7497\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 12.4896 - val_loss: 17.0194\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.8491 - val_loss: 16.9441\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4269 - val_loss: 17.0204\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 11.2393 - val_loss: 17.1480\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 10.9278 - val_loss: 17.3882\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6232 - val_loss: 17.4413\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5118 - val_loss: 17.5658\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9730 - val_loss: 17.5590\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9716 - val_loss: 17.7043\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2183 - val_loss: 17.8940\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6311 - val_loss: 17.7312\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6864 - val_loss: 17.8513\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3264 - val_loss: 18.0421\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0923 - val_loss: 17.9477\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3969 - val_loss: 18.0157\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0306 - val_loss: 18.2329\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7740 - val_loss: 18.4272\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3571 - val_loss: 18.2418\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5673 - val_loss: 18.5778\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5711 - val_loss: 18.5108\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0194 - val_loss: 18.5446\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2987 - val_loss: 18.6768\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 969us/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 56ms/step - loss: 19.3245 - val_loss: 20.2492\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.1012 - val_loss: 18.0303\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.4015 - val_loss: 17.1093\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 14.7553 - val_loss: 16.8856\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.7570 - val_loss: 16.8132\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.5996 - val_loss: 16.6314\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.4806 - val_loss: 16.8427\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.1545 - val_loss: 16.9349\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.4193 - val_loss: 17.1517\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5107 - val_loss: 17.2201\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5317 - val_loss: 17.3971\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3509 - val_loss: 17.4013\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5522 - val_loss: 17.5193\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7448 - val_loss: 17.9005\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4850 - val_loss: 17.7311\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2314 - val_loss: 17.9331\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1979 - val_loss: 18.5515\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2091 - val_loss: 18.4835\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8563 - val_loss: 18.1698\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8283 - val_loss: 18.6533\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0762 - val_loss: 18.8648\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6938 - val_loss: 19.1695\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7771 - val_loss: 18.8151\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5287 - val_loss: 19.8489\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3374 - val_loss: 19.1214\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1085 - val_loss: 19.3623\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 962us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 959us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 52ms/step - loss: 17.3624 - val_loss: 23.4909\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.8716 - val_loss: 21.0082\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.0106 - val_loss: 19.7535\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.4122 - val_loss: 19.1925\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.0008 - val_loss: 18.9610\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.4577 - val_loss: 18.4971\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.3669 - val_loss: 18.5046\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.2786 - val_loss: 18.1962\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.1678 - val_loss: 18.3197\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.9357 - val_loss: 18.0079\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.7831 - val_loss: 17.7568\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.1015 - val_loss: 17.7751\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.3992 - val_loss: 17.4312\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4110 - val_loss: 17.6571\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0867 - val_loss: 17.7194\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0419 - val_loss: 17.8468\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0931 - val_loss: 18.0059\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0760 - val_loss: 17.9832\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7301 - val_loss: 18.0785\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5105 - val_loss: 18.1541\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2531 - val_loss: 18.0790\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1276 - val_loss: 18.3869\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7877 - val_loss: 18.3408\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2414 - val_loss: 18.5393\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4030 - val_loss: 18.1570\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2495 - val_loss: 17.7618\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.6545 - val_loss: 18.0964\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7649 - val_loss: 18.1238\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8446 - val_loss: 18.4525\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2554 - val_loss: 18.4056\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1074 - val_loss: 18.4056\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1676 - val_loss: 18.3613\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1668 - val_loss: 18.2218\n",
      "18/18 [==============================] - 0s 810us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 808us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 822us/step\n",
      "Executing 8359c65d iter 19\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 58ms/step - loss: 20.3150 - val_loss: 27.6674\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 18.1356 - val_loss: 24.8900\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.9469 - val_loss: 22.6817\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 15.9425 - val_loss: 21.3814\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.7117 - val_loss: 20.4448\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.0070 - val_loss: 19.4082\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.1950 - val_loss: 18.9482\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.1497 - val_loss: 18.6452\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.6198 - val_loss: 18.4770\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1485 - val_loss: 18.6732\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.1470 - val_loss: 18.4633\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6521 - val_loss: 18.5274\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9298 - val_loss: 18.5148\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5575 - val_loss: 18.4984\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.4621 - val_loss: 18.6016\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5940 - val_loss: 18.4936\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9357 - val_loss: 18.8173\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1794 - val_loss: 18.8716\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8233 - val_loss: 18.8385\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.1301 - val_loss: 18.9489\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0056 - val_loss: 19.0190\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5005 - val_loss: 19.1353\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5464 - val_loss: 19.0194\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2980 - val_loss: 19.1250\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2471 - val_loss: 19.1326\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4449 - val_loss: 19.0159\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2659 - val_loss: 18.9753\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1835 - val_loss: 19.1426\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9568 - val_loss: 19.2271\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8881 - val_loss: 19.3866\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 9.9413 - val_loss: 19.3609\n",
      "18/18 [==============================] - 0s 996us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 898us/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 983us/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 19s 62ms/step - loss: 18.9592 - val_loss: 26.8836\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 17.7711 - val_loss: 25.4079\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.7993 - val_loss: 23.8520\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.8555 - val_loss: 22.4237\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.8622 - val_loss: 21.1352\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.0823 - val_loss: 19.9825\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.3381 - val_loss: 19.2502\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.0088 - val_loss: 18.5351\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 12.4317 - val_loss: 18.0159\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.0158 - val_loss: 17.8558\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7401 - val_loss: 17.6125\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5563 - val_loss: 17.5977\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.4603 - val_loss: 17.4837\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0249 - val_loss: 17.5026\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8313 - val_loss: 17.6297\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8151 - val_loss: 17.6045\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5093 - val_loss: 17.7840\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2416 - val_loss: 17.8413\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0444 - val_loss: 17.8886\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1271 - val_loss: 17.9489\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8893 - val_loss: 18.0191\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5932 - val_loss: 18.0906\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4916 - val_loss: 18.2212\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5011 - val_loss: 18.3110\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2330 - val_loss: 18.3095\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3488 - val_loss: 18.1998\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1631 - val_loss: 18.2391\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9231 - val_loss: 18.2717\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0157 - val_loss: 18.3221\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8069 - val_loss: 18.4598\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0416 - val_loss: 18.4524\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9766 - val_loss: 18.4867\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5377 - val_loss: 18.5591\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 644us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 55ms/step - loss: 24.1428 - val_loss: 30.8001\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 18.4981 - val_loss: 25.4007\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.2214 - val_loss: 22.2725\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.8555 - val_loss: 20.3497\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8733 - val_loss: 19.1758\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.7315 - val_loss: 18.1627\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7059 - val_loss: 17.6099\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.4821 - val_loss: 17.1171\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3710 - val_loss: 16.9881\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3019 - val_loss: 16.7407\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3530 - val_loss: 16.4569\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7335 - val_loss: 16.3823\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.2853 - val_loss: 16.2291\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5241 - val_loss: 16.2733\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0684 - val_loss: 16.2077\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1399 - val_loss: 16.0980\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5792 - val_loss: 16.3039\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7655 - val_loss: 16.1962\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3968 - val_loss: 16.0344\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1722 - val_loss: 16.2799\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1290 - val_loss: 16.3088\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3884 - val_loss: 16.4417\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0962 - val_loss: 16.2557\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8028 - val_loss: 16.7073\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0465 - val_loss: 16.6225\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8909 - val_loss: 16.4691\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0174 - val_loss: 16.5804\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8648 - val_loss: 16.6005\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4845 - val_loss: 16.7665\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4701 - val_loss: 16.8942\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7226 - val_loss: 16.6583\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3592 - val_loss: 16.5194\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4429 - val_loss: 16.6973\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1705 - val_loss: 16.8930\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0007 - val_loss: 17.0912\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5169 - val_loss: 16.9307\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5255 - val_loss: 16.9117\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 9.2178 - val_loss: 17.1404\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3977 - val_loss: 17.0843\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 930us/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 52ms/step - loss: 20.0296 - val_loss: 27.9226\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.8540 - val_loss: 24.9354\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.8449 - val_loss: 22.5347\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.9510 - val_loss: 20.7182\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.1460 - val_loss: 19.5038\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.2369 - val_loss: 18.2320\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.5987 - val_loss: 17.5576\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.0223 - val_loss: 16.9445\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.5821 - val_loss: 16.5425\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.6516 - val_loss: 16.4856\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.9868 - val_loss: 16.2968\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.7303 - val_loss: 16.3171\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.6830 - val_loss: 16.2995\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2678 - val_loss: 16.3341\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3111 - val_loss: 16.4159\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1912 - val_loss: 16.4246\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.2151 - val_loss: 16.5295\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.1180 - val_loss: 16.6028\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9254 - val_loss: 16.6880\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8415 - val_loss: 16.7637\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.0179 - val_loss: 16.7841\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8207 - val_loss: 16.8291\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8796 - val_loss: 16.9286\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3921 - val_loss: 17.0532\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9459 - val_loss: 17.0914\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8170 - val_loss: 17.1218\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3422 - val_loss: 17.1250\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7097 - val_loss: 17.2621\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9070 - val_loss: 17.2084\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8129 - val_loss: 17.3348\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0891 - val_loss: 17.3983\n",
      "18/18 [==============================] - 0s 765us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 848us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 841us/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "19/19 [==============================] - 0s 915us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 841us/step\n",
      "Executing ecf2577f iter 20\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 58ms/step - loss: 18.9934 - val_loss: 22.3386\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.1948 - val_loss: 19.7096\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.9002 - val_loss: 17.9975\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.7984 - val_loss: 16.8939\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.9462 - val_loss: 16.1136\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.0506 - val_loss: 15.4732\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5592 - val_loss: 15.1289\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9808 - val_loss: 15.0345\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.9467 - val_loss: 14.8574\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.6169 - val_loss: 14.9515\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4458 - val_loss: 14.8717\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5557 - val_loss: 14.9269\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1319 - val_loss: 14.7905\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2398 - val_loss: 14.7751\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0424 - val_loss: 14.7847\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0663 - val_loss: 14.7799\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6137 - val_loss: 14.8585\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8293 - val_loss: 14.8511\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4461 - val_loss: 14.9859\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9514 - val_loss: 14.9986\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4219 - val_loss: 15.1705\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5631 - val_loss: 15.1586\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4091 - val_loss: 15.2269\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5319 - val_loss: 15.4163\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1127 - val_loss: 15.4739\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2906 - val_loss: 15.5841\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9322 - val_loss: 15.5881\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2548 - val_loss: 15.6827\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0131 - val_loss: 15.9247\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8600 - val_loss: 16.1224\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1304 - val_loss: 15.9915\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3245 - val_loss: 15.9620\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5503 - val_loss: 16.2170\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6770 - val_loss: 16.2210\n",
      "18/18 [==============================] - 0s 945us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 922us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 957us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 17s 61ms/step - loss: 18.0136 - val_loss: 25.2619\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.8685 - val_loss: 23.1719\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.4530 - val_loss: 20.7815\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 14.3376 - val_loss: 18.8077\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.8403 - val_loss: 16.9340\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9619 - val_loss: 15.4057\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.3007 - val_loss: 14.8222\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0964 - val_loss: 14.3877\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7765 - val_loss: 14.1421\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5625 - val_loss: 14.0890\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 10.0807 - val_loss: 14.0132\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0017 - val_loss: 14.0661\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8428 - val_loss: 14.0101\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5896 - val_loss: 13.9637\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 9.3845 - val_loss: 13.9711\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1750 - val_loss: 13.9683\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0302 - val_loss: 14.0964\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8540 - val_loss: 14.1528\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9744 - val_loss: 14.1492\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1287 - val_loss: 14.2230\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8547 - val_loss: 14.3454\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6718 - val_loss: 14.2864\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4633 - val_loss: 14.3036\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5633 - val_loss: 14.5334\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6279 - val_loss: 14.5460\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0559 - val_loss: 14.6004\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2079 - val_loss: 14.5142\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1946 - val_loss: 14.6560\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1352 - val_loss: 14.6700\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.6865 - val_loss: 14.8503\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.5388 - val_loss: 14.8749\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1636 - val_loss: 14.9404\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.8049 - val_loss: 14.9929\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.3747 - val_loss: 14.8779\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 626us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 56ms/step - loss: 19.9358 - val_loss: 23.9267\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.3568 - val_loss: 20.1811\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.7309 - val_loss: 17.3454\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.2593 - val_loss: 15.6487\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.2917 - val_loss: 14.7326\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7748 - val_loss: 13.9640\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.4190 - val_loss: 13.7590\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9370 - val_loss: 13.5551\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7575 - val_loss: 13.6283\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3606 - val_loss: 13.5016\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.5366 - val_loss: 13.5702\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.0807 - val_loss: 13.5593\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4970 - val_loss: 13.3970\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5594 - val_loss: 13.5449\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3051 - val_loss: 13.4974\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0854 - val_loss: 13.6089\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.9561 - val_loss: 13.8121\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8647 - val_loss: 13.7814\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7665 - val_loss: 13.6992\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4929 - val_loss: 13.8344\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.6131 - val_loss: 13.7457\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5761 - val_loss: 13.9619\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4121 - val_loss: 13.6839\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1738 - val_loss: 14.3164\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3407 - val_loss: 13.7630\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9326 - val_loss: 14.1796\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.2996 - val_loss: 14.2301\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9012 - val_loss: 14.3084\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8908 - val_loss: 14.3175\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8402 - val_loss: 14.6930\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6648 - val_loss: 14.4787\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7985 - val_loss: 14.5085\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5669 - val_loss: 14.4535\n",
      "18/18 [==============================] - 0s 951us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1000us/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 53ms/step - loss: 20.6642 - val_loss: 25.7290\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.8548 - val_loss: 22.4741\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 16.4708 - val_loss: 19.6059\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.8644 - val_loss: 17.5208\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.5768 - val_loss: 16.1472\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.9226 - val_loss: 15.2144\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 12.2509 - val_loss: 14.7685\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.7469 - val_loss: 14.5980\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9359 - val_loss: 14.6326\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1499 - val_loss: 14.4656\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8702 - val_loss: 14.5203\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3805 - val_loss: 14.6972\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4408 - val_loss: 14.4970\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2005 - val_loss: 14.5016\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.7710 - val_loss: 14.4993\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0323 - val_loss: 14.4364\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3365 - val_loss: 14.5962\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1957 - val_loss: 14.7167\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4271 - val_loss: 14.6525\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4638 - val_loss: 14.5955\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3031 - val_loss: 14.7720\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1358 - val_loss: 14.7669\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7331 - val_loss: 14.6494\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5066 - val_loss: 14.8689\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0985 - val_loss: 14.8547\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1266 - val_loss: 14.7035\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6454 - val_loss: 14.7235\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9899 - val_loss: 14.7960\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3073 - val_loss: 14.9032\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3162 - val_loss: 14.9806\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4795 - val_loss: 14.9983\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6741 - val_loss: 15.1126\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6904 - val_loss: 15.0812\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0999 - val_loss: 15.0959\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9896 - val_loss: 15.0503\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8413 - val_loss: 15.1722\n",
      "18/18 [==============================] - 0s 957us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 938us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 837us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 854us/step\n",
      "Executing 458d357c iter 21\n",
      "Train predicting  0 RNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 18s 57ms/step - loss: 20.6926 - val_loss: 28.2402\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 18.4952 - val_loss: 25.0737\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.8688 - val_loss: 22.8017\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.6900 - val_loss: 21.0812\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.7062 - val_loss: 19.6287\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.8987 - val_loss: 18.1502\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.0757 - val_loss: 17.2927\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.5589 - val_loss: 16.3710\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9459 - val_loss: 15.6227\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.6329 - val_loss: 15.1310\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.1307 - val_loss: 14.7918\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.7726 - val_loss: 14.7947\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.7784 - val_loss: 14.4456\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.4553 - val_loss: 14.2549\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4218 - val_loss: 14.1746\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1162 - val_loss: 13.9436\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.9275 - val_loss: 13.9684\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.1229 - val_loss: 13.9011\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5580 - val_loss: 13.6376\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8463 - val_loss: 13.6402\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.7271 - val_loss: 13.6163\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5801 - val_loss: 13.6703\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.4810 - val_loss: 13.5227\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3301 - val_loss: 13.6656\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1336 - val_loss: 13.7607\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0727 - val_loss: 13.7387\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1882 - val_loss: 13.6689\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9879 - val_loss: 13.6520\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9332 - val_loss: 13.9040\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7968 - val_loss: 13.8082\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0040 - val_loss: 13.7444\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.1084 - val_loss: 13.6256\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1057 - val_loss: 13.6345\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4918 - val_loss: 13.6951\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8797 - val_loss: 13.5924\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0341 - val_loss: 13.7136\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1605 - val_loss: 13.7624\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9344 - val_loss: 13.6992\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3470 - val_loss: 13.5198\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6336 - val_loss: 13.5066\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8844 - val_loss: 13.6180\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5669 - val_loss: 13.6644\n",
      "Epoch 43/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4723 - val_loss: 13.5878\n",
      "Epoch 44/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3091 - val_loss: 13.7461\n",
      "Epoch 45/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7558 - val_loss: 13.5978\n",
      "Epoch 46/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4578 - val_loss: 13.3546\n",
      "Epoch 47/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1575 - val_loss: 13.3930\n",
      "Epoch 48/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3432 - val_loss: 13.4500\n",
      "Epoch 49/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3306 - val_loss: 13.4332\n",
      "Epoch 50/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0504 - val_loss: 13.4981\n",
      "Epoch 51/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0527 - val_loss: 13.6064\n",
      "Epoch 52/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0565 - val_loss: 13.4890\n",
      "Epoch 53/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2149 - val_loss: 13.5433\n",
      "Epoch 54/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0444 - val_loss: 13.7090\n",
      "Epoch 55/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.3371 - val_loss: 13.8484\n",
      "Epoch 56/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.0755 - val_loss: 13.5809\n",
      "Epoch 57/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.8078 - val_loss: 13.6457\n",
      "Epoch 58/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.9081 - val_loss: 13.8498\n",
      "Epoch 59/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.3941 - val_loss: 13.7587\n",
      "Epoch 60/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1103 - val_loss: 13.7266\n",
      "Epoch 61/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8931 - val_loss: 13.9642\n",
      "Epoch 62/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.8360 - val_loss: 13.8288\n",
      "Epoch 63/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8681 - val_loss: 14.1323\n",
      "Epoch 64/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8971 - val_loss: 14.3719\n",
      "Epoch 65/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.5958 - val_loss: 14.0671\n",
      "Epoch 66/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.0797 - val_loss: 14.0249\n",
      "18/18 [==============================] - 0s 953us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 944us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 982us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 LSTM16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 19s 88ms/step - loss: 17.9582 - val_loss: 24.8127\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.6124 - val_loss: 22.1235\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.9684 - val_loss: 18.8249\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.5110 - val_loss: 16.5109\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 12.2222 - val_loss: 15.4678\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.9769 - val_loss: 14.7338\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3356 - val_loss: 14.6009\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.2706 - val_loss: 14.5858\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 10.9257 - val_loss: 14.4664\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.5696 - val_loss: 14.5073\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 10.2674 - val_loss: 14.5772\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.1568 - val_loss: 14.5216\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0514 - val_loss: 14.4604\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0803 - val_loss: 14.4196\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5971 - val_loss: 14.4227\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3159 - val_loss: 14.2734\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0374 - val_loss: 14.3770\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1871 - val_loss: 14.5352\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8364 - val_loss: 14.3644\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1320 - val_loss: 14.4598\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1523 - val_loss: 14.5424\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5749 - val_loss: 14.5891\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4610 - val_loss: 14.6307\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.2360 - val_loss: 14.9296\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.1934 - val_loss: 14.8973\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.8821 - val_loss: 14.9216\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.6295 - val_loss: 14.8810\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.9489 - val_loss: 15.0584\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.9197 - val_loss: 15.1634\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.0689 - val_loss: 15.4349\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.4722 - val_loss: 15.3437\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.3766 - val_loss: 15.2940\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.0529 - val_loss: 15.1654\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.0634 - val_loss: 15.3183\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.2626 - val_loss: 15.4842\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 7.3829 - val_loss: 15.6503\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 CNNRNN16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 56ms/step - loss: 22.9753 - val_loss: 28.1917\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 18.6177 - val_loss: 23.1535\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 16.7859 - val_loss: 20.3602\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 15.5553 - val_loss: 18.7508\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 14.2648 - val_loss: 17.6759\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 13.9926 - val_loss: 16.7402\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.7502 - val_loss: 16.2245\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.4352 - val_loss: 15.8588\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3807 - val_loss: 15.6750\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.7424 - val_loss: 15.6466\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 11.8335 - val_loss: 15.6471\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 11.3855 - val_loss: 15.3631\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8707 - val_loss: 15.2138\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.8042 - val_loss: 15.3569\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4593 - val_loss: 15.2299\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.4513 - val_loss: 15.1255\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.2673 - val_loss: 15.1644\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.3281 - val_loss: 15.1377\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 10.0909 - val_loss: 15.0441\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8326 - val_loss: 15.0098\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8513 - val_loss: 14.9144\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.5739 - val_loss: 14.9191\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8052 - val_loss: 15.0546\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.3837 - val_loss: 15.1232\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4649 - val_loss: 14.9267\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.0737 - val_loss: 15.1017\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.4236 - val_loss: 15.1234\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.1296 - val_loss: 15.2505\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.2449 - val_loss: 15.4686\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9444 - val_loss: 15.2691\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7911 - val_loss: 15.2747\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7740 - val_loss: 15.1841\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.7746 - val_loss: 15.1982\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.8208 - val_loss: 15.1291\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6727 - val_loss: 15.3908\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.9123 - val_loss: 15.2554\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8204 - val_loss: 15.3609\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.5861 - val_loss: 15.2801\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.6367 - val_loss: 15.1717\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7251 - val_loss: 15.1441\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4029 - val_loss: 15.1721\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Train predicting  0 MLP16\n",
      "Epoch 1/200\n",
      "69/69 [==============================] - 16s 54ms/step - loss: 20.7808 - val_loss: 27.6816\n",
      "Epoch 2/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 18.7663 - val_loss: 25.2830\n",
      "Epoch 3/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 17.4356 - val_loss: 23.3609\n",
      "Epoch 4/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 15.9405 - val_loss: 21.4534\n",
      "Epoch 5/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 14.5503 - val_loss: 19.6118\n",
      "Epoch 6/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 13.6367 - val_loss: 18.1128\n",
      "Epoch 7/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 12.3306 - val_loss: 17.1710\n",
      "Epoch 8/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.8186 - val_loss: 16.5475\n",
      "Epoch 9/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 11.3954 - val_loss: 16.1768\n",
      "Epoch 10/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9186 - val_loss: 16.1069\n",
      "Epoch 11/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.9617 - val_loss: 15.9387\n",
      "Epoch 12/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3009 - val_loss: 15.8293\n",
      "Epoch 13/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.8114 - val_loss: 15.8040\n",
      "Epoch 14/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.3313 - val_loss: 15.7504\n",
      "Epoch 15/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2820 - val_loss: 15.7874\n",
      "Epoch 16/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.5845 - val_loss: 15.5606\n",
      "Epoch 17/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0401 - val_loss: 15.5967\n",
      "Epoch 18/200\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 9.8074 - val_loss: 15.7489\n",
      "Epoch 19/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0142 - val_loss: 15.5709\n",
      "Epoch 20/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5829 - val_loss: 15.5874\n",
      "Epoch 21/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.8170 - val_loss: 15.5443\n",
      "Epoch 22/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.2440 - val_loss: 15.4851\n",
      "Epoch 23/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3098 - val_loss: 15.4851\n",
      "Epoch 24/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 10.0599 - val_loss: 15.6937\n",
      "Epoch 25/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.8722 - val_loss: 15.6354\n",
      "Epoch 26/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.3315 - val_loss: 15.6219\n",
      "Epoch 27/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.0570 - val_loss: 15.5588\n",
      "Epoch 28/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5281 - val_loss: 15.6798\n",
      "Epoch 29/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.6412 - val_loss: 15.7605\n",
      "Epoch 30/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4276 - val_loss: 15.7610\n",
      "Epoch 31/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4895 - val_loss: 15.8830\n",
      "Epoch 32/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 9.5167 - val_loss: 15.6823\n",
      "Epoch 33/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9286 - val_loss: 15.7435\n",
      "Epoch 34/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.4353 - val_loss: 15.6291\n",
      "Epoch 35/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7647 - val_loss: 15.8078\n",
      "Epoch 36/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.5710 - val_loss: 15.9979\n",
      "Epoch 37/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.1860 - val_loss: 15.9352\n",
      "Epoch 38/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.2812 - val_loss: 15.8026\n",
      "Epoch 39/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.9029 - val_loss: 15.6908\n",
      "Epoch 40/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.6699 - val_loss: 15.6995\n",
      "Epoch 41/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 8.7899 - val_loss: 15.5933\n",
      "Epoch 42/200\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 7.9483 - val_loss: 15.7294\n",
      "18/18 [==============================] - 0s 957us/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 778us/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "19/19 [==============================] - 0s 833us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 909us/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/19 [==============================] - 0s 800us/step\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for id in id_experiments:\n",
    "    k+=1\n",
    "    print(\"Executing\",id, \"iter\", k)\n",
    "    data = {1: pd.read_parquet(f\"data/climate_features/{region}/predictor_{id}_year.parquet\")}\n",
    "    rnn16_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    lstm16_model = Sequential([\n",
    "    LSTM(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    cnn_rnn_model = Sequential([\n",
    "        Conv1D(16, kernel_size=1, activation=\"relu\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Reshape((1, 16)),  # Back to time dimension\n",
    "        SimpleRNN(8, activation=\"tanh\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    lp_model = Sequential([\n",
    "        Flatten(input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    # assert len(regressors) == len(name_regressors)\n",
    "    regressors =  [rnn16_model, lstm16_model, cnn_rnn_model, lp_model]\n",
    "    name_regressors =  [\"RNN16\", \"LSTM16\", \"CNNRNN16\", \"MLP16\"]\n",
    "    assert len(regressors) == len(name_regressors)\n",
    "    experiment_1 = PredictionExperiment(data, indices_of_interest, regressors, name_regressors, 60, id, loss_fn=SERA(bounds=bounds,T=100))\n",
    "    experiment_1.execute_experiment()\n",
    "    experiment_1.get_metrics(\"r2\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"TSCV\", show=False)\n",
    "\n",
    "    #experiment_1.top_results(\"r2\", 5, stage=\"prediction\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    #experiment_1.top_results(\"cv_r2\", 5, stage=\"CV\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    experiment_1.save_results(f\"data/sera_results_year/{region}_results/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
