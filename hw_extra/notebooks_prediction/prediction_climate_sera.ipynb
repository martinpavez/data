{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERA Monthly Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "SEED = 42\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, GRU, Conv1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\Desktop\\data\\hw_extra\n"
     ]
    }
   ],
   "source": [
    "# Add the folder to the Python path\n",
    "\n",
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())\n",
    "\n",
    "FIRST_YEAR= 1972\n",
    "FREQUENCY= \"monthly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.abspath(\"functions/\") #INPUT_PATH)#'path_to_your_folder')  # Replace with the actual folder path\n",
    "sys.path.insert(0, folder_path)\n",
    "\n",
    "from Predictions import (\n",
    "    PredictionExperiment,\n",
    "    PredictionModel,\n",
    "    SERA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = [\"HWN\", \"HWF\", \"HWD\", \"HWM\", \"HWA\"]\n",
    "bounds = (-1.1692892810242344, -0.30647585455315646, 4.561547586528888, 6.499969486244418)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>season</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_6.parquet</td>\n",
       "      <td>6</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_7.parquet</td>\n",
       "      <td>7</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6e47cb06</td>\n",
       "      <td>predictor_6e47cb06_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_6.parquet</td>\n",
       "      <td>6</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_7.parquet</td>\n",
       "      <td>7</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5cb3fa02</td>\n",
       "      <td>predictor_5cb3fa02_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                       filename  season   \n",
       "0   6e47cb06   predictor_6e47cb06_1.parquet       1  \\\n",
       "1   6e47cb06   predictor_6e47cb06_2.parquet       2   \n",
       "2   6e47cb06   predictor_6e47cb06_3.parquet       3   \n",
       "3   6e47cb06   predictor_6e47cb06_4.parquet       4   \n",
       "4   6e47cb06   predictor_6e47cb06_5.parquet       5   \n",
       "5   6e47cb06   predictor_6e47cb06_6.parquet       6   \n",
       "6   6e47cb06   predictor_6e47cb06_7.parquet       7   \n",
       "7   6e47cb06   predictor_6e47cb06_8.parquet       8   \n",
       "8   6e47cb06   predictor_6e47cb06_9.parquet       9   \n",
       "9   6e47cb06  predictor_6e47cb06_10.parquet      10   \n",
       "10  6e47cb06  predictor_6e47cb06_11.parquet      11   \n",
       "11  6e47cb06  predictor_6e47cb06_12.parquet      12   \n",
       "12  5cb3fa02   predictor_5cb3fa02_1.parquet       1   \n",
       "13  5cb3fa02   predictor_5cb3fa02_2.parquet       2   \n",
       "14  5cb3fa02   predictor_5cb3fa02_3.parquet       3   \n",
       "15  5cb3fa02   predictor_5cb3fa02_4.parquet       4   \n",
       "16  5cb3fa02   predictor_5cb3fa02_5.parquet       5   \n",
       "17  5cb3fa02   predictor_5cb3fa02_6.parquet       6   \n",
       "18  5cb3fa02   predictor_5cb3fa02_7.parquet       7   \n",
       "19  5cb3fa02   predictor_5cb3fa02_8.parquet       8   \n",
       "20  5cb3fa02   predictor_5cb3fa02_9.parquet       9   \n",
       "21  5cb3fa02  predictor_5cb3fa02_10.parquet      10   \n",
       "22  5cb3fa02  predictor_5cb3fa02_11.parquet      11   \n",
       "23  5cb3fa02  predictor_5cb3fa02_12.parquet      12   \n",
       "\n",
       "                                              indices  \n",
       "0   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "1   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "2   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "3   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "4   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "5   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "6   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "7   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "8   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "9   df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "10  df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "11  df9a31c5-20a07cea-cfb03125-9169e0dc-0b0bffae-b...  \n",
       "12  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "13  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "14  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "15  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "16  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "17  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "18  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "19  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "20  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "21  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "22  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  \n",
       "23  fde0e327-340e2882-f27c56aa-5b9237bf-46fa0cb8-6...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region=\"california\"\n",
    "metadata_path = f\"data/climate_features/{region}/metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.reset_index(inplace=True, drop=True)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(f\"data/sera_results/{region}_results/results.csv\")\n",
    "ids_results = results[\"id_data\"].unique()\n",
    "id_experiments = metadata[\"id\"].unique()\n",
    "ids_to_execute = [id for id in id_experiments if id not in ids_results]\n",
    "print(len(ids_to_execute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for id in ids_to_execute:\n",
    "    k+=1\n",
    "    print(\"Executing\",id, \"iter\", k)\n",
    "    data = {i: pd.read_parquet(f\"data/climate_features/{region}/predictor_{id}_{i}.parquet\") for i in range(1,13)}\n",
    "    rnn16_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    lstm16_model = Sequential([\n",
    "    LSTM(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    cnn_rnn_model = Sequential([\n",
    "        Conv1D(16, kernel_size=1, activation=\"relu\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Reshape((1, 16)),  # Back to time dimension\n",
    "        SimpleRNN(8, activation=\"tanh\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    lp_model = Sequential([\n",
    "        Flatten(input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    # assert len(regressors) == len(name_regressors)\n",
    "    regressors =  [rnn16_model, lstm16_model, cnn_rnn_model, lp_model]\n",
    "    name_regressors =  [\"RNN16\", \"LSTM16\", \"CNNRNN16\", \"MLP16\"]\n",
    "    assert len(regressors) == len(name_regressors)\n",
    "    experiment_1 = PredictionExperiment(data, indices_of_interest, regressors, name_regressors, 5, id, loss_fn=SERA(bounds=bounds,T=100))\n",
    "    experiment_1.execute_experiment()\n",
    "    experiment_1.get_metrics(\"r2\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"TSCV\", show=False)\n",
    "\n",
    "    #experiment_1.top_results(\"r2\", 5, stage=\"prediction\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    #experiment_1.top_results(\"cv_r2\", 5, stage=\"CV\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    experiment_1.save_results(f\"data/sera_results/{region}_results/results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>season</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_1.parquet</td>\n",
       "      <td>1</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_2.parquet</td>\n",
       "      <td>2</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_3.parquet</td>\n",
       "      <td>3</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_4.parquet</td>\n",
       "      <td>4</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978f49d7</td>\n",
       "      <td>predictor_978f49d7_5.parquet</td>\n",
       "      <td>5</td>\n",
       "      <td>fde0e327-340e2882-43701738-e306f58b-e601b072-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_8.parquet</td>\n",
       "      <td>8</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_9.parquet</td>\n",
       "      <td>9</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_10.parquet</td>\n",
       "      <td>10</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_11.parquet</td>\n",
       "      <td>11</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>458d357c</td>\n",
       "      <td>predictor_458d357c_12.parquet</td>\n",
       "      <td>12</td>\n",
       "      <td>32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                       filename  season   \n",
       "0    978f49d7   predictor_978f49d7_1.parquet       1  \\\n",
       "1    978f49d7   predictor_978f49d7_2.parquet       2   \n",
       "2    978f49d7   predictor_978f49d7_3.parquet       3   \n",
       "3    978f49d7   predictor_978f49d7_4.parquet       4   \n",
       "4    978f49d7   predictor_978f49d7_5.parquet       5   \n",
       "..        ...                            ...     ...   \n",
       "247  458d357c   predictor_458d357c_8.parquet       8   \n",
       "248  458d357c   predictor_458d357c_9.parquet       9   \n",
       "249  458d357c  predictor_458d357c_10.parquet      10   \n",
       "250  458d357c  predictor_458d357c_11.parquet      11   \n",
       "251  458d357c  predictor_458d357c_12.parquet      12   \n",
       "\n",
       "                                               indices  \n",
       "0    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "1    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "2    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "3    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "4    fde0e327-340e2882-43701738-e306f58b-e601b072-e...  \n",
       "..                                                 ...  \n",
       "247  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "248  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "249  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "250  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "251  32f131d2-69ffcfa8-4af95abb-4a86cb22-52eda853-3...  \n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region=\"chile\"\n",
    "metadata = pd.read_csv(f\"data/climate_features/{region}/metadata.csv\")\n",
    "metadata.reset_index(inplace=True, drop=True)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(f\"data/climate_results/{region}_results/results.csv\")\n",
    "ids_results = results[\"id_data\"].unique()\n",
    "id_experiments = metadata[\"id\"].unique()\n",
    "ids_to_execute = [id for id in id_experiments if id not in ids_results]\n",
    "print(len(ids_to_execute))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_execute = ['b33fc639', 'ecf2577f', '458d357c', '4effa258', '9bd58418',\n",
    "       '9f8163e4', '511854f2', '30ab9bad', '8c95fd00', '978f49d7', '3832cbd6', '8359c65d',\n",
    "       'd7101242', '3adff093', '311dd366',\n",
    "       '3df87a13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 3832cbd6 iter 1\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 831ms/step - loss: 16.9825 - val_loss: 7.2536\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 16.9690 - val_loss: 7.1011\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.8783 - val_loss: 6.9296\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.7931 - val_loss: 6.7539\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.8485 - val_loss: 6.6009\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.2780 - val_loss: 6.4834\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.5043 - val_loss: 6.3719\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.5610 - val_loss: 6.2658\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.9500 - val_loss: 6.1440\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.9897 - val_loss: 6.0344\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.1241 - val_loss: 5.9361\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.0590 - val_loss: 5.7925\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7533 - val_loss: 5.6787\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.0489 - val_loss: 5.5727\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.6423 - val_loss: 5.4633\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.9820 - val_loss: 5.3442\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.9913 - val_loss: 5.2260\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0934 - val_loss: 5.1343\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.9674 - val_loss: 5.0350\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.4726 - val_loss: 4.9377\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.0699 - val_loss: 4.8522\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.8251 - val_loss: 4.7988\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1452 - val_loss: 4.7237\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.1602 - val_loss: 4.6599\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.1575 - val_loss: 4.6067\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.0463 - val_loss: 4.5697\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.4083 - val_loss: 4.5327\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2634 - val_loss: 4.4754\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.9449 - val_loss: 4.4265\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7471 - val_loss: 4.3924\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6535 - val_loss: 4.3761\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.1672 - val_loss: 4.3559\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.9647 - val_loss: 4.3398\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8442 - val_loss: 4.3314\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2981 - val_loss: 4.3140\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.5435 - val_loss: 4.3197\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9949 - val_loss: 4.3475\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.9755 - val_loss: 4.3592\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.1387 - val_loss: 4.3826\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8965 - val_loss: 4.4245\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8974 - val_loss: 4.4438\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.9172 - val_loss: 4.4771\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.0834 - val_loss: 4.5017\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.7451 - val_loss: 4.5184\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7166 - val_loss: 4.5406\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 862ms/step - loss: 15.5744 - val_loss: 6.7048\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.4717 - val_loss: 6.6070\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.5043 - val_loss: 6.5016\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.0153 - val_loss: 6.3889\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.2301 - val_loss: 6.2770\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.9000 - val_loss: 6.1853\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.2569 - val_loss: 6.0756\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.4700 - val_loss: 5.9698\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.0145 - val_loss: 5.8588\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.0585 - val_loss: 5.7450\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.6909 - val_loss: 5.6496\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.2237 - val_loss: 5.5501\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.3555 - val_loss: 5.4445\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.5991 - val_loss: 5.3457\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.8752 - val_loss: 5.2493\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.8697 - val_loss: 5.1497\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.7998 - val_loss: 5.0356\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.8483 - val_loss: 4.9496\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 11.2483 - val_loss: 4.8544\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.1851 - val_loss: 4.7664\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.9208 - val_loss: 4.6916\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5310 - val_loss: 4.6332\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.7090 - val_loss: 4.5666\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.6151 - val_loss: 4.5054\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1791 - val_loss: 4.4498\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1656 - val_loss: 4.4159\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0884 - val_loss: 4.3792\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7196 - val_loss: 4.3500\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8414 - val_loss: 4.3177\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0460 - val_loss: 4.2915\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6324 - val_loss: 4.2784\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8107 - val_loss: 4.2684\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2024 - val_loss: 4.2618\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8909 - val_loss: 4.2603\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.2724 - val_loss: 4.2565\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.1143 - val_loss: 4.2632\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.7010 - val_loss: 4.2838\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3097 - val_loss: 4.2936\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6247 - val_loss: 4.2916\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2269 - val_loss: 4.3036\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4872 - val_loss: 4.3107\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.2567 - val_loss: 4.3280\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.7295 - val_loss: 4.3404\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.2582 - val_loss: 4.3474\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3622 - val_loss: 4.3495\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 757ms/step - loss: 19.3680 - val_loss: 6.5862\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.3492 - val_loss: 6.4398\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.9765 - val_loss: 6.2814\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.1730 - val_loss: 6.1282\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.2770 - val_loss: 5.9925\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.4277 - val_loss: 5.8897\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.0231 - val_loss: 5.7779\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.8277 - val_loss: 5.6870\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.3486 - val_loss: 5.6021\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.1954 - val_loss: 5.5188\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.2144 - val_loss: 5.4538\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.2765 - val_loss: 5.3873\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.1589 - val_loss: 5.3105\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.7265 - val_loss: 5.2405\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.4238 - val_loss: 5.1790\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.4263 - val_loss: 5.1163\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.0207 - val_loss: 5.0527\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.2380 - val_loss: 5.0063\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.2212 - val_loss: 4.9563\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.3719 - val_loss: 4.8981\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.6360 - val_loss: 4.8536\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9690 - val_loss: 4.8161\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.7083 - val_loss: 4.7698\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6182 - val_loss: 4.7164\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.0797 - val_loss: 4.6727\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.9169 - val_loss: 4.6380\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5828 - val_loss: 4.6068\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0474 - val_loss: 4.5780\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.6370 - val_loss: 4.5552\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.9641 - val_loss: 4.5336\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1255 - val_loss: 4.5269\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9024 - val_loss: 4.5182\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2382 - val_loss: 4.5161\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.4517 - val_loss: 4.5096\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0589 - val_loss: 4.4988\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.6674 - val_loss: 4.4983\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.2153 - val_loss: 4.5128\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0918 - val_loss: 4.5220\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6746 - val_loss: 4.5294\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4568 - val_loss: 4.5546\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6597 - val_loss: 4.5678\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2885 - val_loss: 4.5925\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5337 - val_loss: 4.6113\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9626 - val_loss: 4.6263\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1970 - val_loss: 4.6459\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4298 - val_loss: 4.6614\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 779ms/step - loss: 19.3521 - val_loss: 8.2283\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 18.6744 - val_loss: 8.0256\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.0724 - val_loss: 7.8286\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 18.1728 - val_loss: 7.6675\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 16.8547 - val_loss: 7.5168\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.2590 - val_loss: 7.3942\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.5971 - val_loss: 7.2832\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 16.0737 - val_loss: 7.1939\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.6504 - val_loss: 7.1088\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.2299 - val_loss: 7.0335\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.0635 - val_loss: 6.9581\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.2907 - val_loss: 6.9079\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.8055 - val_loss: 6.8615\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.9233 - val_loss: 6.8264\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.9302 - val_loss: 6.7949\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5495 - val_loss: 6.7666\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.3064 - val_loss: 6.7606\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6746 - val_loss: 6.7517\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.0273 - val_loss: 6.7587\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5254 - val_loss: 6.7560\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.9183 - val_loss: 6.7449\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.1413 - val_loss: 6.7415\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.2771 - val_loss: 6.7356\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0788 - val_loss: 6.7464\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.2322 - val_loss: 6.7387\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.6884 - val_loss: 6.7230\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.5058 - val_loss: 6.6889\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2016 - val_loss: 6.6657\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8210 - val_loss: 6.6693\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.0991 - val_loss: 6.6751\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5515 - val_loss: 6.6609\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0563 - val_loss: 6.6478\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3607 - val_loss: 6.6472\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8758 - val_loss: 6.6314\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.0977 - val_loss: 6.6177\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7060 - val_loss: 6.6189\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.5174 - val_loss: 6.6009\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.3286 - val_loss: 6.5853\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4385 - val_loss: 6.6000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.3219 - val_loss: 6.5752\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6139 - val_loss: 6.5796\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.4192 - val_loss: 6.5790\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.9439 - val_loss: 6.5763\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6745 - val_loss: 6.5624\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8574 - val_loss: 6.5677\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8437 - val_loss: 6.5432\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.1925 - val_loss: 6.5141\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.7259 - val_loss: 6.4980\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1962 - val_loss: 6.4906\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8231 - val_loss: 6.4746\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.1286 - val_loss: 6.4734\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0596 - val_loss: 6.4970\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.2168 - val_loss: 6.5431\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.2572 - val_loss: 6.5746\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.1332 - val_loss: 6.5853\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.6306 - val_loss: 6.5845\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.9990 - val_loss: 6.5623\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.7387 - val_loss: 6.5371\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9413 - val_loss: 6.5182\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.7085 - val_loss: 6.5141\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6379 - val_loss: 6.4780\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 7.1911 - val_loss: 21.0083\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6081 - val_loss: 21.1723\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.0051 - val_loss: 21.3483\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8743 - val_loss: 21.3008\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.0473 - val_loss: 21.4110\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.7255 - val_loss: 21.3041\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4833 - val_loss: 21.1819\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4684 - val_loss: 21.0842\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.3595 - val_loss: 20.9042\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4306 - val_loss: 20.5658\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.5907 - val_loss: 20.4198\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9335 - val_loss: 20.2554\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9527 - val_loss: 20.0666\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.1913 - val_loss: 19.8086\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6229 - val_loss: 19.5401\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9887 - val_loss: 19.2474\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4769 - val_loss: 18.8966\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.1993 - val_loss: 18.6370\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.2119 - val_loss: 18.4543\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.6883 - val_loss: 18.3213\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.0554 - val_loss: 18.2405\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.6771 - val_loss: 18.0071\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.8406 - val_loss: 17.8414\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.0899 - val_loss: 17.7555\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.3321 - val_loss: 17.5421\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2422 - val_loss: 17.3615\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.0637 - val_loss: 17.1694\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.3777 - val_loss: 16.9308\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.1419 - val_loss: 16.7705\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.2322 - val_loss: 16.5893\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.1084 - val_loss: 16.3956\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.5235 - val_loss: 16.1711\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.4276 - val_loss: 16.0086\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.4442 - val_loss: 15.7497\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.8796 - val_loss: 15.6026\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.9836 - val_loss: 15.4206\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.8893 - val_loss: 15.3958\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4636 - val_loss: 15.2865\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.9717 - val_loss: 15.2132\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.9487 - val_loss: 14.9009\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.0496 - val_loss: 14.6329\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1815 - val_loss: 14.4942\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1742 - val_loss: 14.3297\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.5282 - val_loss: 14.1600\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1266 - val_loss: 14.2024\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.4359 - val_loss: 14.2022\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.0373 - val_loss: 14.2539\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0753 - val_loss: 14.1986\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3429 - val_loss: 14.0946\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4306 - val_loss: 14.0621\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4328 - val_loss: 13.9307\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.3430 - val_loss: 13.8442\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7117 - val_loss: 13.7821\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.2028 - val_loss: 13.6643\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7337 - val_loss: 13.6658\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.8526 - val_loss: 13.5453\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8911 - val_loss: 13.4191\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.2495 - val_loss: 13.2474\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.5773 - val_loss: 13.0373\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.8811 - val_loss: 12.9199\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9321 - val_loss: 12.7609\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.8028 - val_loss: 12.8167\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2924 - val_loss: 12.8536\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6593 - val_loss: 12.8733\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6919 - val_loss: 12.7130\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6121 - val_loss: 12.3961\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8173 - val_loss: 12.2499\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4607 - val_loss: 12.2334\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.6629 - val_loss: 12.2221\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3841 - val_loss: 12.3198\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.3822 - val_loss: 12.5230\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2891 - val_loss: 12.6525\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3726 - val_loss: 12.6486\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.4759 - val_loss: 12.5382\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3292 - val_loss: 12.3812\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.6194 - val_loss: 12.2143\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0561 - val_loss: 12.1161\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2789 - val_loss: 12.1607\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.3211 - val_loss: 12.1777\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2738 - val_loss: 12.1277\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0806 - val_loss: 11.9682\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1628 - val_loss: 11.8263\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4009 - val_loss: 11.6831\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.0607 - val_loss: 11.6538\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1112 - val_loss: 11.5899\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.2833 - val_loss: 11.5874\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1150 - val_loss: 11.7609\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1181 - val_loss: 11.8992\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9220 - val_loss: 11.9415\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9301 - val_loss: 11.8451\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9457 - val_loss: 11.6798\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2225 - val_loss: 11.4378\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0833 - val_loss: 11.3129\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0679 - val_loss: 11.2867\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9280 - val_loss: 11.3796\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9773 - val_loss: 11.4869\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0556 - val_loss: 11.7028\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7957 - val_loss: 11.9907\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7667 - val_loss: 12.1721\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8392 - val_loss: 11.9532\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0337 - val_loss: 11.6565\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7506 - val_loss: 11.5861\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9374 - val_loss: 11.5701\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9409 - val_loss: 11.4713\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 5.7941 - val_loss: 13.6178\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.8363 - val_loss: 13.6905\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3030 - val_loss: 13.8541\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6483 - val_loss: 13.9656\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5861 - val_loss: 14.1192\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.3312 - val_loss: 14.0926\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2338 - val_loss: 14.1122\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2297 - val_loss: 14.1245\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1098 - val_loss: 14.0740\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.9773 - val_loss: 13.9204\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.8961 - val_loss: 13.8165\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 812ms/step - loss: 5.8313 - val_loss: 21.2030\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6680 - val_loss: 21.2428\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.9936 - val_loss: 21.2424\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5267 - val_loss: 21.1697\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1697 - val_loss: 21.2545\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.8908 - val_loss: 21.3539\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1660 - val_loss: 21.4590\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4381 - val_loss: 21.4367\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1201 - val_loss: 21.3763\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.8476 - val_loss: 21.1956\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.9781 - val_loss: 21.1310\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5445 - val_loss: 21.0594\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.6182 - val_loss: 20.9959\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.5835 - val_loss: 20.7747\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.5567 - val_loss: 20.6352\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4751 - val_loss: 20.6624\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.4431 - val_loss: 20.6546\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9089 - val_loss: 20.6708\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4014 - val_loss: 20.6228\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9506 - val_loss: 20.4618\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.2904 - val_loss: 20.4659\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9435 - val_loss: 20.3853\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.2533 - val_loss: 20.3272\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.8596 - val_loss: 20.2252\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.6418 - val_loss: 19.9217\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5569 - val_loss: 19.7477\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.4787 - val_loss: 19.5572\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.8662 - val_loss: 19.3977\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4241 - val_loss: 19.3971\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.1213 - val_loss: 19.3975\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2739 - val_loss: 19.2565\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.3614 - val_loss: 19.0758\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.1411 - val_loss: 19.1125\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9454 - val_loss: 19.0305\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0816 - val_loss: 19.0138\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.1002 - val_loss: 18.9566\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3251 - val_loss: 18.9059\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4271 - val_loss: 18.8646\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8712 - val_loss: 18.8561\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8611 - val_loss: 18.9344\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9012 - val_loss: 19.0469\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0257 - val_loss: 19.1977\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9710 - val_loss: 19.1115\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1835 - val_loss: 18.8835\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.3660 - val_loss: 18.7730\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5532 - val_loss: 18.8008\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5500 - val_loss: 18.9971\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0971 - val_loss: 19.0881\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7494 - val_loss: 19.0472\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9901 - val_loss: 19.0034\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9823 - val_loss: 18.9560\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7471 - val_loss: 18.9429\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4640 - val_loss: 18.9672\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0778 - val_loss: 18.7622\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3081 - val_loss: 18.6711\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8053 - val_loss: 18.6064\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7766 - val_loss: 18.5692\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3080 - val_loss: 18.5553\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.4513 - val_loss: 18.5293\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1589 - val_loss: 18.6401\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2900 - val_loss: 18.7019\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2711 - val_loss: 18.7613\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7462 - val_loss: 18.7643\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3335 - val_loss: 18.7097\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1551 - val_loss: 18.6684\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3874 - val_loss: 18.6046\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9594 - val_loss: 18.5828\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3452 - val_loss: 18.6193\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9618 - val_loss: 18.5546\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 783ms/step - loss: 5.0026 - val_loss: 10.5466\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2805 - val_loss: 10.7280\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5806 - val_loss: 10.8454\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1184 - val_loss: 10.8444\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5850 - val_loss: 10.8206\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3970 - val_loss: 10.8354\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.8097 - val_loss: 10.8287\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.4529 - val_loss: 10.8698\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.1570 - val_loss: 10.7741\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0598 - val_loss: 10.5695\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9594 - val_loss: 10.4003\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7646 - val_loss: 10.4007\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.2184 - val_loss: 10.4113\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.6964 - val_loss: 10.3144\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4965 - val_loss: 10.3874\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3445 - val_loss: 10.4241\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.4585 - val_loss: 10.3934\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5409 - val_loss: 10.4120\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.4282 - val_loss: 10.4401\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2408 - val_loss: 10.4540\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9859 - val_loss: 10.3809\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2062 - val_loss: 10.2586\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0978 - val_loss: 10.2167\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9030 - val_loss: 10.2811\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2795 - val_loss: 10.1758\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9265 - val_loss: 10.0861\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.6370 - val_loss: 10.0183\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9748 - val_loss: 9.8622\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2172 - val_loss: 9.8022\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6734 - val_loss: 9.7307\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8415 - val_loss: 9.6235\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8564 - val_loss: 9.4057\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8426 - val_loss: 9.2600\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.7580 - val_loss: 9.2879\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.5320 - val_loss: 9.4606\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.4269 - val_loss: 9.5285\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5614 - val_loss: 9.5606\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4235 - val_loss: 9.5873\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5010 - val_loss: 9.5109\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3969 - val_loss: 9.2775\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2945 - val_loss: 9.1366\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8528 - val_loss: 9.0337\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2975 - val_loss: 8.9442\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4688 - val_loss: 9.0799\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3145 - val_loss: 9.2182\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1774 - val_loss: 9.2630\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7672 - val_loss: 9.3253\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1586 - val_loss: 9.4731\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.5541 - val_loss: 9.6267\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8333 - val_loss: 9.7325\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1788 - val_loss: 9.8123\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2006 - val_loss: 9.7620\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0757 - val_loss: 9.7320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 801ms/step - loss: 11.1178 - val_loss: 2.4095\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.9866 - val_loss: 2.4248\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7028 - val_loss: 2.4592\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.3272 - val_loss: 2.5079\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.6462 - val_loss: 2.5218\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7665 - val_loss: 2.5496\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6977 - val_loss: 2.5797\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8014 - val_loss: 2.5951\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9183 - val_loss: 2.6223\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5691 - val_loss: 2.6777\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4624 - val_loss: 2.7515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 857ms/step - loss: 11.5720 - val_loss: 6.1128\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.6631 - val_loss: 5.9751\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 11.3072 - val_loss: 5.8459\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.1280 - val_loss: 5.7349\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0239 - val_loss: 5.6186\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.3262 - val_loss: 5.5108\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.7694 - val_loss: 5.4045\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.8442 - val_loss: 5.2984\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.1155 - val_loss: 5.1915\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.0876 - val_loss: 5.0777\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.9718 - val_loss: 5.0029\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7706 - val_loss: 4.9265\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0098 - val_loss: 4.8698\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9160 - val_loss: 4.8022\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.9264 - val_loss: 4.7381\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0360 - val_loss: 4.6741\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7433 - val_loss: 4.6042\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9218 - val_loss: 4.5588\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.3375 - val_loss: 4.5101\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.2001 - val_loss: 4.4644\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8562 - val_loss: 4.4212\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7714 - val_loss: 4.3860\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3675 - val_loss: 4.3428\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2967 - val_loss: 4.2948\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0227 - val_loss: 4.2554\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8645 - val_loss: 4.2143\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4453 - val_loss: 4.1824\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4696 - val_loss: 4.1607\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6191 - val_loss: 4.1378\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.3929 - val_loss: 4.1229\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9682 - val_loss: 4.1040\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6385 - val_loss: 4.0884\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6558 - val_loss: 4.0827\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.9938 - val_loss: 4.0863\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1419 - val_loss: 4.0817\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.1091 - val_loss: 4.0720\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1556 - val_loss: 4.0679\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.7573 - val_loss: 4.0406\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.5988 - val_loss: 4.0261\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.3639 - val_loss: 4.0469\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.9395 - val_loss: 4.0461\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.3771 - val_loss: 4.0428\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5586 - val_loss: 4.0429\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.0521 - val_loss: 4.0331\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2951 - val_loss: 4.0123\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1690 - val_loss: 4.0355\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.9120 - val_loss: 4.0432\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.9663 - val_loss: 4.0307\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5385 - val_loss: 4.0793\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.3454 - val_loss: 4.0754\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5945 - val_loss: 4.0982\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.7943 - val_loss: 4.0891\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.7117 - val_loss: 4.0742\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.0028 - val_loss: 4.0825\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.0929 - val_loss: 4.0602\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 811ms/step - loss: 9.1385 - val_loss: 1.7409\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0105 - val_loss: 1.7203\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5396 - val_loss: 1.7065\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.2180 - val_loss: 1.7067\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.9045 - val_loss: 1.7115\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9252 - val_loss: 1.7171\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.1715 - val_loss: 1.7265\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4435 - val_loss: 1.7452\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7662 - val_loss: 1.7623\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.0750 - val_loss: 1.7944\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5665 - val_loss: 1.8385\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2611 - val_loss: 1.8624\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2231 - val_loss: 1.8850\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 778ms/step - loss: 15.1785 - val_loss: 5.7013\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.0189 - val_loss: 5.6218\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.4892 - val_loss: 5.5501\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.5472 - val_loss: 5.4752\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.4046 - val_loss: 5.3915\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.8490 - val_loss: 5.3155\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.4398 - val_loss: 5.2392\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.7339 - val_loss: 5.1734\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.6289 - val_loss: 5.1015\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.1341 - val_loss: 5.0535\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6987 - val_loss: 5.0015\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.0726 - val_loss: 4.9359\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.4881 - val_loss: 4.8842\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.0980 - val_loss: 4.8301\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.6912 - val_loss: 4.7931\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.4498 - val_loss: 4.7646\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0112 - val_loss: 4.7289\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0225 - val_loss: 4.7146\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.7251 - val_loss: 4.6954\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5568 - val_loss: 4.6819\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6516 - val_loss: 4.6608\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7496 - val_loss: 4.6590\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8845 - val_loss: 4.6735\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3408 - val_loss: 4.6713\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.0441 - val_loss: 4.6790\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.1392 - val_loss: 4.6629\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.1024 - val_loss: 4.6559\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8122 - val_loss: 4.6465\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0448 - val_loss: 4.6308\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4005 - val_loss: 4.6300\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.3776 - val_loss: 4.6261\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3564 - val_loss: 4.6232\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5268 - val_loss: 4.6261\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.7390 - val_loss: 4.6357\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.0781 - val_loss: 4.6415\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6002 - val_loss: 4.6626\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1855 - val_loss: 4.6735\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.5206 - val_loss: 4.6741\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1873 - val_loss: 4.6762\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.0122 - val_loss: 4.6796\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.0953 - val_loss: 4.6788\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1213 - val_loss: 4.6899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 785ms/step - loss: 16.7469 - val_loss: 3.6494\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.6657 - val_loss: 3.7710\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.7363 - val_loss: 3.9280\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.2647 - val_loss: 4.0929\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.3032 - val_loss: 4.2411\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.3524 - val_loss: 4.3612\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.1419 - val_loss: 4.5398\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.3445 - val_loss: 4.7233\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.8002 - val_loss: 4.9000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7911 - val_loss: 5.1113\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.3305 - val_loss: 5.2576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 892ms/step - loss: 13.2495 - val_loss: 2.2565\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.6929 - val_loss: 2.2160\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.6826 - val_loss: 2.2324\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.3217 - val_loss: 2.2651\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.8901 - val_loss: 2.2718\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.9207 - val_loss: 2.2768\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7721 - val_loss: 2.3129\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7446 - val_loss: 2.3458\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.9535 - val_loss: 2.3766\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.6257 - val_loss: 2.4389\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.5428 - val_loss: 2.4579\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.7114 - val_loss: 2.4742\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 804ms/step - loss: 12.6468 - val_loss: 1.5806\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.0861 - val_loss: 1.5818\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5542 - val_loss: 1.6161\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.2749 - val_loss: 1.6519\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.8152 - val_loss: 1.6639\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0994 - val_loss: 1.6672\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.5970 - val_loss: 1.6999\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7470 - val_loss: 1.7347\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.3670 - val_loss: 1.7828\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.3679 - val_loss: 1.8444\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.6415 - val_loss: 1.8876\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 782ms/step - loss: 16.0883 - val_loss: 3.4373\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.0015 - val_loss: 3.3981\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.0083 - val_loss: 3.3791\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.8658 - val_loss: 3.3798\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.5481 - val_loss: 3.3888\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.8531 - val_loss: 3.3822\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.0356 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.8986 - val_loss: 3.4777\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.2821 - val_loss: 3.5275\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.3692 - val_loss: 3.6065\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.2602 - val_loss: 3.6300\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.1603 - val_loss: 3.6443\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.9762 - val_loss: 3.6916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 804ms/step - loss: 10.0405 - val_loss: 77.1521\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5334 - val_loss: 76.8013\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5099 - val_loss: 76.6045\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.0325 - val_loss: 76.2743\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5786 - val_loss: 76.1784\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.4048 - val_loss: 75.9305\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8254 - val_loss: 75.6945\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9267 - val_loss: 75.4448\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3845 - val_loss: 75.4414\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8068 - val_loss: 75.2301\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8697 - val_loss: 74.9949\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.6028 - val_loss: 74.6609\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.6671 - val_loss: 74.6708\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5564 - val_loss: 74.5991\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9383 - val_loss: 74.3760\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7078 - val_loss: 74.3284\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8977 - val_loss: 74.0459\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.3545 - val_loss: 73.8694\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.4159 - val_loss: 73.8826\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1493 - val_loss: 73.9157\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.7260 - val_loss: 73.7934\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4892 - val_loss: 73.8621\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4691 - val_loss: 74.0030\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.5903 - val_loss: 73.9247\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.1798 - val_loss: 73.9344\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0509 - val_loss: 73.9400\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.0109 - val_loss: 73.8270\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.9864 - val_loss: 73.7858\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2744 - val_loss: 73.8039\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9752 - val_loss: 73.9658\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.3005 - val_loss: 74.0494\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.3825 - val_loss: 73.8901\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.6269 - val_loss: 73.9874\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.3323 - val_loss: 74.1008\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.1633 - val_loss: 74.0686\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.2385 - val_loss: 73.8956\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2235 - val_loss: 73.6831\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4906 - val_loss: 73.4044\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.3992 - val_loss: 73.4410\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1719 - val_loss: 73.5606\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.8898 - val_loss: 73.3850\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.4417 - val_loss: 73.2253\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.2223 - val_loss: 72.9556\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.6862 - val_loss: 72.7697\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5906 - val_loss: 72.5869\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.2570 - val_loss: 72.2187\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.4133 - val_loss: 71.8258\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4479 - val_loss: 71.6075\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0040 - val_loss: 71.2656\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.7198 - val_loss: 71.3501\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7462 - val_loss: 71.1584\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2646 - val_loss: 71.0165\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2333 - val_loss: 70.9225\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.8617 - val_loss: 70.8391\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2939 - val_loss: 70.6996\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4467 - val_loss: 70.7131\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6330 - val_loss: 70.5188\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5600 - val_loss: 70.5804\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.6783 - val_loss: 70.4721\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3118 - val_loss: 70.4630\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1567 - val_loss: 70.2484\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.3014 - val_loss: 70.4135\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8675 - val_loss: 70.6584\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9890 - val_loss: 70.4529\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4213 - val_loss: 70.6180\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0705 - val_loss: 70.0887\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1393 - val_loss: 70.0279\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2798 - val_loss: 70.0981\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8602 - val_loss: 70.4377\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4552 - val_loss: 70.6349\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5740 - val_loss: 70.6109\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4314 - val_loss: 70.3500\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6303 - val_loss: 70.1353\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8293 - val_loss: 69.9674\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4073 - val_loss: 70.1226\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3791 - val_loss: 70.2797\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7044 - val_loss: 70.1532\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5488 - val_loss: 70.1916\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2973 - val_loss: 70.3623\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.1721 - val_loss: 70.2180\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8082 - val_loss: 69.8714\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9205 - val_loss: 69.7792\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.0292 - val_loss: 69.3199\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1355 - val_loss: 68.9615\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1490 - val_loss: 68.2776\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9107 - val_loss: 67.6358\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3637 - val_loss: 67.3317\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2969 - val_loss: 67.0712\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3991 - val_loss: 67.2137\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6118 - val_loss: 67.5910\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0622 - val_loss: 67.5659\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8681 - val_loss: 66.8781\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9949 - val_loss: 66.8702\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2714 - val_loss: 66.8036\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2828 - val_loss: 66.7647\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.0456 - val_loss: 66.5371\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2358 - val_loss: 66.1396\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0133 - val_loss: 66.0821\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9902 - val_loss: 66.2781\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7103 - val_loss: 66.3014\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2830 - val_loss: 65.5901\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4884 - val_loss: 65.0052\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1823 - val_loss: 64.7957\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4007 - val_loss: 65.0651\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3440 - val_loss: 65.1621\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0841 - val_loss: 65.4263\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0787 - val_loss: 65.3445\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8068 - val_loss: 65.1733\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8320 - val_loss: 64.8438\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6851 - val_loss: 64.7870\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8084 - val_loss: 64.5762\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2597 - val_loss: 64.3431\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5453 - val_loss: 64.0544\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0417 - val_loss: 63.4322\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.2963 - val_loss: 62.9142\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6150 - val_loss: 62.6665\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9169 - val_loss: 62.2061\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2924 - val_loss: 62.5171\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.7410 - val_loss: 62.7667\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8654 - val_loss: 63.3105\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4414 - val_loss: 63.7443\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.9411 - val_loss: 64.4120\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0028 - val_loss: 64.6672\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.7681 - val_loss: 65.1200\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3382 - val_loss: 65.0117\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9952 - val_loss: 64.6924\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9205 - val_loss: 64.2884\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 865ms/step - loss: 10.0808 - val_loss: 64.2977\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.7302 - val_loss: 64.8551\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.6424 - val_loss: 65.5173\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.8549 - val_loss: 66.0157\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7641 - val_loss: 66.8242\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.1255 - val_loss: 67.3279\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.4872 - val_loss: 67.8247\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.6310 - val_loss: 68.2843\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8924 - val_loss: 68.9386\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8655 - val_loss: 69.3667\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.1259 - val_loss: 69.7130\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 819ms/step - loss: 9.4960 - val_loss: 61.9323\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5383 - val_loss: 62.5517\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.3450 - val_loss: 63.1895\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.8464 - val_loss: 63.5705\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2934 - val_loss: 64.1537\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.3921 - val_loss: 64.5872\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7481 - val_loss: 64.9536\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.3685 - val_loss: 65.2532\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0730 - val_loss: 65.6115\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8953 - val_loss: 65.7232\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2133 - val_loss: 65.7886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 780ms/step - loss: 9.2180 - val_loss: 62.4951\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5099 - val_loss: 62.7827\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3517 - val_loss: 63.2184\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.1470 - val_loss: 63.4401\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.5180 - val_loss: 63.9165\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0058 - val_loss: 64.2325\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7915 - val_loss: 64.5347\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.7031 - val_loss: 64.7663\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.5946 - val_loss: 65.0973\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5145 - val_loss: 65.2894\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1043 - val_loss: 65.5442\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 811ms/step - loss: 15.2708 - val_loss: 10.3008\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 15.7068 - val_loss: 10.2732\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.2040 - val_loss: 10.2602\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.8411 - val_loss: 10.2538\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.4619 - val_loss: 10.2721\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.9392 - val_loss: 10.2997\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.9490 - val_loss: 10.3223\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7320 - val_loss: 10.3736\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.7895 - val_loss: 10.4298\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.5481 - val_loss: 10.4410\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.7807 - val_loss: 10.4729\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.0996 - val_loss: 10.5207\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5642 - val_loss: 10.5458\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5104 - val_loss: 10.5923\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 868ms/step - loss: 10.9114 - val_loss: 7.1998\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.0564 - val_loss: 7.1898\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5311 - val_loss: 7.1862\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0177 - val_loss: 7.1987\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.8188 - val_loss: 7.1917\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5633 - val_loss: 7.1873\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7484 - val_loss: 7.1880\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.4419 - val_loss: 7.1929\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.8870 - val_loss: 7.1980\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.4134 - val_loss: 7.1864\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.6187 - val_loss: 7.1854\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2384 - val_loss: 7.1721\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9417 - val_loss: 7.1645\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5152 - val_loss: 7.1583\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3523 - val_loss: 7.1499\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.3295 - val_loss: 7.1435\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.1450 - val_loss: 7.1399\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4495 - val_loss: 7.1323\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4087 - val_loss: 7.1314\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.7817 - val_loss: 7.1292\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4859 - val_loss: 7.1322\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.5644 - val_loss: 7.1446\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3255 - val_loss: 7.1527\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2573 - val_loss: 7.1619\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.1061 - val_loss: 7.1771\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.0218 - val_loss: 7.1952\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.8635 - val_loss: 7.2127\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6348 - val_loss: 7.2204\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8259 - val_loss: 7.2330\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8364 - val_loss: 7.2492\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 795ms/step - loss: 11.1551 - val_loss: 10.1338\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.2198 - val_loss: 10.0828\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5432 - val_loss: 10.0449\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.8437 - val_loss: 10.0530\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1881 - val_loss: 10.0868\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.1607 - val_loss: 10.1425\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9680 - val_loss: 10.2145\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.1471 - val_loss: 10.3299\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5483 - val_loss: 10.4592\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8093 - val_loss: 10.5940\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9905 - val_loss: 10.7481\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.8538 - val_loss: 10.9345\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8630 - val_loss: 11.0475\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 762ms/step - loss: 16.8810 - val_loss: 6.6376\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.3813 - val_loss: 6.6758\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.2426 - val_loss: 6.7100\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.7018 - val_loss: 6.7631\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.5676 - val_loss: 6.8147\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.9925 - val_loss: 6.8646\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.9414 - val_loss: 6.9212\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.4192 - val_loss: 6.9731\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.9566 - val_loss: 7.0200\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.1596 - val_loss: 7.0664\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.1007 - val_loss: 7.1090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 819ms/step - loss: 17.6075 - val_loss: 7.5033\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.2097 - val_loss: 7.4834\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 17.1792 - val_loss: 7.4446\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.2672 - val_loss: 7.4038\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.2867 - val_loss: 7.3327\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 16.2220 - val_loss: 7.2403\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.5049 - val_loss: 7.1715\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.3999 - val_loss: 7.1366\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.8466 - val_loss: 7.0751\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.9335 - val_loss: 7.0081\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.5441 - val_loss: 6.9695\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.7610 - val_loss: 6.8876\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.5456 - val_loss: 6.7898\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.4516 - val_loss: 6.7710\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.7724 - val_loss: 6.7339\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.3820 - val_loss: 6.6799\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.5957 - val_loss: 6.6622\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.2717 - val_loss: 6.6274\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.2574 - val_loss: 6.5896\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.1212 - val_loss: 6.5341\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.9225 - val_loss: 6.4712\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.3044 - val_loss: 6.4425\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.1578 - val_loss: 6.3820\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.8766 - val_loss: 6.3371\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.7470 - val_loss: 6.2917\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.4750 - val_loss: 6.2258\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7245 - val_loss: 6.1867\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.4147 - val_loss: 6.0987\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.5117 - val_loss: 6.0473\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.0726 - val_loss: 5.9849\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.4323 - val_loss: 5.9006\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.2286 - val_loss: 5.8095\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.0623 - val_loss: 5.7672\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.9901 - val_loss: 5.6915\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6916 - val_loss: 5.6633\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5667 - val_loss: 5.6077\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0465 - val_loss: 5.5463\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.8575 - val_loss: 5.4705\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5538 - val_loss: 5.4382\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.7053 - val_loss: 5.3956\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.9704 - val_loss: 5.3388\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0956 - val_loss: 5.3001\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9248 - val_loss: 5.2606\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.3328 - val_loss: 5.1999\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.1984 - val_loss: 5.1337\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.3150 - val_loss: 5.0942\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.9709 - val_loss: 5.0523\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.1520 - val_loss: 4.9844\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6247 - val_loss: 4.9367\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8457 - val_loss: 4.8516\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0494 - val_loss: 4.8098\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8739 - val_loss: 4.8015\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4259 - val_loss: 4.7724\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4235 - val_loss: 4.7518\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3442 - val_loss: 4.7530\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.9715 - val_loss: 4.7369\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.9961 - val_loss: 4.7138\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.5301 - val_loss: 4.6625\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5903 - val_loss: 4.5424\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5371 - val_loss: 4.4664\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.9997 - val_loss: 4.4414\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2814 - val_loss: 4.4334\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.7764 - val_loss: 4.4267\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3308 - val_loss: 4.4039\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6398 - val_loss: 4.3423\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7916 - val_loss: 4.2898\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.0611 - val_loss: 4.2479\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.5102 - val_loss: 4.2102\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.8044 - val_loss: 4.1915\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.0770 - val_loss: 4.1401\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6002 - val_loss: 4.0638\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.7730 - val_loss: 4.0131\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.6761 - val_loss: 3.9849\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.5845 - val_loss: 3.9464\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.7658 - val_loss: 3.9856\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1074 - val_loss: 3.9714\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2215 - val_loss: 3.9241\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6032 - val_loss: 3.8256\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.6473 - val_loss: 3.7386\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5080 - val_loss: 3.6390\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1201 - val_loss: 3.5694\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1734 - val_loss: 3.5214\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2315 - val_loss: 3.5017\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.8135 - val_loss: 3.5256\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.8353 - val_loss: 3.5137\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1514 - val_loss: 3.4872\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.3686 - val_loss: 3.4937\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2837 - val_loss: 3.4964\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4442 - val_loss: 3.5325\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.1829 - val_loss: 3.5407\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.8418 - val_loss: 3.5725\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.4057 - val_loss: 3.6089\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.6993 - val_loss: 3.6415\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1080 - val_loss: 3.6723\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.9416 - val_loss: 3.6861\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.3983 - val_loss: 3.7442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 865ms/step - loss: 17.3709 - val_loss: 3.8435\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.0926 - val_loss: 3.9314\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.5145 - val_loss: 3.9992\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.3502 - val_loss: 4.0790\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.8074 - val_loss: 4.1313\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.0497 - val_loss: 4.1797\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.5233 - val_loss: 4.2305\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.1356 - val_loss: 4.2907\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.7707 - val_loss: 4.3380\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.6202 - val_loss: 4.3889\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.8329 - val_loss: 4.4348\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 914ms/step - loss: 14.8662 - val_loss: 6.9393\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.6479 - val_loss: 6.7386\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 12.7423 - val_loss: 6.5840\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.3305 - val_loss: 6.4201\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 12.1525 - val_loss: 6.2441\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.8714 - val_loss: 6.0976\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.7518 - val_loss: 5.9423\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.2646 - val_loss: 5.8308\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.5564 - val_loss: 5.7497\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.9130 - val_loss: 5.6713\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.2050 - val_loss: 5.6534\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.3406 - val_loss: 5.5994\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.1170 - val_loss: 5.5311\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0049 - val_loss: 5.5524\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5181 - val_loss: 5.5591\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9221 - val_loss: 5.5283\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.5696 - val_loss: 5.4856\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9483 - val_loss: 5.4834\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2592 - val_loss: 5.4546\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.0760 - val_loss: 5.3388\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.2305 - val_loss: 5.2954\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.7292 - val_loss: 5.3005\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.1572 - val_loss: 5.2204\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.1466 - val_loss: 5.1806\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.2684 - val_loss: 5.1734\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7237 - val_loss: 5.1460\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4422 - val_loss: 5.1439\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.7777 - val_loss: 5.0133\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.0266 - val_loss: 5.0096\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.1156 - val_loss: 4.9696\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.1280 - val_loss: 4.9062\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0343 - val_loss: 4.8728\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.1297 - val_loss: 4.8765\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.7065 - val_loss: 4.8110\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.6002 - val_loss: 4.7671\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9839 - val_loss: 4.7386\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8391 - val_loss: 4.7233\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8014 - val_loss: 4.5793\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.2222 - val_loss: 4.4551\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7048 - val_loss: 4.3764\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.7357 - val_loss: 4.2815\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.0774 - val_loss: 4.2562\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.2928 - val_loss: 4.2192\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.7931 - val_loss: 4.1161\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.5915 - val_loss: 4.0317\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.0624 - val_loss: 3.9793\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.7538 - val_loss: 3.9057\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5371 - val_loss: 3.8606\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.0110 - val_loss: 3.8057\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.9792 - val_loss: 3.6961\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.9050 - val_loss: 3.6269\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.7761 - val_loss: 3.5878\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.0476 - val_loss: 3.5125\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2419 - val_loss: 3.4255\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1334 - val_loss: 3.3511\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2631 - val_loss: 3.2939\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.1310 - val_loss: 3.2310\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.7564 - val_loss: 3.1901\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.8227 - val_loss: 3.1034\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3453 - val_loss: 3.0763\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8268 - val_loss: 3.0452\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7150 - val_loss: 3.0224\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5616 - val_loss: 2.9725\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.1691 - val_loss: 2.9610\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.9379 - val_loss: 2.9203\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.0891 - val_loss: 2.8798\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.8172 - val_loss: 2.8195\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9176 - val_loss: 2.7866\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4209 - val_loss: 2.7979\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3524 - val_loss: 2.8077\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.9187 - val_loss: 2.7601\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.5217 - val_loss: 2.7359\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3545 - val_loss: 2.7344\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9359 - val_loss: 2.7100\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0134 - val_loss: 2.6561\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8683 - val_loss: 2.6036\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.8302 - val_loss: 2.5854\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9201 - val_loss: 2.5571\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0743 - val_loss: 2.5546\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.5693 - val_loss: 2.5492\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.7511 - val_loss: 2.5606\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8805 - val_loss: 2.5363\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9780 - val_loss: 2.5472\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.6366 - val_loss: 2.5475\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7859 - val_loss: 2.5115\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4120 - val_loss: 2.4950\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5378 - val_loss: 2.4967\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.3674 - val_loss: 2.5234\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8328 - val_loss: 2.5530\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3611 - val_loss: 2.4927\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0074 - val_loss: 2.4592\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.4708 - val_loss: 2.4823\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2286 - val_loss: 2.4705\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7265 - val_loss: 2.4824\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4364 - val_loss: 2.5014\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0089 - val_loss: 2.4903\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8273 - val_loss: 2.4756\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.8816 - val_loss: 2.4647\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4992 - val_loss: 2.4478\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8162 - val_loss: 2.3876\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0596 - val_loss: 2.3773\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7598 - val_loss: 2.3284\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3555 - val_loss: 2.3358\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9934 - val_loss: 2.3466\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4579 - val_loss: 2.3063\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8416 - val_loss: 2.3190\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3647 - val_loss: 2.4011\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9519 - val_loss: 2.4167\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7915 - val_loss: 2.4402\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9417 - val_loss: 2.4329\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5841 - val_loss: 2.4141\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4233 - val_loss: 2.3809\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7466 - val_loss: 2.4333\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8999 - val_loss: 2.3793\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6632 - val_loss: 2.3644\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 576ms/step - loss: 17.6071 - val_loss: 5.6264\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.9711 - val_loss: 5.7156\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.7625 - val_loss: 5.7777\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.6158 - val_loss: 5.8437\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.0325 - val_loss: 5.9070\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.0256 - val_loss: 5.9636\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.0122 - val_loss: 6.0114\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.4543 - val_loss: 6.0539\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.0010 - val_loss: 6.0704\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.0991 - val_loss: 6.0714\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.8371 - val_loss: 6.1012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 610ms/step - loss: 21.7431 - val_loss: 8.0913\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 19.6066 - val_loss: 8.0339\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.7522 - val_loss: 8.0796\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 18.6593 - val_loss: 8.1021\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 17.1904 - val_loss: 8.0239\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.9375 - val_loss: 7.9655\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.3202 - val_loss: 7.8929\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.7459 - val_loss: 7.8529\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.1790 - val_loss: 7.7801\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.4544 - val_loss: 7.7376\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.3484 - val_loss: 7.7006\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.5809 - val_loss: 7.7804\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.5603 - val_loss: 7.8428\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.9883 - val_loss: 7.7468\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.8824 - val_loss: 7.6623\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.6787 - val_loss: 7.5609\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.7874 - val_loss: 7.4759\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.0917 - val_loss: 7.4208\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.6082 - val_loss: 7.4239\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.9292 - val_loss: 7.2659\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.9280 - val_loss: 7.1532\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.1201 - val_loss: 7.1010\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.2497 - val_loss: 7.0572\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.5864 - val_loss: 7.1200\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.6938 - val_loss: 7.1256\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.8456 - val_loss: 7.1348\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.0263 - val_loss: 7.1570\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.0431 - val_loss: 7.2202\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.5609 - val_loss: 7.2095\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.5152 - val_loss: 7.1642\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.3470 - val_loss: 7.2526\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.1009 - val_loss: 7.2724\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.5295 - val_loss: 7.2196\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 636ms/step - loss: 9.6196 - val_loss: 4.1087\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.3287 - val_loss: 4.0282\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.3488 - val_loss: 3.9640\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0070 - val_loss: 3.9678\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.6491 - val_loss: 3.8517\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.1191 - val_loss: 3.8672\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8279 - val_loss: 3.8321\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.6762 - val_loss: 3.7853\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.3544 - val_loss: 3.7177\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.6139 - val_loss: 3.6738\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.1950 - val_loss: 3.6704\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.5903 - val_loss: 3.6808\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.1260 - val_loss: 3.7284\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.7225 - val_loss: 3.7052\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.7562 - val_loss: 3.7051\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8802 - val_loss: 3.7271\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2085 - val_loss: 3.7448\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4358 - val_loss: 3.7440\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.5231 - val_loss: 3.7360\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.4925 - val_loss: 3.6888\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4079 - val_loss: 3.6938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 609ms/step - loss: 15.9980 - val_loss: 5.2561\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.4033 - val_loss: 5.4548\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.5335 - val_loss: 5.8026\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.8635 - val_loss: 6.0700\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.1524 - val_loss: 6.1120\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.9934 - val_loss: 6.2680\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.1839 - val_loss: 6.3116\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.8314 - val_loss: 6.3702\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.1139 - val_loss: 6.3479\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.6241 - val_loss: 6.2904\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.7795 - val_loss: 6.2548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 581ms/step - loss: 9.9907 - val_loss: 3.2237\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.7932 - val_loss: 3.2322\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.2174 - val_loss: 3.2595\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.2457 - val_loss: 3.3110\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.8598 - val_loss: 3.2918\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.8308 - val_loss: 3.3357\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.0457 - val_loss: 3.3671\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.4421 - val_loss: 3.4071\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.4195 - val_loss: 3.4253\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.6797 - val_loss: 3.4411\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.7226 - val_loss: 3.4498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 595ms/step - loss: 10.2731 - val_loss: 7.3088\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.9740 - val_loss: 6.9763\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.6752 - val_loss: 6.7467\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.1344 - val_loss: 6.5531\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8512 - val_loss: 6.3110\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3012 - val_loss: 6.1095\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3827 - val_loss: 5.9317\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5036 - val_loss: 5.7918\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3289 - val_loss: 5.6841\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6668 - val_loss: 5.5698\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.1191 - val_loss: 5.4912\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3688 - val_loss: 5.4125\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1445 - val_loss: 5.3381\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1043 - val_loss: 5.2944\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2816 - val_loss: 5.2396\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4226 - val_loss: 5.2119\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4540 - val_loss: 5.1401\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4515 - val_loss: 5.0868\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9206 - val_loss: 5.0117\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9832 - val_loss: 4.9231\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.6597 - val_loss: 4.8496\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5195 - val_loss: 4.8027\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1838 - val_loss: 4.7574\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8285 - val_loss: 4.7030\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4825 - val_loss: 4.6641\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2834 - val_loss: 4.6553\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9689 - val_loss: 4.6734\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9034 - val_loss: 4.6530\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1713 - val_loss: 4.6356\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.6431 - val_loss: 4.6280\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9699 - val_loss: 4.6535\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8895 - val_loss: 4.6489\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7258 - val_loss: 4.6387\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9083 - val_loss: 4.6206\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.0997 - val_loss: 4.6142\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8716 - val_loss: 4.6169\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5018 - val_loss: 4.6136\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9579 - val_loss: 4.5923\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0121 - val_loss: 4.5951\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4692 - val_loss: 4.6105\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0006 - val_loss: 4.6627\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5259 - val_loss: 4.7170\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3240 - val_loss: 4.7662\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7047 - val_loss: 4.8133\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7811 - val_loss: 4.8358\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2402 - val_loss: 4.8422\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4705 - val_loss: 4.8430\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4110 - val_loss: 4.8304\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 651ms/step - loss: 9.4335 - val_loss: 7.1288\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.4906 - val_loss: 6.9582\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.6727 - val_loss: 6.8408\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0269 - val_loss: 6.7324\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4466 - val_loss: 6.5958\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.0942 - val_loss: 6.4856\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5080 - val_loss: 6.3948\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9200 - val_loss: 6.3199\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6119 - val_loss: 6.2511\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9938 - val_loss: 6.1893\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.0868 - val_loss: 6.1399\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.0822 - val_loss: 6.0683\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2582 - val_loss: 6.0103\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5280 - val_loss: 5.9654\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7688 - val_loss: 5.9219\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7277 - val_loss: 5.8974\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5584 - val_loss: 5.8576\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5169 - val_loss: 5.8485\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5273 - val_loss: 5.8502\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6328 - val_loss: 5.8337\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4285 - val_loss: 5.8279\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0007 - val_loss: 5.8269\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8566 - val_loss: 5.8227\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6417 - val_loss: 5.8276\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7786 - val_loss: 5.8391\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8454 - val_loss: 5.8527\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5218 - val_loss: 5.8820\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3654 - val_loss: 5.9003\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6314 - val_loss: 5.9206\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8634 - val_loss: 5.9410\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2471 - val_loss: 5.9544\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2758 - val_loss: 5.9621\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2411 - val_loss: 5.9872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 601ms/step - loss: 13.9593 - val_loss: 8.1527\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.5452 - val_loss: 7.8486\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.1855 - val_loss: 7.6842\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.4049 - val_loss: 7.5138\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.8787 - val_loss: 7.3698\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.8334 - val_loss: 7.2180\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.3632 - val_loss: 7.0974\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.7938 - val_loss: 7.0333\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.7902 - val_loss: 6.9960\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.7004 - val_loss: 6.9520\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9387 - val_loss: 6.8576\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9858 - val_loss: 6.7619\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4641 - val_loss: 6.6983\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8556 - val_loss: 6.6573\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8292 - val_loss: 6.6126\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7366 - val_loss: 6.5697\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8999 - val_loss: 6.5310\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.4274 - val_loss: 6.4963\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.6400 - val_loss: 6.4669\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1529 - val_loss: 6.4640\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7822 - val_loss: 6.4870\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5233 - val_loss: 6.4625\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.0756 - val_loss: 6.3636\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3892 - val_loss: 6.2185\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3669 - val_loss: 6.1954\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.5539 - val_loss: 6.1502\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1656 - val_loss: 6.1704\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6508 - val_loss: 6.1257\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5046 - val_loss: 6.0779\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2216 - val_loss: 6.0849\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.4597 - val_loss: 6.0566\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5031 - val_loss: 6.0524\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9090 - val_loss: 6.0715\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9605 - val_loss: 6.0547\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.0712 - val_loss: 6.0634\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1593 - val_loss: 6.0589\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.0908 - val_loss: 6.1032\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.7087 - val_loss: 6.1164\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7025 - val_loss: 6.1234\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6021 - val_loss: 6.1372\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.2162 - val_loss: 6.1651\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4410 - val_loss: 6.2154\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 569ms/step - loss: 7.6869 - val_loss: 6.7099\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.0811 - val_loss: 6.7197\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4235 - val_loss: 6.7026\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0978 - val_loss: 6.6356\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.2042 - val_loss: 6.5773\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8585 - val_loss: 6.5612\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3216 - val_loss: 6.5308\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7999 - val_loss: 6.5016\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8328 - val_loss: 6.4588\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.2941 - val_loss: 6.4101\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9839 - val_loss: 6.3868\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.5036 - val_loss: 6.3451\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9565 - val_loss: 6.3220\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2580 - val_loss: 6.3199\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.3132 - val_loss: 6.3560\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5163 - val_loss: 6.3934\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0273 - val_loss: 6.3984\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1448 - val_loss: 6.4454\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.0988 - val_loss: 6.4465\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9107 - val_loss: 6.4380\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.3397 - val_loss: 6.3899\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9497 - val_loss: 6.4037\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2207 - val_loss: 6.3995\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8992 - val_loss: 6.3973\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 593ms/step - loss: 7.2443 - val_loss: 3.3190\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0640 - val_loss: 3.3159\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3307 - val_loss: 3.3342\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2642 - val_loss: 3.3609\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.4068 - val_loss: 3.3765\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7543 - val_loss: 3.4153\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9603 - val_loss: 3.4548\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.6760 - val_loss: 3.5034\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5583 - val_loss: 3.5409\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7700 - val_loss: 3.5669\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.3177 - val_loss: 3.5796\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4762 - val_loss: 3.5963\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 669ms/step - loss: 7.3305 - val_loss: 4.0212\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8944 - val_loss: 4.2166\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.4854 - val_loss: 4.3481\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.9477 - val_loss: 4.5259\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9971 - val_loss: 4.7168\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9024 - val_loss: 4.8376\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6927 - val_loss: 4.9429\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5066 - val_loss: 5.0351\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2491 - val_loss: 5.0943\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5124 - val_loss: 5.1404\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9683 - val_loss: 5.1906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 584ms/step - loss: 10.4807 - val_loss: 5.1080\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.5553 - val_loss: 5.2884\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.6852 - val_loss: 5.4323\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.5505 - val_loss: 5.5599\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9859 - val_loss: 5.7624\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9812 - val_loss: 5.9146\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5097 - val_loss: 6.0518\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8691 - val_loss: 6.2203\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5720 - val_loss: 6.4194\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4507 - val_loss: 6.5552\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8429 - val_loss: 6.6971\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 574ms/step - loss: 8.2109 - val_loss: 4.2575\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2848 - val_loss: 4.2307\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.7041 - val_loss: 4.2129\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.9361 - val_loss: 4.2140\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.3636 - val_loss: 4.2157\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2447 - val_loss: 4.2306\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.6890 - val_loss: 4.2386\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.0319 - val_loss: 4.2628\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7860 - val_loss: 4.2904\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5502 - val_loss: 4.3194\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3933 - val_loss: 4.3575\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.1423 - val_loss: 4.3910\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9021 - val_loss: 4.4081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 592ms/step - loss: 9.0417 - val_loss: 80.7802\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2375 - val_loss: 78.8024\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2295 - val_loss: 77.3067\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.4854 - val_loss: 75.7253\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.6340 - val_loss: 74.3524\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8909 - val_loss: 73.1454\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3605 - val_loss: 72.1295\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.7796 - val_loss: 71.0067\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.4673 - val_loss: 69.9043\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8214 - val_loss: 68.6825\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6732 - val_loss: 67.2702\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9409 - val_loss: 66.0206\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2729 - val_loss: 64.9611\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2425 - val_loss: 63.8923\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9683 - val_loss: 63.1082\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.8070 - val_loss: 62.3661\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3628 - val_loss: 61.1383\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9336 - val_loss: 60.4564\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4251 - val_loss: 59.3364\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3958 - val_loss: 58.1732\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1087 - val_loss: 57.2916\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6988 - val_loss: 56.4616\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7728 - val_loss: 55.6359\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7044 - val_loss: 54.9444\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5130 - val_loss: 54.1862\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2370 - val_loss: 53.4369\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9176 - val_loss: 52.3935\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.0970 - val_loss: 51.5797\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9041 - val_loss: 50.8522\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7739 - val_loss: 50.2544\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5491 - val_loss: 49.6488\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1231 - val_loss: 49.2548\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5650 - val_loss: 48.7991\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7097 - val_loss: 48.5745\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8407 - val_loss: 48.2983\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.1859 - val_loss: 47.9050\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7063 - val_loss: 47.6145\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2514 - val_loss: 47.2883\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4215 - val_loss: 46.7330\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2061 - val_loss: 46.6732\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0864 - val_loss: 46.4141\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4601 - val_loss: 46.3261\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8816 - val_loss: 46.3799\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9413 - val_loss: 46.0647\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4641 - val_loss: 45.8624\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7483 - val_loss: 45.7398\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7039 - val_loss: 45.7728\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9170 - val_loss: 45.8085\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2345 - val_loss: 45.6032\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1579 - val_loss: 45.6142\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9515 - val_loss: 45.5721\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.9642 - val_loss: 45.6348\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0410 - val_loss: 45.6998\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8333 - val_loss: 45.7280\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0273 - val_loss: 45.3922\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7397 - val_loss: 45.0158\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.1261 - val_loss: 44.7012\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8310 - val_loss: 44.4035\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6713 - val_loss: 44.5312\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7554 - val_loss: 44.7553\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8257 - val_loss: 44.6915\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7055 - val_loss: 44.2989\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4592 - val_loss: 44.1571\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2958 - val_loss: 44.1979\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6227 - val_loss: 44.3800\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7103 - val_loss: 44.6674\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2058 - val_loss: 44.6731\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1873 - val_loss: 44.4844\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5108 - val_loss: 44.2483\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1798 - val_loss: 44.2100\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6632 - val_loss: 44.0639\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0400 - val_loss: 44.0635\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1685 - val_loss: 44.0325\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7776 - val_loss: 44.0296\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1484 - val_loss: 44.0630\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5290 - val_loss: 44.2049\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3736 - val_loss: 44.2969\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5183 - val_loss: 43.9452\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3100 - val_loss: 43.7871\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7670 - val_loss: 44.1586\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1360 - val_loss: 44.2734\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2437 - val_loss: 44.0167\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1977 - val_loss: 43.8025\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3155 - val_loss: 43.7076\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1379 - val_loss: 43.7586\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1582 - val_loss: 44.1845\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8552 - val_loss: 44.3663\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4914 - val_loss: 44.2228\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3567 - val_loss: 43.8693\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0559 - val_loss: 43.6705\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0774 - val_loss: 43.7876\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.9902 - val_loss: 44.0071\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3851 - val_loss: 43.7475\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7995 - val_loss: 43.3675\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4935 - val_loss: 42.9727\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5876 - val_loss: 42.7776\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0896 - val_loss: 42.7422\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1294 - val_loss: 42.8692\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6077 - val_loss: 43.3717\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9659 - val_loss: 43.7942\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1733 - val_loss: 43.9363\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5337 - val_loss: 44.2243\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5280 - val_loss: 44.3528\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8770 - val_loss: 44.2387\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2571 - val_loss: 44.4774\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0835 - val_loss: 44.3875\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8331 - val_loss: 44.7865\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 651ms/step - loss: 8.1081 - val_loss: 66.0977\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5207 - val_loss: 65.6682\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5732 - val_loss: 65.3980\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0239 - val_loss: 65.1231\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0947 - val_loss: 64.7811\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.0711 - val_loss: 64.6254\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2947 - val_loss: 64.5797\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3548 - val_loss: 64.5050\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1362 - val_loss: 64.3739\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6704 - val_loss: 64.0478\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7490 - val_loss: 63.8630\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0155 - val_loss: 63.6650\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3327 - val_loss: 63.4798\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3817 - val_loss: 63.1563\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4663 - val_loss: 62.8538\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9103 - val_loss: 62.5565\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5479 - val_loss: 61.8459\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.3931 - val_loss: 61.7795\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4848 - val_loss: 61.2423\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0000 - val_loss: 60.7167\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6434 - val_loss: 60.5079\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.3959 - val_loss: 60.4194\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1221 - val_loss: 60.0844\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.0700 - val_loss: 59.8500\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9805 - val_loss: 59.7340\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6384 - val_loss: 59.5953\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6042 - val_loss: 59.2541\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5984 - val_loss: 59.0891\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9684 - val_loss: 58.8837\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2731 - val_loss: 58.5228\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5052 - val_loss: 58.2167\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8150 - val_loss: 58.0352\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1194 - val_loss: 58.0397\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2148 - val_loss: 58.2104\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1591 - val_loss: 58.3956\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1115 - val_loss: 58.5416\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1291 - val_loss: 58.7500\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6432 - val_loss: 58.8426\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9743 - val_loss: 58.7570\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8171 - val_loss: 59.0186\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5854 - val_loss: 58.9194\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3286 - val_loss: 59.0922\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 599ms/step - loss: 9.3723 - val_loss: 82.1582\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8752 - val_loss: 79.7555\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.5819 - val_loss: 78.0911\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.0720 - val_loss: 75.7147\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.3011 - val_loss: 73.8471\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8520 - val_loss: 72.7894\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5877 - val_loss: 72.2191\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5286 - val_loss: 71.1508\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8262 - val_loss: 70.2075\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5514 - val_loss: 68.8653\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3342 - val_loss: 67.6730\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6815 - val_loss: 66.9585\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2385 - val_loss: 66.8030\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4727 - val_loss: 66.2922\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4130 - val_loss: 65.7227\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9502 - val_loss: 65.0856\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7617 - val_loss: 63.9536\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5065 - val_loss: 64.4111\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8871 - val_loss: 63.3919\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8776 - val_loss: 62.3149\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9281 - val_loss: 62.0592\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3082 - val_loss: 62.3620\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0733 - val_loss: 62.4790\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4801 - val_loss: 62.9278\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0426 - val_loss: 63.1353\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5361 - val_loss: 63.4746\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9814 - val_loss: 63.2091\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3009 - val_loss: 63.5844\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6199 - val_loss: 63.9967\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7717 - val_loss: 64.1880\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2638 - val_loss: 63.8937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 602ms/step - loss: 6.9450 - val_loss: 65.7052\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0524 - val_loss: 66.1144\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.8369 - val_loss: 66.3404\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5050 - val_loss: 66.3787\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0717 - val_loss: 66.2689\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4559 - val_loss: 66.5126\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2890 - val_loss: 66.6821\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6980 - val_loss: 66.7978\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.8663 - val_loss: 66.8252\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3042 - val_loss: 66.6529\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3729 - val_loss: 66.5681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 592ms/step - loss: 8.8292 - val_loss: 8.2813\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.7151 - val_loss: 7.8080\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8047 - val_loss: 7.4464\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.8076 - val_loss: 7.1947\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8139 - val_loss: 7.0409\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0747 - val_loss: 6.8081\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7811 - val_loss: 6.6504\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0371 - val_loss: 6.5130\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8990 - val_loss: 6.4279\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1560 - val_loss: 6.3781\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6008 - val_loss: 6.3472\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3398 - val_loss: 6.3819\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0445 - val_loss: 6.3059\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0226 - val_loss: 6.1734\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0075 - val_loss: 6.0691\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4648 - val_loss: 6.0134\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4633 - val_loss: 6.0122\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2276 - val_loss: 6.1214\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9099 - val_loss: 6.1127\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7022 - val_loss: 6.0705\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.3267 - val_loss: 5.9770\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0358 - val_loss: 5.8566\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.6925 - val_loss: 5.8072\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0359 - val_loss: 5.7646\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1096 - val_loss: 5.7913\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5524 - val_loss: 5.8741\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.7925 - val_loss: 5.9412\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.7051 - val_loss: 6.0212\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2731 - val_loss: 5.9365\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6238 - val_loss: 5.9283\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3848 - val_loss: 5.8804\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2021 - val_loss: 5.8425\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1600 - val_loss: 5.6945\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0878 - val_loss: 5.5698\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.6525 - val_loss: 5.6189\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2615 - val_loss: 5.7092\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1917 - val_loss: 5.7337\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9258 - val_loss: 5.6510\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2294 - val_loss: 5.6324\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9203 - val_loss: 5.5658\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3037 - val_loss: 5.4695\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8076 - val_loss: 5.3277\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5728 - val_loss: 5.2607\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3525 - val_loss: 5.2915\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.6084 - val_loss: 5.3874\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6846 - val_loss: 5.3656\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8065 - val_loss: 5.3412\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9296 - val_loss: 5.3259\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1381 - val_loss: 5.4813\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4689 - val_loss: 5.5137\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6660 - val_loss: 5.5020\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8756 - val_loss: 5.5292\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7009 - val_loss: 5.6035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 656ms/step - loss: 8.3997 - val_loss: 13.9124\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3735 - val_loss: 13.1445\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.1180 - val_loss: 12.5413\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.1158 - val_loss: 11.9601\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7005 - val_loss: 11.5763\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8939 - val_loss: 10.9992\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.9251 - val_loss: 10.4468\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4627 - val_loss: 9.9306\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.9768 - val_loss: 9.4119\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.7865 - val_loss: 8.8689\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2590 - val_loss: 8.4602\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2021 - val_loss: 8.4005\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8416 - val_loss: 8.2781\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.1131 - val_loss: 8.1978\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.3447 - val_loss: 7.9749\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8417 - val_loss: 7.6974\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.1423 - val_loss: 7.4773\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9716 - val_loss: 7.5253\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.9163 - val_loss: 7.4712\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.9270 - val_loss: 7.3993\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8802 - val_loss: 7.2869\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7881 - val_loss: 7.0603\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.4550 - val_loss: 7.0265\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2906 - val_loss: 7.0102\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1627 - val_loss: 7.0349\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5839 - val_loss: 7.1858\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5699 - val_loss: 7.3059\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.8756 - val_loss: 7.4366\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8025 - val_loss: 7.2678\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1385 - val_loss: 7.3011\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5114 - val_loss: 7.2150\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4145 - val_loss: 7.1353\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4181 - val_loss: 7.0111\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0591 - val_loss: 6.8782\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0639 - val_loss: 6.9124\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9281 - val_loss: 6.9271\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5054 - val_loss: 6.8091\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6887 - val_loss: 6.7803\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9647 - val_loss: 6.8540\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3869 - val_loss: 6.9866\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1750 - val_loss: 7.0664\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9174 - val_loss: 7.0237\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0060 - val_loss: 7.0244\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2615 - val_loss: 7.1293\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1951 - val_loss: 7.2219\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1366 - val_loss: 7.1988\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7049 - val_loss: 7.2160\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0906 - val_loss: 7.2883\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 14s 605ms/step - loss: 8.4368 - val_loss: 7.9781\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3333 - val_loss: 7.5139\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.2800 - val_loss: 7.1822\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3083 - val_loss: 6.9206\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.7419 - val_loss: 6.7349\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5233 - val_loss: 6.5254\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2082 - val_loss: 6.4573\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.0737 - val_loss: 6.4532\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2314 - val_loss: 6.4150\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.5740 - val_loss: 6.4026\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3725 - val_loss: 6.4783\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9389 - val_loss: 6.6287\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6185 - val_loss: 6.6724\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9688 - val_loss: 6.7669\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.2900 - val_loss: 6.7809\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8972 - val_loss: 6.8229\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7764 - val_loss: 6.8155\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8261 - val_loss: 6.7880\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.8506 - val_loss: 6.7873\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2316 - val_loss: 6.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 590ms/step - loss: 9.7997 - val_loss: 11.3445\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.4425 - val_loss: 11.1475\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.2078 - val_loss: 10.8898\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.3556 - val_loss: 10.5485\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.8157 - val_loss: 10.3023\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.4438 - val_loss: 10.1266\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.4537 - val_loss: 9.8546\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.9644 - val_loss: 9.5771\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.5010 - val_loss: 9.2304\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7312 - val_loss: 8.8912\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3746 - val_loss: 8.7227\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5176 - val_loss: 8.6922\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.0249 - val_loss: 8.4919\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.0191 - val_loss: 8.3261\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.5473 - val_loss: 8.1670\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0203 - val_loss: 8.0417\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3181 - val_loss: 8.0201\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0638 - val_loss: 8.0636\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6892 - val_loss: 7.9637\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.2810 - val_loss: 7.8844\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3233 - val_loss: 7.7898\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5311 - val_loss: 7.5353\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.8261 - val_loss: 7.4018\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5023 - val_loss: 7.2058\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7075 - val_loss: 6.9591\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0631 - val_loss: 6.9356\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9606 - val_loss: 6.8005\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7294 - val_loss: 6.7646\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.7667 - val_loss: 6.5868\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5438 - val_loss: 6.5998\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0362 - val_loss: 6.5157\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5466 - val_loss: 6.4813\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2111 - val_loss: 6.3138\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1994 - val_loss: 6.3163\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6759 - val_loss: 6.4540\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1077 - val_loss: 6.5307\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2981 - val_loss: 6.5047\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.5207 - val_loss: 6.3579\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9230 - val_loss: 6.1947\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5779 - val_loss: 6.0412\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.7094 - val_loss: 5.9100\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5164 - val_loss: 5.8205\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2153 - val_loss: 5.7040\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5246 - val_loss: 5.7630\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6405 - val_loss: 5.8169\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2934 - val_loss: 5.9082\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1377 - val_loss: 6.0317\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4724 - val_loss: 6.1417\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.7949 - val_loss: 6.2455\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1268 - val_loss: 6.2272\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6998 - val_loss: 6.2078\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5373 - val_loss: 6.2266\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6927 - val_loss: 6.1725\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Executing 8359c65d iter 2\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 15s 637ms/step - loss: 18.3028 - val_loss: 6.8500\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 18.5680 - val_loss: 6.7882\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.3136 - val_loss: 6.7879\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.4219 - val_loss: 6.7639\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.3806 - val_loss: 6.7418\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.0206 - val_loss: 6.7036\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 17.0505 - val_loss: 6.6725\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.8840 - val_loss: 6.6005\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.4114 - val_loss: 6.5107\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.5564 - val_loss: 6.4360\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.9747 - val_loss: 6.3900\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.2478 - val_loss: 6.3712\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.9733 - val_loss: 6.3269\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.8103 - val_loss: 6.2899\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 16.0348 - val_loss: 6.2316\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.7136 - val_loss: 6.1842\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.3085 - val_loss: 6.1099\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.9983 - val_loss: 6.0495\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.6207 - val_loss: 5.9820\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.3716 - val_loss: 5.8870\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.3054 - val_loss: 5.8004\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.0030 - val_loss: 5.7131\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.4171 - val_loss: 5.6151\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.7490 - val_loss: 5.5183\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.8111 - val_loss: 5.4447\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.0979 - val_loss: 5.3737\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.5146 - val_loss: 5.3217\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.1852 - val_loss: 5.2518\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.2860 - val_loss: 5.1523\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.1070 - val_loss: 5.0397\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.0409 - val_loss: 4.9492\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.6335 - val_loss: 4.8675\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.5851 - val_loss: 4.8190\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.4417 - val_loss: 4.7654\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.2098 - val_loss: 4.7060\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.1359 - val_loss: 4.6512\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.7046 - val_loss: 4.6028\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.5787 - val_loss: 4.5327\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.3776 - val_loss: 4.4581\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.8442 - val_loss: 4.3981\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.8458 - val_loss: 4.3267\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.8922 - val_loss: 4.2825\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.0875 - val_loss: 4.2383\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.3150 - val_loss: 4.1400\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.3801 - val_loss: 4.0487\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.3704 - val_loss: 3.9649\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.8056 - val_loss: 3.9073\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.5463 - val_loss: 3.8775\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.0918 - val_loss: 3.8654\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.3531 - val_loss: 3.8477\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.9516 - val_loss: 3.8073\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.6047 - val_loss: 3.7774\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0690 - val_loss: 3.7434\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.1928 - val_loss: 3.7242\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0375 - val_loss: 3.7116\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.3098 - val_loss: 3.7318\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.3928 - val_loss: 3.7310\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.4015 - val_loss: 3.7341\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9670 - val_loss: 3.7381\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0766 - val_loss: 3.7325\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.1194 - val_loss: 3.7353\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9353 - val_loss: 3.7718\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.2695 - val_loss: 3.7945\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.0651 - val_loss: 3.8030\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.3778 - val_loss: 3.7928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 793ms/step - loss: 15.6810 - val_loss: 7.2765\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.6200 - val_loss: 7.2171\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.6596 - val_loss: 7.1573\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.4099 - val_loss: 7.0915\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.7812 - val_loss: 7.0262\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.3044 - val_loss: 6.9751\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.8343 - val_loss: 6.9124\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.3270 - val_loss: 6.8523\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.6353 - val_loss: 6.7916\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.9251 - val_loss: 6.7300\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.1054 - val_loss: 6.6826\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.2356 - val_loss: 6.6262\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.3737 - val_loss: 6.5658\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.8047 - val_loss: 6.5110\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.6920 - val_loss: 6.4594\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.5365 - val_loss: 6.4051\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 13.1164 - val_loss: 6.3364\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.4280 - val_loss: 6.2815\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.9162 - val_loss: 6.2172\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.7126 - val_loss: 6.1569\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.8512 - val_loss: 6.1063\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.4398 - val_loss: 6.0564\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.3182 - val_loss: 5.9892\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.6923 - val_loss: 5.9260\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.5612 - val_loss: 5.8616\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.8248 - val_loss: 5.7964\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.3848 - val_loss: 5.7247\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.2683 - val_loss: 5.6533\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.9456 - val_loss: 5.5919\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.0057 - val_loss: 5.5346\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6467 - val_loss: 5.4829\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 11.0083 - val_loss: 5.4157\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.7255 - val_loss: 5.3643\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.9463 - val_loss: 5.3105\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.3414 - val_loss: 5.2473\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.0337 - val_loss: 5.1986\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.8874 - val_loss: 5.1522\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.9992 - val_loss: 5.0966\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.4377 - val_loss: 5.0359\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.2480 - val_loss: 4.9702\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8842 - val_loss: 4.9151\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.7601 - val_loss: 4.8713\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.1438 - val_loss: 4.8155\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.6768 - val_loss: 4.7419\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.3883 - val_loss: 4.6778\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.5905 - val_loss: 4.6111\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6272 - val_loss: 4.5620\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8111 - val_loss: 4.5229\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8050 - val_loss: 4.4715\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.4147 - val_loss: 4.4173\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4079 - val_loss: 4.3534\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.3226 - val_loss: 4.3228\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7642 - val_loss: 4.2844\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.1703 - val_loss: 4.2550\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3130 - val_loss: 4.2193\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.9103 - val_loss: 4.2095\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.6969 - val_loss: 4.1915\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.6616 - val_loss: 4.1620\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3881 - val_loss: 4.1314\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.4912 - val_loss: 4.0987\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8097 - val_loss: 4.0507\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.2066 - val_loss: 4.0302\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.7693 - val_loss: 3.9991\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6500 - val_loss: 3.9789\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.8354 - val_loss: 3.9442\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.9201 - val_loss: 3.9124\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.5231 - val_loss: 3.8647\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.4910 - val_loss: 3.8415\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.0665 - val_loss: 3.8173\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.0142 - val_loss: 3.7930\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.3262 - val_loss: 3.7570\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.6592 - val_loss: 3.7287\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.0132 - val_loss: 3.7069\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.5077 - val_loss: 3.6886\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.7872 - val_loss: 3.6727\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.5244 - val_loss: 3.6487\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.8089 - val_loss: 3.6286\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.4001 - val_loss: 3.6207\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.7151 - val_loss: 3.5957\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6568 - val_loss: 3.5780\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.7495 - val_loss: 3.5593\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.6036 - val_loss: 3.5300\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.6621 - val_loss: 3.5129\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.6449 - val_loss: 3.4905\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.8031 - val_loss: 3.4706\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2395 - val_loss: 3.4326\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4619 - val_loss: 3.4031\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.4879 - val_loss: 3.3790\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9251 - val_loss: 3.3558\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.6060 - val_loss: 3.3365\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5791 - val_loss: 3.3165\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2519 - val_loss: 3.2978\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.0981 - val_loss: 3.2710\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.6029 - val_loss: 3.2336\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.8335 - val_loss: 3.2045\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3456 - val_loss: 3.1804\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3951 - val_loss: 3.1461\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.1233 - val_loss: 3.1331\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.3446 - val_loss: 3.1135\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.1372 - val_loss: 3.1006\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.1554 - val_loss: 3.0682\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.1591 - val_loss: 3.0557\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.2073 - val_loss: 3.0480\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.2314 - val_loss: 3.0257\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.6661 - val_loss: 2.9941\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9306 - val_loss: 2.9770\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.7562 - val_loss: 2.9636\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5200 - val_loss: 2.9392\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.4574 - val_loss: 2.9359\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.6212 - val_loss: 2.9357\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4445 - val_loss: 2.9098\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3586 - val_loss: 2.8907\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7753 - val_loss: 2.8660\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2897 - val_loss: 2.8513\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9601 - val_loss: 2.8342\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3477 - val_loss: 2.8416\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.0174 - val_loss: 2.8074\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3862 - val_loss: 2.7863\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8908 - val_loss: 2.7533\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6901 - val_loss: 2.7262\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7273 - val_loss: 2.6974\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6127 - val_loss: 2.6773\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1606 - val_loss: 2.6614\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9835 - val_loss: 2.6408\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.0137 - val_loss: 2.6293\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.5302 - val_loss: 2.6257\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3328 - val_loss: 2.6235\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.3577 - val_loss: 2.6132\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7231 - val_loss: 2.6008\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0661 - val_loss: 2.6034\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4530 - val_loss: 2.6062\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1378 - val_loss: 2.6119\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0917 - val_loss: 2.6238\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4045 - val_loss: 2.6055\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1260 - val_loss: 2.6181\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9264 - val_loss: 2.6076\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.2438 - val_loss: 2.6197\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4086 - val_loss: 2.6216\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7232 - val_loss: 2.5423\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.5346 - val_loss: 2.5336\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9455 - val_loss: 2.5371\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4745 - val_loss: 2.5489\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7885 - val_loss: 2.5521\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9121 - val_loss: 2.5546\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8114 - val_loss: 2.5443\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8972 - val_loss: 2.5428\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.7107 - val_loss: 2.5512\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9572 - val_loss: 2.5593\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.6835 - val_loss: 2.5943\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1692 - val_loss: 2.6139\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 923ms/step - loss: 18.8272 - val_loss: 10.4864\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 18.2208 - val_loss: 10.3070\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.2753 - val_loss: 10.1583\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.6006 - val_loss: 9.9783\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 18.1102 - val_loss: 9.8311\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.8164 - val_loss: 9.6939\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.1300 - val_loss: 9.5291\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.2182 - val_loss: 9.3807\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 16.5396 - val_loss: 9.2360\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.0844 - val_loss: 9.0565\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 16.2026 - val_loss: 8.9223\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 16.0411 - val_loss: 8.7958\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 16.6079 - val_loss: 8.6762\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.8434 - val_loss: 8.5334\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 15.7878 - val_loss: 8.4394\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.6910 - val_loss: 8.3612\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 15.6251 - val_loss: 8.2650\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.7867 - val_loss: 8.1603\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.4126 - val_loss: 8.0535\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.9553 - val_loss: 7.9487\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.0497 - val_loss: 7.8828\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.7550 - val_loss: 7.8081\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.5672 - val_loss: 7.7341\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.3484 - val_loss: 7.6734\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.4343 - val_loss: 7.6096\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.7893 - val_loss: 7.5543\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.6364 - val_loss: 7.5004\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.8698 - val_loss: 7.4202\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.8465 - val_loss: 7.3468\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 13.9702 - val_loss: 7.2727\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 12.9446 - val_loss: 7.2060\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.6317 - val_loss: 7.1109\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.9574 - val_loss: 7.0583\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.2182 - val_loss: 6.9985\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.9201 - val_loss: 6.9453\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.9493 - val_loss: 6.9061\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.0690 - val_loss: 6.8772\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 12.2281 - val_loss: 6.8145\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.3341 - val_loss: 6.7463\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.3754 - val_loss: 6.7034\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.4488 - val_loss: 6.6711\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.6469 - val_loss: 6.6801\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.2086 - val_loss: 6.6616\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.8588 - val_loss: 6.5953\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.8089 - val_loss: 6.5398\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.2030 - val_loss: 6.4830\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.0134 - val_loss: 6.4611\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.0104 - val_loss: 6.4377\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.2836 - val_loss: 6.4185\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.7333 - val_loss: 6.4102\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.2038 - val_loss: 6.3940\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.5374 - val_loss: 6.3705\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.7817 - val_loss: 6.3252\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.4284 - val_loss: 6.3461\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.9766 - val_loss: 6.3753\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8459 - val_loss: 6.4165\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.1274 - val_loss: 6.4241\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.8069 - val_loss: 6.4178\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0443 - val_loss: 6.3800\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.2979 - val_loss: 6.3507\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.3464 - val_loss: 6.3537\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.5611 - val_loss: 6.4138\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5962 - val_loss: 6.4740\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 640ms/step - loss: 21.5371 - val_loss: 8.6772\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 23.1127 - val_loss: 8.4140\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 21.0945 - val_loss: 8.1589\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 21.6781 - val_loss: 7.9953\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 21.7591 - val_loss: 7.8899\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 18.7748 - val_loss: 7.7947\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 20.3405 - val_loss: 7.7031\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 19.6331 - val_loss: 7.6258\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 18.3110 - val_loss: 7.5518\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 18.6452 - val_loss: 7.4805\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 16.6527 - val_loss: 7.4217\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.2929 - val_loss: 7.3671\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.5002 - val_loss: 7.3106\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 17.3738 - val_loss: 7.2590\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.6045 - val_loss: 7.2155\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.7758 - val_loss: 7.1670\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.6458 - val_loss: 7.0012\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.8701 - val_loss: 6.8340\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 16.6673 - val_loss: 6.6671\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.4823 - val_loss: 6.5137\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 15.5972 - val_loss: 6.4021\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.7989 - val_loss: 6.2664\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.5724 - val_loss: 6.0938\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.2609 - val_loss: 5.9717\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.8976 - val_loss: 5.8261\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 14.4297 - val_loss: 5.6817\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.8500 - val_loss: 5.5145\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 14.0361 - val_loss: 5.3589\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 13.9103 - val_loss: 5.2210\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 13.1909 - val_loss: 5.0989\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.3829 - val_loss: 5.0082\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.3762 - val_loss: 4.9062\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 13.9632 - val_loss: 4.8235\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.4824 - val_loss: 4.7476\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.6788 - val_loss: 4.6772\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12.8056 - val_loss: 4.6221\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.0976 - val_loss: 4.5712\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.7487 - val_loss: 4.4935\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 12.8811 - val_loss: 4.4167\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.9216 - val_loss: 4.3357\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.7578 - val_loss: 4.2667\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.6659 - val_loss: 4.2313\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.4927 - val_loss: 4.1851\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.4494 - val_loss: 4.1113\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.7505 - val_loss: 4.0481\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.2998 - val_loss: 4.0120\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.2703 - val_loss: 3.9645\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.8504 - val_loss: 3.9396\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.4020 - val_loss: 3.8861\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.9650 - val_loss: 3.8454\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.5755 - val_loss: 3.7820\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.2389 - val_loss: 3.7427\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 10.5601 - val_loss: 3.6708\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.3550 - val_loss: 3.6020\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.4539 - val_loss: 3.5539\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.9641 - val_loss: 3.5399\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.9825 - val_loss: 3.5069\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 11.5222 - val_loss: 3.4688\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.1467 - val_loss: 3.4268\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.3329 - val_loss: 3.3865\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8247 - val_loss: 3.3440\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.4751 - val_loss: 3.3155\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0323 - val_loss: 3.2823\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.6795 - val_loss: 3.2604\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8284 - val_loss: 3.2262\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.5804 - val_loss: 3.2037\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.3350 - val_loss: 3.1776\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 10.2092 - val_loss: 3.1672\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8448 - val_loss: 3.1495\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.8416 - val_loss: 3.1302\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.5050 - val_loss: 3.0859\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9629 - val_loss: 3.0481\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.1262 - val_loss: 3.0417\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9107 - val_loss: 3.0422\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0362 - val_loss: 3.0542\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0240 - val_loss: 3.0425\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.9800 - val_loss: 3.0160\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.8889 - val_loss: 2.9970\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.7352 - val_loss: 2.9746\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.1137 - val_loss: 2.9837\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.3851 - val_loss: 2.9991\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.7609 - val_loss: 2.9827\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.8877 - val_loss: 2.9794\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6568 - val_loss: 2.9638\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.4262 - val_loss: 2.9554\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5562 - val_loss: 2.9181\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8133 - val_loss: 2.9071\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2735 - val_loss: 2.8990\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.0901 - val_loss: 2.9070\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.4551 - val_loss: 2.9158\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4339 - val_loss: 2.9358\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.8339 - val_loss: 2.9402\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.4666 - val_loss: 2.9426\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.5981 - val_loss: 2.9484\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7657 - val_loss: 2.9594\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8397 - val_loss: 2.9710\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3729 - val_loss: 2.9596\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8999 - val_loss: 2.9681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 681ms/step - loss: 6.7706 - val_loss: 24.3996\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8489 - val_loss: 24.2425\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.1810 - val_loss: 24.1281\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.7038 - val_loss: 23.7875\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.4250 - val_loss: 23.5600\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.1079 - val_loss: 23.3652\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2399 - val_loss: 23.2185\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.0557 - val_loss: 23.1046\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.5258 - val_loss: 23.0195\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.4962 - val_loss: 22.9002\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.3296 - val_loss: 22.7870\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.3621 - val_loss: 22.7041\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2976 - val_loss: 22.6454\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9923 - val_loss: 22.5771\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.2372 - val_loss: 22.5710\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9395 - val_loss: 22.4311\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5359 - val_loss: 22.2702\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.3854 - val_loss: 22.1657\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.7315 - val_loss: 22.0464\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4816 - val_loss: 21.9333\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1131 - val_loss: 21.7997\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4883 - val_loss: 21.6541\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.5903 - val_loss: 21.5294\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9567 - val_loss: 21.3611\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1944 - val_loss: 21.2211\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.0825 - val_loss: 21.0723\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.4207 - val_loss: 20.8754\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4483 - val_loss: 20.7188\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0966 - val_loss: 20.5503\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9627 - val_loss: 20.3523\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.7227 - val_loss: 20.1358\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7120 - val_loss: 19.8283\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6534 - val_loss: 19.6730\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6898 - val_loss: 19.5009\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3360 - val_loss: 19.3038\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8441 - val_loss: 19.1449\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7735 - val_loss: 18.9877\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5890 - val_loss: 18.7185\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7234 - val_loss: 18.5341\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5038 - val_loss: 18.3783\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5327 - val_loss: 18.2375\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0587 - val_loss: 18.1562\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0664 - val_loss: 18.0431\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9563 - val_loss: 17.9147\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3903 - val_loss: 17.8601\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8060 - val_loss: 17.8208\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2409 - val_loss: 17.7931\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9501 - val_loss: 17.8242\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0125 - val_loss: 17.8315\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.2713 - val_loss: 17.8279\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7953 - val_loss: 17.7732\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.4091 - val_loss: 17.6732\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6206 - val_loss: 17.6213\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8767 - val_loss: 17.5144\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.7819 - val_loss: 17.4881\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8796 - val_loss: 17.5003\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2399 - val_loss: 17.5155\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2710 - val_loss: 17.5213\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8639 - val_loss: 17.5194\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0795 - val_loss: 17.5240\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2224 - val_loss: 17.4539\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7164 - val_loss: 17.3956\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6663 - val_loss: 17.3919\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4367 - val_loss: 17.5380\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5621 - val_loss: 17.6250\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.9232 - val_loss: 17.6858\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6701 - val_loss: 17.7267\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5753 - val_loss: 17.7328\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7676 - val_loss: 17.6985\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3571 - val_loss: 17.7052\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4630 - val_loss: 17.7059\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5278 - val_loss: 17.7597\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4868 - val_loss: 17.8159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 961ms/step - loss: 8.8772 - val_loss: 20.1650\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.5753 - val_loss: 20.0456\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.6479 - val_loss: 20.0276\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9918 - val_loss: 19.9657\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3931 - val_loss: 20.0203\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.1248 - val_loss: 20.0471\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.5118 - val_loss: 20.0009\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.1229 - val_loss: 19.9864\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5872 - val_loss: 19.9953\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5212 - val_loss: 19.9067\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.0503 - val_loss: 19.8626\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.9979 - val_loss: 19.7871\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.0924 - val_loss: 19.7616\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.5276 - val_loss: 19.6793\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.9387 - val_loss: 19.6505\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.5208 - val_loss: 19.5799\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4104 - val_loss: 19.4984\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.2218 - val_loss: 19.4297\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0035 - val_loss: 19.3315\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.6028 - val_loss: 19.2391\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4546 - val_loss: 19.1983\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.0523 - val_loss: 19.2195\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.9815 - val_loss: 19.1819\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4176 - val_loss: 19.1435\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9794 - val_loss: 19.1754\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3110 - val_loss: 19.1787\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.7479 - val_loss: 19.1611\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7523 - val_loss: 19.1408\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5441 - val_loss: 19.1634\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2106 - val_loss: 19.1942\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.6536 - val_loss: 19.1776\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.1291 - val_loss: 19.1170\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1156 - val_loss: 19.1024\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1235 - val_loss: 19.0840\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8561 - val_loss: 19.1094\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.3361 - val_loss: 19.1248\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0478 - val_loss: 19.0613\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.2557 - val_loss: 19.0153\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7882 - val_loss: 18.9230\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.1382 - val_loss: 18.8999\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.9455 - val_loss: 18.8601\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5312 - val_loss: 18.8710\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6521 - val_loss: 18.9353\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6045 - val_loss: 18.9475\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6812 - val_loss: 18.9400\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7621 - val_loss: 18.9421\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.6841 - val_loss: 18.9265\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7698 - val_loss: 18.8832\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8336 - val_loss: 18.8011\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.4941 - val_loss: 18.8256\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.4959 - val_loss: 18.7617\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.8154 - val_loss: 18.6734\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3983 - val_loss: 18.6177\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5339 - val_loss: 18.5462\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5148 - val_loss: 18.4936\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3864 - val_loss: 18.4786\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3500 - val_loss: 18.4762\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5365 - val_loss: 18.4489\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5456 - val_loss: 18.4128\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5839 - val_loss: 18.4827\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.5096 - val_loss: 18.4769\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3297 - val_loss: 18.4091\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1373 - val_loss: 18.3438\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8725 - val_loss: 18.3589\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2396 - val_loss: 18.3754\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.3074 - val_loss: 18.4394\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.3028 - val_loss: 18.5291\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0974 - val_loss: 18.5182\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2641 - val_loss: 18.5319\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9339 - val_loss: 18.5869\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8761 - val_loss: 18.6455\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9104 - val_loss: 18.7249\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0825 - val_loss: 18.8942\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 634ms/step - loss: 5.2941 - val_loss: 23.7014\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5.5512 - val_loss: 23.5400\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.9501 - val_loss: 23.3945\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.4114 - val_loss: 23.1821\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9322 - val_loss: 23.0569\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5807 - val_loss: 22.9490\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.6659 - val_loss: 22.8472\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9175 - val_loss: 22.7180\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5729 - val_loss: 22.6258\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3508 - val_loss: 22.4776\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.3803 - val_loss: 22.4030\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.2835 - val_loss: 22.3482\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1801 - val_loss: 22.2828\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.0269 - val_loss: 22.1445\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1592 - val_loss: 22.0792\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2867 - val_loss: 21.9914\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8200 - val_loss: 21.8588\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.6654 - val_loss: 21.8541\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5841 - val_loss: 21.8330\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6079 - val_loss: 21.7479\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.5235 - val_loss: 21.7352\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2738 - val_loss: 21.6426\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7917 - val_loss: 21.6217\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7731 - val_loss: 21.5828\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0937 - val_loss: 21.5463\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1103 - val_loss: 21.5502\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0140 - val_loss: 21.5147\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2528 - val_loss: 21.4287\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3864 - val_loss: 21.3966\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.0327 - val_loss: 21.3265\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.0492 - val_loss: 21.2355\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.7408 - val_loss: 21.1646\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.6353 - val_loss: 21.2096\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.3973 - val_loss: 21.2439\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7749 - val_loss: 21.2963\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9079 - val_loss: 21.3234\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5371 - val_loss: 21.3462\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8263 - val_loss: 21.3569\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6357 - val_loss: 21.3060\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5533 - val_loss: 21.3517\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5186 - val_loss: 21.3510\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3330 - val_loss: 21.3905\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 603ms/step - loss: 6.9010 - val_loss: 13.0718\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8929 - val_loss: 13.2118\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6764 - val_loss: 13.3218\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.8682 - val_loss: 13.3758\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.5110 - val_loss: 13.4718\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6256 - val_loss: 13.5503\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0432 - val_loss: 13.6076\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1440 - val_loss: 13.6598\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.9226 - val_loss: 13.7002\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.7786 - val_loss: 13.7069\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.1729 - val_loss: 13.7424\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 843ms/step - loss: 13.5437 - val_loss: 3.4845\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.0325 - val_loss: 3.3121\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.1796 - val_loss: 3.1813\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 10.6861 - val_loss: 3.1034\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.4162 - val_loss: 3.0263\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.7405 - val_loss: 2.9811\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.9351 - val_loss: 2.9824\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.1217 - val_loss: 3.0250\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.1791 - val_loss: 3.0709\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 10.8068 - val_loss: 3.1153\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4374 - val_loss: 3.1625\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9482 - val_loss: 3.2304\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.7819 - val_loss: 3.2826\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.0621 - val_loss: 3.3304\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.1031 - val_loss: 3.3969\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.0371 - val_loss: 3.4669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 690ms/step - loss: 11.0171 - val_loss: 3.6660\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.4098 - val_loss: 3.7136\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 10.0925 - val_loss: 3.8000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.3035 - val_loss: 3.8901\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.6976 - val_loss: 3.9935\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.7385 - val_loss: 4.0836\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3068 - val_loss: 4.1969\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2899 - val_loss: 4.3357\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.6518 - val_loss: 4.4717\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 11.0387 - val_loss: 4.5998\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3368 - val_loss: 4.7166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 130s 1s/step - loss: 9.6047 - val_loss: 4.0450\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.0834 - val_loss: 3.8959\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.1474 - val_loss: 3.7892\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.5821 - val_loss: 3.7121\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9374 - val_loss: 3.6686\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.2374 - val_loss: 3.6299\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.1945 - val_loss: 3.5914\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.6833 - val_loss: 3.5630\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0144 - val_loss: 3.5330\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9051 - val_loss: 3.4970\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4724 - val_loss: 3.4608\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.2733 - val_loss: 3.4720\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8414 - val_loss: 3.4906\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7380 - val_loss: 3.5032\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7356 - val_loss: 3.5168\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7609 - val_loss: 3.5335\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0416 - val_loss: 3.5526\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0040 - val_loss: 3.5776\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.1329 - val_loss: 3.5990\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.1818 - val_loss: 3.6345\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.5439 - val_loss: 3.6831\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 458us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 700ms/step - loss: 13.2242 - val_loss: 7.5011\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.4946 - val_loss: 7.3934\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.2986 - val_loss: 7.2737\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.2832 - val_loss: 7.1546\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.8977 - val_loss: 7.0621\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.2412 - val_loss: 6.9514\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.4098 - val_loss: 6.8893\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.6205 - val_loss: 6.8311\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.6201 - val_loss: 6.7966\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 12.5412 - val_loss: 6.7452\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.3879 - val_loss: 6.7300\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.0592 - val_loss: 6.7289\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4858 - val_loss: 6.7068\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.2807 - val_loss: 6.6844\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9841 - val_loss: 6.6932\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9457 - val_loss: 6.6932\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5688 - val_loss: 6.7053\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.1931 - val_loss: 6.7150\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6748 - val_loss: 6.7478\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.8142 - val_loss: 6.7855\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.2053 - val_loss: 6.8147\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.9641 - val_loss: 6.8260\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1340 - val_loss: 6.8489\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.5199 - val_loss: 6.8872\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 720ms/step - loss: 15.5577 - val_loss: 4.7217\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.5554 - val_loss: 4.8321\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.2640 - val_loss: 5.0584\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.3241 - val_loss: 5.3076\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.3424 - val_loss: 5.5580\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 11.9294 - val_loss: 5.7106\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.7210 - val_loss: 5.9521\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.0672 - val_loss: 6.1863\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.5208 - val_loss: 6.4115\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.0319 - val_loss: 6.6296\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.6987 - val_loss: 6.7908\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 751ms/step - loss: 13.2086 - val_loss: 4.1275\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.6528 - val_loss: 4.2269\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9467 - val_loss: 4.4215\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.0545 - val_loss: 4.6228\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.1131 - val_loss: 4.7954\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.7422 - val_loss: 4.9115\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.2423 - val_loss: 5.1089\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.1137 - val_loss: 5.3050\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.6916 - val_loss: 5.4886\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.6542 - val_loss: 5.6833\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.9215 - val_loss: 5.8181\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 720ms/step - loss: 13.2756 - val_loss: 3.5811\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.8468 - val_loss: 3.5377\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.2944 - val_loss: 3.5731\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.5439 - val_loss: 3.6005\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.3038 - val_loss: 3.6133\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.7328 - val_loss: 3.6139\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.5473 - val_loss: 3.6677\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.1931 - val_loss: 3.7053\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.7547 - val_loss: 3.7248\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.7949 - val_loss: 3.7406\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 11.1109 - val_loss: 3.7391\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.0660 - val_loss: 3.7139\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 16s 706ms/step - loss: 11.9207 - val_loss: 4.1168\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.1015 - val_loss: 3.9779\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.4013 - val_loss: 3.8953\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.8974 - val_loss: 3.8670\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.4615 - val_loss: 3.8153\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.4794 - val_loss: 3.7715\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.4681 - val_loss: 3.8096\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.7615 - val_loss: 3.8410\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9074 - val_loss: 3.8600\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.3697 - val_loss: 3.8913\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.5438 - val_loss: 3.8804\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9030 - val_loss: 3.8586\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.0415 - val_loss: 3.8950\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.0060 - val_loss: 3.9430\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5257 - val_loss: 3.9916\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5863 - val_loss: 4.0494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 965ms/step - loss: 7.8899 - val_loss: 70.9374\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.4447 - val_loss: 70.6884\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.2442 - val_loss: 70.4299\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.6373 - val_loss: 70.1701\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.5502 - val_loss: 70.1223\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8103 - val_loss: 69.9309\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.4000 - val_loss: 69.6881\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6877 - val_loss: 69.4504\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1332 - val_loss: 69.5149\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2193 - val_loss: 69.5060\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.9977 - val_loss: 69.5012\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.0721 - val_loss: 69.4024\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7142 - val_loss: 69.2945\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.5978 - val_loss: 69.3054\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7645 - val_loss: 69.3492\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.1939 - val_loss: 69.4634\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.5980 - val_loss: 69.2343\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.8097 - val_loss: 69.2011\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9184 - val_loss: 69.2023\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9417 - val_loss: 69.0630\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.6083 - val_loss: 68.9377\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7736 - val_loss: 69.0195\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.9693 - val_loss: 68.9474\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.9957 - val_loss: 68.6286\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.2390 - val_loss: 68.4723\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3458 - val_loss: 68.2744\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2374 - val_loss: 68.0398\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.7057 - val_loss: 67.8076\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.4957 - val_loss: 67.8443\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.3414 - val_loss: 67.8189\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.4999 - val_loss: 67.8628\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.9163 - val_loss: 67.5287\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.0248 - val_loss: 67.4568\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.9513 - val_loss: 67.5531\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.7115 - val_loss: 67.3285\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7260 - val_loss: 67.1483\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7023 - val_loss: 67.0526\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2061 - val_loss: 66.9889\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3097 - val_loss: 67.0131\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.0718 - val_loss: 67.1184\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5803 - val_loss: 66.9373\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.5146 - val_loss: 67.0297\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3153 - val_loss: 66.8289\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.1693 - val_loss: 67.3393\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.0039 - val_loss: 67.8974\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1955 - val_loss: 68.0574\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3906 - val_loss: 68.1483\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.2451 - val_loss: 68.5865\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.8763 - val_loss: 68.5896\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.6776 - val_loss: 68.9013\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7771 - val_loss: 68.6834\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5606 - val_loss: 68.4668\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1874 - val_loss: 68.8491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 829ms/step - loss: 8.1831 - val_loss: 53.2837\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.9854 - val_loss: 52.5033\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.7282 - val_loss: 51.5835\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.1050 - val_loss: 50.5438\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.3854 - val_loss: 49.8561\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1049 - val_loss: 49.0381\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.3313 - val_loss: 48.0772\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.9516 - val_loss: 47.0740\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.6515 - val_loss: 46.2942\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.3288 - val_loss: 45.6315\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9224 - val_loss: 45.0672\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.3356 - val_loss: 44.4113\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.3914 - val_loss: 44.1192\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.1671 - val_loss: 43.8249\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.4514 - val_loss: 43.3056\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.9754 - val_loss: 43.0927\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.5905 - val_loss: 42.2484\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.7073 - val_loss: 41.6978\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.6708 - val_loss: 41.1296\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3221 - val_loss: 40.5679\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.7362 - val_loss: 40.0181\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.8903 - val_loss: 39.7356\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.4462 - val_loss: 39.2968\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8497 - val_loss: 38.6948\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4295 - val_loss: 38.4081\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1655 - val_loss: 37.8335\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.9618 - val_loss: 37.3150\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1890 - val_loss: 37.0329\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.0012 - val_loss: 36.8433\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.5318 - val_loss: 36.5988\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4684 - val_loss: 36.5710\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0361 - val_loss: 36.2076\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.2458 - val_loss: 36.1358\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4501 - val_loss: 35.9852\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.0797 - val_loss: 35.3852\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.6322 - val_loss: 35.0998\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.3863 - val_loss: 34.7477\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2227 - val_loss: 34.1442\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.0502 - val_loss: 33.5174\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.6483 - val_loss: 33.2528\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.6594 - val_loss: 32.8349\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.9575 - val_loss: 32.4121\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6182 - val_loss: 31.9480\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.8075 - val_loss: 31.8127\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5835 - val_loss: 31.7239\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.4460 - val_loss: 31.5599\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2291 - val_loss: 31.2727\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.1964 - val_loss: 31.4157\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.1255 - val_loss: 31.1524\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5773 - val_loss: 31.1697\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.3187 - val_loss: 30.8271\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.4332 - val_loss: 30.5655\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.3350 - val_loss: 30.3135\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1523 - val_loss: 30.1841\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5165 - val_loss: 30.0065\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2822 - val_loss: 29.8918\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.8437 - val_loss: 29.6262\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.3969 - val_loss: 29.5060\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0884 - val_loss: 29.2041\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9666 - val_loss: 28.9841\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.3376 - val_loss: 28.6179\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1101 - val_loss: 28.2951\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9828 - val_loss: 28.3115\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9053 - val_loss: 28.1784\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8268 - val_loss: 28.1195\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9397 - val_loss: 27.9144\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.3181 - val_loss: 27.7871\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.0369 - val_loss: 27.7331\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.6996 - val_loss: 27.5181\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.9207 - val_loss: 27.6040\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.8160 - val_loss: 27.6455\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8827 - val_loss: 27.4662\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8557 - val_loss: 27.5522\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4523 - val_loss: 27.6650\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8021 - val_loss: 27.7465\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9458 - val_loss: 27.7517\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4547 - val_loss: 27.7233\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9089 - val_loss: 27.5766\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8619 - val_loss: 27.3402\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.9947 - val_loss: 26.9564\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8407 - val_loss: 26.5439\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.7871 - val_loss: 26.2172\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.6308 - val_loss: 26.1187\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.8924 - val_loss: 25.9602\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8351 - val_loss: 25.5930\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2894 - val_loss: 25.4870\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.4649 - val_loss: 25.4479\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9249 - val_loss: 25.1730\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.1712 - val_loss: 24.9494\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.1660 - val_loss: 24.9081\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.3636 - val_loss: 24.8302\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2491 - val_loss: 24.5473\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.2510 - val_loss: 24.4246\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5230 - val_loss: 24.4670\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3239 - val_loss: 24.7250\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.7489 - val_loss: 24.9050\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1396 - val_loss: 24.8621\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2417 - val_loss: 24.7320\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.2657 - val_loss: 24.7834\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.5171 - val_loss: 24.9558\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.2549 - val_loss: 24.7813\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.2939 - val_loss: 24.5936\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4593 - val_loss: 24.4527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 717ms/step - loss: 9.8725 - val_loss: 74.3647\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.5653 - val_loss: 74.5121\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.1207 - val_loss: 74.8426\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6567 - val_loss: 75.0911\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.8839 - val_loss: 75.4930\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2636 - val_loss: 75.7457\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.6182 - val_loss: 75.9419\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.4723 - val_loss: 76.0371\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3509 - val_loss: 76.2447\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.6344 - val_loss: 76.4019\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4346 - val_loss: 76.3268\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 970ms/step - loss: 11.7539 - val_loss: 53.8553\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.9667 - val_loss: 53.9707\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.8196 - val_loss: 54.1535\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.9998 - val_loss: 54.1976\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.6099 - val_loss: 54.4862\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.5748 - val_loss: 54.5825\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 13.2925 - val_loss: 54.5843\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 13.5142 - val_loss: 54.5881\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.6729 - val_loss: 54.7124\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.8357 - val_loss: 54.6473\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.3907 - val_loss: 54.5885\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 967ms/step - loss: 14.7230 - val_loss: 6.0981\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.8642 - val_loss: 6.1511\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 14.8585 - val_loss: 6.2017\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.7542 - val_loss: 6.2536\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.8382 - val_loss: 6.3194\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.7643 - val_loss: 6.3732\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.0412 - val_loss: 6.4341\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.9380 - val_loss: 6.4445\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.2383 - val_loss: 6.4763\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 13.7355 - val_loss: 6.4902\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.5338 - val_loss: 6.5037\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 84s 14s/step - loss: 15.1016 - val_loss: 4.1826\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.6553 - val_loss: 4.0530\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.6536 - val_loss: 3.9423\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 13.9357 - val_loss: 3.8259\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.0306 - val_loss: 3.7763\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.7369 - val_loss: 3.6121\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 12.6971 - val_loss: 3.5423\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.5676 - val_loss: 3.4675\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.7834 - val_loss: 3.4059\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.4386 - val_loss: 3.2665\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.8463 - val_loss: 3.2104\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.6049 - val_loss: 3.1247\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.7182 - val_loss: 3.0905\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.9669 - val_loss: 3.0485\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.3366 - val_loss: 3.0269\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.5305 - val_loss: 3.0543\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.8103 - val_loss: 3.0852\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.7177 - val_loss: 3.1235\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.0748 - val_loss: 3.1850\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.3632 - val_loss: 3.2668\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.9453 - val_loss: 3.3825\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.0503 - val_loss: 3.4802\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5050 - val_loss: 3.5444\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.0662 - val_loss: 3.6231\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.9576 - val_loss: 3.7361\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 999ms/step - loss: 17.0022 - val_loss: 6.0274\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.0937 - val_loss: 6.0453\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 16.0651 - val_loss: 6.0717\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.2118 - val_loss: 6.0785\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 14.2606 - val_loss: 6.0655\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.7731 - val_loss: 6.0629\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.7680 - val_loss: 6.0708\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 13.3312 - val_loss: 6.0624\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.9971 - val_loss: 6.0667\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.2473 - val_loss: 6.0823\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.3342 - val_loss: 6.1133\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 735ms/step - loss: 15.6216 - val_loss: 11.8134\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.0603 - val_loss: 11.6148\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.3895 - val_loss: 10.8237\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.5051 - val_loss: 10.0441\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.2804 - val_loss: 9.5033\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 19.5572 - val_loss: 8.7371\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.3753 - val_loss: 8.2260\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.4683 - val_loss: 7.8649\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.4820 - val_loss: 7.5906\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.3454 - val_loss: 7.1438\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.5458 - val_loss: 6.7859\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.6301 - val_loss: 6.5051\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.7496 - val_loss: 6.3836\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.0349 - val_loss: 6.2610\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.5494 - val_loss: 6.2159\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.8204 - val_loss: 6.2084\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.1810 - val_loss: 6.2735\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.5826 - val_loss: 6.2357\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.7506 - val_loss: 6.3193\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.6002 - val_loss: 6.3415\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.2149 - val_loss: 6.1910\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.3406 - val_loss: 6.0881\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.4529 - val_loss: 6.0169\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.9991 - val_loss: 5.9689\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.7151 - val_loss: 5.9756\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6393 - val_loss: 6.0340\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.8268 - val_loss: 6.0718\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.4133 - val_loss: 6.1510\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7936 - val_loss: 6.2327\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5897 - val_loss: 6.3403\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.6346 - val_loss: 6.4688\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.1009 - val_loss: 6.6217\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0863 - val_loss: 6.7848\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.8326 - val_loss: 6.9142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 726ms/step - loss: 21.1417 - val_loss: 6.2259\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 19.6151 - val_loss: 6.2236\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 19.6385 - val_loss: 6.1719\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.4892 - val_loss: 6.0981\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.9578 - val_loss: 6.0454\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 19.4048 - val_loss: 5.9488\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 18.0529 - val_loss: 5.9717\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 18.2527 - val_loss: 5.9198\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 19.0705 - val_loss: 5.8408\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.8412 - val_loss: 5.7340\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 15.9642 - val_loss: 5.7458\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.2034 - val_loss: 5.7840\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 17.5400 - val_loss: 5.8283\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 17.7372 - val_loss: 5.8249\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.8379 - val_loss: 5.8278\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 14.6362 - val_loss: 5.9242\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.5205 - val_loss: 6.0141\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.0371 - val_loss: 6.0992\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.7766 - val_loss: 6.1497\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 16.4420 - val_loss: 6.2287\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 772ms/step - loss: 18.7546 - val_loss: 7.1425\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 19.8489 - val_loss: 7.5593\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 18.7565 - val_loss: 7.9895\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.9029 - val_loss: 8.2405\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 17.3417 - val_loss: 8.6076\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 17.6939 - val_loss: 8.8567\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 16.8971 - val_loss: 9.0284\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 17.0674 - val_loss: 9.2167\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.7933 - val_loss: 9.3614\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.2584 - val_loss: 9.4743\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.3286 - val_loss: 9.6328\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 725ms/step - loss: 18.1365 - val_loss: 5.1700\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 16.7386 - val_loss: 5.1843\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 17.4593 - val_loss: 5.2086\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 15.0193 - val_loss: 5.2174\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 16.4425 - val_loss: 5.2477\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.5035 - val_loss: 5.2431\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.1650 - val_loss: 5.2835\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.9984 - val_loss: 5.3349\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.1187 - val_loss: 5.3752\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.4848 - val_loss: 5.3962\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.6644 - val_loss: 5.4291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 716ms/step - loss: 18.2780 - val_loss: 7.5639\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.5884 - val_loss: 7.5777\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 18.7592 - val_loss: 7.6371\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.1480 - val_loss: 7.6471\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 17.3529 - val_loss: 7.6697\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 17.1297 - val_loss: 7.6544\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 17.0607 - val_loss: 7.7026\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 17.0767 - val_loss: 7.6679\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.9658 - val_loss: 7.6059\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.4016 - val_loss: 7.5238\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.6884 - val_loss: 7.5097\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 15.9879 - val_loss: 7.4637\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 15.9912 - val_loss: 7.4251\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.4930 - val_loss: 7.3827\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 16.2351 - val_loss: 7.3234\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.2281 - val_loss: 7.3052\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 15.4838 - val_loss: 7.2884\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.8212 - val_loss: 7.2496\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.1029 - val_loss: 7.1721\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.1504 - val_loss: 7.0547\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.3050 - val_loss: 6.9569\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.6430 - val_loss: 6.8566\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.5631 - val_loss: 6.7330\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.1973 - val_loss: 6.6549\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.6546 - val_loss: 6.5832\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.8080 - val_loss: 6.5342\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.7721 - val_loss: 6.5396\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.7447 - val_loss: 6.4980\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.1872 - val_loss: 6.4836\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.0200 - val_loss: 6.5217\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.9186 - val_loss: 6.5332\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.5188 - val_loss: 6.5359\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.6709 - val_loss: 6.5587\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.2762 - val_loss: 6.5416\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 11.6578 - val_loss: 6.5789\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.5287 - val_loss: 6.5640\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.4879 - val_loss: 6.5632\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.7969 - val_loss: 6.5709\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.6386 - val_loss: 6.6310\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 735ms/step - loss: 10.5878 - val_loss: 3.4653\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.8575 - val_loss: 3.4421\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.2227 - val_loss: 3.4905\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.9453 - val_loss: 3.5623\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 10.2692 - val_loss: 3.5164\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.5977 - val_loss: 3.5617\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.5213 - val_loss: 3.5476\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.2698 - val_loss: 3.5749\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0666 - val_loss: 3.5488\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.6132 - val_loss: 3.5078\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.5968 - val_loss: 3.5156\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.8650 - val_loss: 3.5573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 784ms/step - loss: 17.5288 - val_loss: 5.2808\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.9861 - val_loss: 5.4675\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.9975 - val_loss: 5.7706\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 17.0120 - val_loss: 6.0490\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.0730 - val_loss: 6.1200\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.6947 - val_loss: 6.5133\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.2333 - val_loss: 6.7422\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.3634 - val_loss: 7.1039\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.0198 - val_loss: 7.3622\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.0860 - val_loss: 7.4996\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.0975 - val_loss: 7.7594\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 806ms/step - loss: 11.7340 - val_loss: 2.4602\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.5606 - val_loss: 2.4875\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.6127 - val_loss: 2.5387\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.4694 - val_loss: 2.5877\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.2835 - val_loss: 2.5778\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.5080 - val_loss: 2.6210\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.0891 - val_loss: 2.6522\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.6231 - val_loss: 2.6919\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.8077 - val_loss: 2.7046\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.7755 - val_loss: 2.7137\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.3372 - val_loss: 2.7297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 828ms/step - loss: 14.9873 - val_loss: 6.5388\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 17.2641 - val_loss: 6.5142\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.5070 - val_loss: 6.3999\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.6708 - val_loss: 6.7152\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.3650 - val_loss: 6.7859\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 13.0749 - val_loss: 7.0761\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.9845 - val_loss: 7.2313\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.6282 - val_loss: 7.4242\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.8354 - val_loss: 7.6438\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.3550 - val_loss: 7.8711\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9912 - val_loss: 8.2858\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.1705 - val_loss: 8.8099\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.8180 - val_loss: 9.3553\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 737ms/step - loss: 9.7186 - val_loss: 5.2438\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6344 - val_loss: 4.9290\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5998 - val_loss: 4.6847\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6585 - val_loss: 4.4349\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8030 - val_loss: 4.2816\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.0558 - val_loss: 4.1337\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2859 - val_loss: 4.0476\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.8020 - val_loss: 3.9622\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9974 - val_loss: 3.8918\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7410 - val_loss: 3.8346\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2021 - val_loss: 3.7955\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8195 - val_loss: 3.7662\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.2849 - val_loss: 3.7406\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4571 - val_loss: 3.7136\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4428 - val_loss: 3.6956\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.5150 - val_loss: 3.6773\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.0893 - val_loss: 3.6657\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.1122 - val_loss: 3.6708\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9276 - val_loss: 3.6787\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4525 - val_loss: 3.6697\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.0438 - val_loss: 3.6618\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1743 - val_loss: 3.6551\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.5164 - val_loss: 3.6385\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.0819 - val_loss: 3.6202\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9509 - val_loss: 3.6222\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.8741 - val_loss: 3.6531\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.9765 - val_loss: 3.6870\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.8987 - val_loss: 3.7090\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.4924 - val_loss: 3.7294\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9236 - val_loss: 3.7888\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.2843 - val_loss: 3.8334\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.1459 - val_loss: 3.8726\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.5522 - val_loss: 3.9191\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.0462 - val_loss: 3.9717\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 754ms/step - loss: 16.0573 - val_loss: 7.8615\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.2418 - val_loss: 7.4379\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 13.7248 - val_loss: 7.1453\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 14.7919 - val_loss: 6.8904\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.0781 - val_loss: 6.6375\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.7321 - val_loss: 6.3440\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 11.3228 - val_loss: 6.1511\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.9953 - val_loss: 5.9013\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.2085 - val_loss: 5.6958\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 12.4107 - val_loss: 5.5784\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.6049 - val_loss: 5.4613\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.2150 - val_loss: 5.4347\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6234 - val_loss: 5.4089\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6306 - val_loss: 5.3645\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.9182 - val_loss: 5.4002\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7463 - val_loss: 5.4195\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2598 - val_loss: 5.3532\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2089 - val_loss: 5.3853\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.8686 - val_loss: 5.4036\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0190 - val_loss: 5.3969\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.5026 - val_loss: 5.4459\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6491 - val_loss: 5.4246\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2828 - val_loss: 5.4415\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.7040 - val_loss: 5.4375\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4513 - val_loss: 5.4817\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.2176 - val_loss: 5.5544\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5679 - val_loss: 5.6350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 771ms/step - loss: 11.2428 - val_loss: 6.5961\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 11.8120 - val_loss: 6.2460\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.4066 - val_loss: 6.0457\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.2405 - val_loss: 5.8773\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.0067 - val_loss: 5.6886\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.3107 - val_loss: 5.5270\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.6121 - val_loss: 5.4067\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.0235 - val_loss: 5.2981\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 11.2461 - val_loss: 5.1861\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.3335 - val_loss: 5.0960\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.2211 - val_loss: 5.0388\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9367 - val_loss: 4.9941\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.0439 - val_loss: 4.9965\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.6998 - val_loss: 4.9793\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5726 - val_loss: 4.9731\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7973 - val_loss: 4.9672\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7296 - val_loss: 4.9428\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.2374 - val_loss: 4.9575\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4750 - val_loss: 5.0272\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5100 - val_loss: 5.0700\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9771 - val_loss: 5.1183\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0391 - val_loss: 5.1516\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.3257 - val_loss: 5.1406\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4705 - val_loss: 5.1251\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6456 - val_loss: 5.2088\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9913 - val_loss: 5.2680\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2942 - val_loss: 5.4094\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 696ms/step - loss: 11.7364 - val_loss: 9.6507\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 13.6389 - val_loss: 9.1895\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 13.4136 - val_loss: 8.8373\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.2673 - val_loss: 8.4390\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 17.9634 - val_loss: 8.0684\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9380 - val_loss: 7.8243\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 11.2514 - val_loss: 7.6439\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.8517 - val_loss: 7.5056\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6570 - val_loss: 7.3873\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.4157 - val_loss: 7.2712\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 14.4713 - val_loss: 7.1752\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.2599 - val_loss: 7.0887\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.6737 - val_loss: 7.0211\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.7525 - val_loss: 6.9921\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3264 - val_loss: 6.9569\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3455 - val_loss: 6.9082\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4329 - val_loss: 6.8277\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.4129 - val_loss: 6.7873\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.0779 - val_loss: 6.7828\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0291 - val_loss: 6.7598\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4903 - val_loss: 6.7372\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.0197 - val_loss: 6.6649\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6497 - val_loss: 6.5836\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.0703 - val_loss: 6.5311\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9513 - val_loss: 6.5022\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3945 - val_loss: 6.5208\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.7322 - val_loss: 6.5522\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4527 - val_loss: 6.5738\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.8987 - val_loss: 6.5752\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.6643 - val_loss: 6.6258\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4587 - val_loss: 6.6633\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.0841 - val_loss: 6.6743\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.3139 - val_loss: 6.6981\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1846 - val_loss: 6.6873\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.8961 - val_loss: 6.6355\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 722ms/step - loss: 11.2028 - val_loss: 3.8797\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.6652 - val_loss: 3.8734\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.4986 - val_loss: 3.8700\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.9094 - val_loss: 3.8773\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.7344 - val_loss: 3.8817\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.5171 - val_loss: 3.9006\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.2721 - val_loss: 3.9114\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.0493 - val_loss: 3.9252\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.4572 - val_loss: 3.9393\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.4687 - val_loss: 3.9688\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0894 - val_loss: 4.0023\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.4436 - val_loss: 4.0210\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.2091 - val_loss: 4.0181\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 790ms/step - loss: 12.6224 - val_loss: 5.3164\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 11.6449 - val_loss: 5.2985\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.9601 - val_loss: 5.2463\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.9358 - val_loss: 5.2745\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.0354 - val_loss: 5.2622\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 10.8388 - val_loss: 5.2731\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.8100 - val_loss: 5.2736\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.3110 - val_loss: 5.1587\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.8225 - val_loss: 4.9491\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.8662 - val_loss: 4.7348\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.6417 - val_loss: 4.6119\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.9295 - val_loss: 4.4768\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.2075 - val_loss: 4.3732\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.2643 - val_loss: 4.2387\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.2716 - val_loss: 4.1018\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0102 - val_loss: 3.9706\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6387 - val_loss: 3.8408\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0724 - val_loss: 3.7056\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4245 - val_loss: 3.5765\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1556 - val_loss: 3.4659\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.1410 - val_loss: 3.3689\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2791 - val_loss: 3.2954\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2135 - val_loss: 3.2188\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7554 - val_loss: 3.1646\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8373 - val_loss: 3.1264\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4760 - val_loss: 3.0865\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8719 - val_loss: 3.0435\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8886 - val_loss: 2.9950\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5700 - val_loss: 2.9749\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.0478 - val_loss: 2.9731\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.4328 - val_loss: 2.9911\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.2515 - val_loss: 3.0062\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.6659 - val_loss: 2.9987\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.0301 - val_loss: 3.0019\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8040 - val_loss: 2.9609\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.0814 - val_loss: 2.9546\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.2867 - val_loss: 2.9842\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4442 - val_loss: 3.0364\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.7275 - val_loss: 3.0848\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6043 - val_loss: 3.1047\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.9245 - val_loss: 3.1368\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.1896 - val_loss: 3.1201\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8008 - val_loss: 3.0939\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2456 - val_loss: 3.1537\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6546 - val_loss: 3.2260\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6593 - val_loss: 3.2374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 724ms/step - loss: 8.2127 - val_loss: 3.6107\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.0645 - val_loss: 3.6478\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8855 - val_loss: 3.6642\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0954 - val_loss: 3.7070\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1460 - val_loss: 3.7421\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.5058 - val_loss: 3.7813\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6311 - val_loss: 3.7878\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.8804 - val_loss: 3.7850\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6752 - val_loss: 3.8061\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9101 - val_loss: 3.8539\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6048 - val_loss: 3.9097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 714ms/step - loss: 10.5225 - val_loss: 5.7837\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.3616 - val_loss: 5.6158\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.9524 - val_loss: 5.4765\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.5972 - val_loss: 5.3604\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.7935 - val_loss: 5.2793\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.5391 - val_loss: 5.2274\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.3031 - val_loss: 5.1788\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.1995 - val_loss: 5.1488\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.0422 - val_loss: 5.1253\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.5997 - val_loss: 5.1211\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.1479 - val_loss: 5.1235\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9057 - val_loss: 5.1070\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6913 - val_loss: 5.1186\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.3738 - val_loss: 5.1299\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.6273 - val_loss: 5.1182\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.0704 - val_loss: 5.1105\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6098 - val_loss: 5.1348\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.2804 - val_loss: 5.1391\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.2734 - val_loss: 5.1542\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6982 - val_loss: 5.1328\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8254 - val_loss: 5.1242\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.9146 - val_loss: 5.0805\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7339 - val_loss: 4.9854\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0705 - val_loss: 4.9284\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6250 - val_loss: 4.9157\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.8391 - val_loss: 4.9189\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.1532 - val_loss: 4.9570\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.0944 - val_loss: 4.9727\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.2809 - val_loss: 4.9978\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.0424 - val_loss: 5.0330\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.5468 - val_loss: 5.0701\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7738 - val_loss: 5.0985\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.4493 - val_loss: 5.1423\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4955 - val_loss: 5.1811\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3301 - val_loss: 5.1474\n",
      "2/2 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 749ms/step - loss: 8.4337 - val_loss: 93.1654\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.6827 - val_loss: 92.8207\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.3113 - val_loss: 92.7204\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6926 - val_loss: 92.6541\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.3150 - val_loss: 92.4006\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.4757 - val_loss: 92.4487\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1148 - val_loss: 92.4292\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8223 - val_loss: 92.8067\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7516 - val_loss: 93.0482\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.7663 - val_loss: 93.2719\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1434 - val_loss: 93.7287\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.8435 - val_loss: 94.0800\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.6417 - val_loss: 94.3358\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8846 - val_loss: 94.5005\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7824 - val_loss: 94.4893\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 827ms/step - loss: 9.9587 - val_loss: 79.7978\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.9550 - val_loss: 79.8558\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.6660 - val_loss: 79.8468\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4917 - val_loss: 79.7124\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.7677 - val_loss: 79.4192\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0619 - val_loss: 79.3188\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7227 - val_loss: 79.0610\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.3102 - val_loss: 78.8123\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4723 - val_loss: 78.4867\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.4628 - val_loss: 78.3001\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.7515 - val_loss: 78.1744\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7539 - val_loss: 77.9337\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.4470 - val_loss: 77.8723\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2285 - val_loss: 77.9176\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6163 - val_loss: 77.8102\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2025 - val_loss: 77.6462\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.1253 - val_loss: 77.5185\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4871 - val_loss: 77.4553\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5048 - val_loss: 77.5251\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.0295 - val_loss: 77.5682\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.1198 - val_loss: 77.5621\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0000 - val_loss: 77.6897\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9627 - val_loss: 77.7525\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4771 - val_loss: 77.8779\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8403 - val_loss: 77.9879\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.7823 - val_loss: 78.0797\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9896 - val_loss: 78.2592\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.7145 - val_loss: 78.4139\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 756ms/step - loss: 8.1153 - val_loss: 76.9124\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7455 - val_loss: 77.3678\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4569 - val_loss: 77.5859\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.1964 - val_loss: 77.9395\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.9306 - val_loss: 77.9893\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5629 - val_loss: 78.3650\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.3347 - val_loss: 78.5492\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2192 - val_loss: 78.8596\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.5840 - val_loss: 79.0530\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3974 - val_loss: 79.2855\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0399 - val_loss: 79.7138\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 756ms/step - loss: 7.2015 - val_loss: 67.3054\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.9756 - val_loss: 67.2170\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.6511 - val_loss: 67.0996\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3583 - val_loss: 67.0988\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.6852 - val_loss: 67.1263\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.9342 - val_loss: 67.3514\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.3562 - val_loss: 67.5075\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3183 - val_loss: 67.6930\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5157 - val_loss: 67.7995\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3804 - val_loss: 68.0032\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.3950 - val_loss: 68.2371\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.7864 - val_loss: 68.2444\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.0550 - val_loss: 68.4279\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.1549 - val_loss: 68.3530\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 830ms/step - loss: 13.4467 - val_loss: 14.9694\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.7164 - val_loss: 13.4999\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.0777 - val_loss: 12.2381\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.2987 - val_loss: 11.1393\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 10.3716 - val_loss: 10.3385\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.6233 - val_loss: 9.6136\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.3558 - val_loss: 8.9746\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.8600 - val_loss: 8.5218\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0971 - val_loss: 8.0776\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5171 - val_loss: 7.6642\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2210 - val_loss: 7.4416\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.5511 - val_loss: 7.2445\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.8446 - val_loss: 7.0414\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5400 - val_loss: 6.8120\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8719 - val_loss: 6.6700\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7562 - val_loss: 6.5638\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.1019 - val_loss: 6.5314\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4695 - val_loss: 6.4297\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.8736 - val_loss: 6.3998\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.7609 - val_loss: 6.4152\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.1090 - val_loss: 6.4021\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7171 - val_loss: 6.3524\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.6683 - val_loss: 6.3030\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7231 - val_loss: 6.2531\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.9968 - val_loss: 6.1822\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.1418 - val_loss: 6.1751\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.1529 - val_loss: 6.2184\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.4259 - val_loss: 6.2460\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.5738 - val_loss: 6.2951\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3856 - val_loss: 6.3334\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.7833 - val_loss: 6.3207\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.5625 - val_loss: 6.3178\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.1530 - val_loss: 6.1747\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8973 - val_loss: 6.1165\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.0849 - val_loss: 6.2132\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.1470 - val_loss: 6.1458\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.5226 - val_loss: 6.0685\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.1009 - val_loss: 5.9541\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.8691 - val_loss: 5.8995\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.0209 - val_loss: 5.8517\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.0764 - val_loss: 5.9025\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.2839 - val_loss: 5.9492\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.5346 - val_loss: 6.0011\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.8493 - val_loss: 6.0523\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.7609 - val_loss: 6.1163\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.9757 - val_loss: 6.2377\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.0273 - val_loss: 6.3348\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.1609 - val_loss: 6.3653\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.8165 - val_loss: 6.3772\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.5677 - val_loss: 6.4517\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 831ms/step - loss: 12.2478 - val_loss: 21.4230\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.8540 - val_loss: 19.7215\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.8591 - val_loss: 17.9979\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.4658 - val_loss: 16.4671\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.6837 - val_loss: 15.2197\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.4180 - val_loss: 14.1161\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.3070 - val_loss: 13.3566\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7045 - val_loss: 12.7098\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.9374 - val_loss: 12.0651\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.1883 - val_loss: 11.5491\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.7647 - val_loss: 11.2119\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5635 - val_loss: 10.9568\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7260 - val_loss: 10.6322\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.9581 - val_loss: 10.3484\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.8103 - val_loss: 10.0666\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.8606 - val_loss: 9.8596\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.7562 - val_loss: 9.8071\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.6359 - val_loss: 9.6987\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.9978 - val_loss: 9.6661\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.2434 - val_loss: 9.6739\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.9363 - val_loss: 9.6930\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.3140 - val_loss: 9.6490\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.5778 - val_loss: 9.7537\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.0035 - val_loss: 9.8493\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4955 - val_loss: 9.9141\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.1500 - val_loss: 10.0726\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.5488 - val_loss: 10.2935\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.5701 - val_loss: 10.4562\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8023 - val_loss: 10.4889\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.2008 - val_loss: 10.5176\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.6720 - val_loss: 10.5077\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.4803 - val_loss: 10.4862\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 753ms/step - loss: 13.5886 - val_loss: 21.0647\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.6279 - val_loss: 20.4608\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.7255 - val_loss: 19.8141\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.7893 - val_loss: 19.2020\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.0616 - val_loss: 18.6134\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.8490 - val_loss: 18.0482\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.8861 - val_loss: 17.5184\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.8053 - val_loss: 17.0664\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.8991 - val_loss: 16.5807\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.5750 - val_loss: 16.0916\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0154 - val_loss: 15.7166\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.3817 - val_loss: 15.4017\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.5330 - val_loss: 14.9553\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.8600 - val_loss: 14.5659\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.4932 - val_loss: 14.2036\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7690 - val_loss: 13.8281\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5104 - val_loss: 13.5317\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.1159 - val_loss: 13.1867\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2742 - val_loss: 12.8358\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.8955 - val_loss: 12.5737\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.7555 - val_loss: 12.2904\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.3255 - val_loss: 11.9186\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.2690 - val_loss: 11.6439\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4107 - val_loss: 11.3810\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.6072 - val_loss: 11.1328\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.9886 - val_loss: 10.9738\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.5484 - val_loss: 10.7908\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.0081 - val_loss: 10.6297\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6064 - val_loss: 10.3957\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.5080 - val_loss: 10.2366\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.0605 - val_loss: 10.1074\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.8246 - val_loss: 10.0026\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.4254 - val_loss: 9.8069\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3189 - val_loss: 9.6392\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0613 - val_loss: 9.5681\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2559 - val_loss: 9.5255\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7534 - val_loss: 9.4535\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.1480 - val_loss: 9.3932\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2717 - val_loss: 9.3640\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.5125 - val_loss: 9.3589\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.9541 - val_loss: 9.3825\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9627 - val_loss: 9.3094\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.3769 - val_loss: 9.2112\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.2260 - val_loss: 9.1674\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.3776 - val_loss: 9.1668\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4959 - val_loss: 9.1899\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0089 - val_loss: 9.1955\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.6960 - val_loss: 9.2410\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.8779 - val_loss: 9.2822\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0890 - val_loss: 9.3051\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1564 - val_loss: 9.3719\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.2015 - val_loss: 9.4844\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1530 - val_loss: 9.5029\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.8102 - val_loss: 9.4584\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6291 - val_loss: 9.4947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 736ms/step - loss: 7.5216 - val_loss: 24.3134\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.7141 - val_loss: 23.2770\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.8574 - val_loss: 22.3844\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.5298 - val_loss: 21.6167\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.1933 - val_loss: 20.9470\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.8792 - val_loss: 20.3276\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.9207 - val_loss: 19.7965\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.3699 - val_loss: 19.2818\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.3192 - val_loss: 18.7612\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0834 - val_loss: 18.2838\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.9722 - val_loss: 17.9464\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.4120 - val_loss: 17.6622\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.6471 - val_loss: 17.1735\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.9915 - val_loss: 16.8203\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.9708 - val_loss: 16.4998\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.0508 - val_loss: 16.2426\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.2373 - val_loss: 16.0908\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.3912 - val_loss: 15.8034\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.1405 - val_loss: 15.5277\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5770 - val_loss: 15.3124\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2650 - val_loss: 15.1726\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.4237 - val_loss: 14.8971\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.2334 - val_loss: 14.8579\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7525 - val_loss: 14.7172\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7279 - val_loss: 14.5134\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.5259 - val_loss: 14.4723\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1137 - val_loss: 14.4166\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.9282 - val_loss: 14.3291\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4207 - val_loss: 14.1306\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1933 - val_loss: 14.0886\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5734 - val_loss: 14.0855\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.3498 - val_loss: 14.0207\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.2354 - val_loss: 13.6293\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7889 - val_loss: 13.1824\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.2700 - val_loss: 13.0331\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8014 - val_loss: 12.9179\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.9426 - val_loss: 12.9284\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8433 - val_loss: 12.8262\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.7093 - val_loss: 12.8392\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6821 - val_loss: 12.8986\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.7962 - val_loss: 12.8155\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.9018 - val_loss: 12.7028\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5851 - val_loss: 12.6513\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.7739 - val_loss: 12.5911\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7756 - val_loss: 12.5847\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5988 - val_loss: 12.5353\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.5190 - val_loss: 12.4268\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.6963 - val_loss: 12.3960\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.9111 - val_loss: 12.5736\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.2341 - val_loss: 12.6768\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.8041 - val_loss: 12.4065\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7971 - val_loss: 12.2098\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4812 - val_loss: 11.8230\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.5330 - val_loss: 11.7130\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1320 - val_loss: 11.7279\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.9497 - val_loss: 11.8318\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2319 - val_loss: 11.8889\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0475 - val_loss: 11.7782\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1233 - val_loss: 11.5993\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.4967 - val_loss: 11.3077\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0558 - val_loss: 11.1154\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.9522 - val_loss: 11.1998\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.0766 - val_loss: 11.3134\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.4299 - val_loss: 11.3118\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.0832 - val_loss: 11.2096\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2869 - val_loss: 11.0361\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6720 - val_loss: 10.8503\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2472 - val_loss: 10.7716\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.3395 - val_loss: 10.8112\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4370 - val_loss: 11.0517\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7744 - val_loss: 11.1870\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.2799 - val_loss: 11.4048\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8542 - val_loss: 11.6215\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1702 - val_loss: 11.9767\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.1390 - val_loss: 12.3664\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.5892 - val_loss: 12.8223\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.0535 - val_loss: 13.1900\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.9202 - val_loss: 13.4453\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 577us/step\n",
      "Executing d7101242 iter 3\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 765ms/step - loss: 17.4258 - val_loss: 10.4531\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 17.6722 - val_loss: 9.8880\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.3680 - val_loss: 9.3334\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 15.9050 - val_loss: 8.8214\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 14.8657 - val_loss: 8.3357\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.6049 - val_loss: 8.0333\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.7997 - val_loss: 7.7519\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.6413 - val_loss: 7.4585\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.7409 - val_loss: 7.1620\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.0452 - val_loss: 6.8862\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.2261 - val_loss: 6.6576\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.3298 - val_loss: 6.4283\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.9734 - val_loss: 6.2755\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.0171 - val_loss: 6.1899\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.9205 - val_loss: 6.0472\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.5184 - val_loss: 5.9245\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 10.2065 - val_loss: 5.7286\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.6468 - val_loss: 5.6506\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 10.7844 - val_loss: 5.5389\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.7282 - val_loss: 5.4206\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.4452 - val_loss: 5.3866\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.0089 - val_loss: 5.4066\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.8535 - val_loss: 5.3717\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.6733 - val_loss: 5.3414\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.8581 - val_loss: 5.3079\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.7537 - val_loss: 5.3356\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.6735 - val_loss: 5.3471\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.6310 - val_loss: 5.3747\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.4081 - val_loss: 5.3546\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.0329 - val_loss: 5.3597\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.9784 - val_loss: 5.4086\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5400 - val_loss: 5.4727\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7381 - val_loss: 5.5772\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7971 - val_loss: 5.6308\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.5473 - val_loss: 5.6947\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 837ms/step - loss: 16.1660 - val_loss: 7.7083\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.4707 - val_loss: 7.6335\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.4375 - val_loss: 7.5545\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 16.1851 - val_loss: 7.4739\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.6323 - val_loss: 7.4023\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.0707 - val_loss: 7.3456\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.6603 - val_loss: 7.2834\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.1277 - val_loss: 7.2269\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.6874 - val_loss: 7.1674\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.0323 - val_loss: 7.1120\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.3813 - val_loss: 7.0652\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.4018 - val_loss: 7.0169\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.7703 - val_loss: 6.9658\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.1855 - val_loss: 6.9119\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 15.5277 - val_loss: 6.8663\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.0490 - val_loss: 6.8144\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.8062 - val_loss: 6.7563\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 14.4547 - val_loss: 6.7040\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.9303 - val_loss: 6.6483\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.7129 - val_loss: 6.5918\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.5871 - val_loss: 6.5378\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.7493 - val_loss: 6.4897\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.6493 - val_loss: 6.4336\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.1339 - val_loss: 6.3779\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.9628 - val_loss: 6.3259\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.2630 - val_loss: 6.2740\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.5691 - val_loss: 6.2160\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 13.4361 - val_loss: 6.1582\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.2373 - val_loss: 6.1064\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.1258 - val_loss: 6.0519\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.2235 - val_loss: 6.0095\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.1304 - val_loss: 5.9639\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 12.3052 - val_loss: 5.9170\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.3171 - val_loss: 5.8674\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.8414 - val_loss: 5.8142\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 11.3796 - val_loss: 5.7667\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.6997 - val_loss: 5.7269\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.4274 - val_loss: 5.6832\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.7047 - val_loss: 5.6405\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.3309 - val_loss: 5.6194\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.3462 - val_loss: 5.5989\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.5942 - val_loss: 5.5908\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.1513 - val_loss: 5.5752\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.4334 - val_loss: 5.5493\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.5869 - val_loss: 5.5355\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.4601 - val_loss: 5.5206\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.7214 - val_loss: 5.5139\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.4019 - val_loss: 5.5115\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.3518 - val_loss: 5.4837\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.5689 - val_loss: 5.4804\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.8673 - val_loss: 5.4797\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.0910 - val_loss: 5.4966\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.6962 - val_loss: 5.5077\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4713 - val_loss: 5.5209\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.8230 - val_loss: 5.5279\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9344 - val_loss: 5.5349\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2649 - val_loss: 5.5510\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.8986 - val_loss: 5.5863\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.5951 - val_loss: 5.6411\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.0006 - val_loss: 5.7041\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.6896 - val_loss: 5.7512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 778ms/step - loss: 20.3636 - val_loss: 7.6446\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 19.6476 - val_loss: 7.3258\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 17.8189 - val_loss: 7.0276\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 17.6000 - val_loss: 6.7385\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 18.1540 - val_loss: 6.4652\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.3774 - val_loss: 6.2556\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.2566 - val_loss: 6.0557\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 15.0180 - val_loss: 5.8864\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 15.6558 - val_loss: 5.7186\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.4524 - val_loss: 5.5626\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 13.4345 - val_loss: 5.4406\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 13.7537 - val_loss: 5.3161\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.4543 - val_loss: 5.2115\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 12.6445 - val_loss: 5.1168\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.6268 - val_loss: 5.0369\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.1333 - val_loss: 4.9635\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.3940 - val_loss: 4.8802\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 11.3066 - val_loss: 4.8284\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.9585 - val_loss: 4.7743\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.1478 - val_loss: 4.7315\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.3797 - val_loss: 4.6915\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.0994 - val_loss: 4.6721\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.7364 - val_loss: 4.6535\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.9520 - val_loss: 4.6337\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.3403 - val_loss: 4.6075\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.4127 - val_loss: 4.5871\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.3496 - val_loss: 4.5627\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.0099 - val_loss: 4.5682\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.1012 - val_loss: 4.5515\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.7607 - val_loss: 4.5318\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.7773 - val_loss: 4.5286\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.0051 - val_loss: 4.5354\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0332 - val_loss: 4.5391\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.7753 - val_loss: 4.5513\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.9247 - val_loss: 4.5566\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.9472 - val_loss: 4.5618\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.5700 - val_loss: 4.5965\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.0712 - val_loss: 4.6138\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.0095 - val_loss: 4.6028\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.8811 - val_loss: 4.6229\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.1702 - val_loss: 4.6265\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 763ms/step - loss: 18.5901 - val_loss: 11.7300\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 18.3230 - val_loss: 11.2888\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 16.4053 - val_loss: 10.8598\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 17.2543 - val_loss: 10.4804\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 17.7840 - val_loss: 10.1198\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 15.7216 - val_loss: 9.8278\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 15.5725 - val_loss: 9.5595\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 16.1286 - val_loss: 9.3100\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.5237 - val_loss: 9.0926\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 15.1269 - val_loss: 8.8795\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 15.0912 - val_loss: 8.6727\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 14.8172 - val_loss: 8.4927\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.0570 - val_loss: 8.3574\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 14.1919 - val_loss: 8.2389\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 14.9253 - val_loss: 8.1376\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.8296 - val_loss: 8.0385\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.7441 - val_loss: 7.9296\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.9432 - val_loss: 7.8265\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 14.0295 - val_loss: 7.7161\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 13.9010 - val_loss: 7.6113\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 14.4467 - val_loss: 7.5101\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 13.0373 - val_loss: 7.4355\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.9699 - val_loss: 7.3534\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 13.0773 - val_loss: 7.2723\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.4679 - val_loss: 7.1925\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.0421 - val_loss: 7.1098\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 12.3040 - val_loss: 7.0283\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 12.2503 - val_loss: 6.9527\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 12.7329 - val_loss: 6.8864\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.9493 - val_loss: 6.8151\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 11.2672 - val_loss: 6.7527\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.7366 - val_loss: 6.6913\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.7755 - val_loss: 6.6285\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.1931 - val_loss: 6.5751\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.0664 - val_loss: 6.5201\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 11.9463 - val_loss: 6.4707\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.0348 - val_loss: 6.4337\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.2328 - val_loss: 6.3979\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.2454 - val_loss: 6.3569\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.3752 - val_loss: 6.3214\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 10.5767 - val_loss: 6.2818\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.6226 - val_loss: 6.2486\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.3718 - val_loss: 6.2195\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.1183 - val_loss: 6.1850\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.6617 - val_loss: 6.1506\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.9004 - val_loss: 6.1150\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.4249 - val_loss: 6.0859\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.0917 - val_loss: 6.0629\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.3961 - val_loss: 6.0341\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.9728 - val_loss: 6.0125\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.9466 - val_loss: 5.9851\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 10.2750 - val_loss: 5.9626\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.1104 - val_loss: 5.9329\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.9656 - val_loss: 5.9088\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.6028 - val_loss: 5.8853\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.4496 - val_loss: 5.8644\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.5235 - val_loss: 5.8447\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.7462 - val_loss: 5.8197\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.6868 - val_loss: 5.8047\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.9638 - val_loss: 5.7854\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.4999 - val_loss: 5.7506\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.8432 - val_loss: 5.7209\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.1633 - val_loss: 5.7051\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.8440 - val_loss: 5.6854\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.6408 - val_loss: 5.6724\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.7594 - val_loss: 5.6614\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.9860 - val_loss: 5.6397\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.5042 - val_loss: 5.6423\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.5574 - val_loss: 5.6295\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1059 - val_loss: 5.6154\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.3581 - val_loss: 5.5886\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.0217 - val_loss: 5.5716\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.4640 - val_loss: 5.5783\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.8729 - val_loss: 5.5673\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.0110 - val_loss: 5.5563\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.2906 - val_loss: 5.5484\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4170 - val_loss: 5.5307\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.2189 - val_loss: 5.5314\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.2223 - val_loss: 5.5258\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.1564 - val_loss: 5.5280\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.7703 - val_loss: 5.5153\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.4075 - val_loss: 5.5003\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 7.1727 - val_loss: 5.5117\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.6872 - val_loss: 5.5198\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.7618 - val_loss: 5.5149\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8046 - val_loss: 5.4929\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.3122 - val_loss: 5.4945\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0144 - val_loss: 5.5071\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.5072 - val_loss: 5.5157\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.1951 - val_loss: 5.5271\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.5730 - val_loss: 5.5229\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7.2801 - val_loss: 5.5247\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.4019 - val_loss: 5.5116\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0063 - val_loss: 5.4850\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.7090 - val_loss: 5.4837\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.1204 - val_loss: 5.4918\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.8764 - val_loss: 5.5272\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.7837 - val_loss: 5.5664\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.2501 - val_loss: 5.5972\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.6988 - val_loss: 5.6363\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.3816 - val_loss: 5.6658\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.3792 - val_loss: 5.6534\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.6522 - val_loss: 5.6383\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.1901 - val_loss: 5.6535\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 6.0774 - val_loss: 5.6998\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 179s 935ms/step - loss: 6.0259 - val_loss: 18.2936\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8522 - val_loss: 18.0507\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.5424 - val_loss: 17.9266\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.4768 - val_loss: 17.7647\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.2308 - val_loss: 17.7161\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.1040 - val_loss: 17.6826\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2528 - val_loss: 17.6984\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3994 - val_loss: 17.6460\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.2038 - val_loss: 17.5801\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.2723 - val_loss: 17.4193\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3387 - val_loss: 17.3642\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.9067 - val_loss: 17.3647\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3089 - val_loss: 17.3253\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3919 - val_loss: 17.1836\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9275 - val_loss: 17.0330\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.7220 - val_loss: 16.9898\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.9051 - val_loss: 17.0386\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6654 - val_loss: 17.1183\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3127 - val_loss: 17.2610\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.0782 - val_loss: 17.2553\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4597 - val_loss: 17.3126\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6717 - val_loss: 17.2384\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.5328 - val_loss: 17.2366\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1481 - val_loss: 17.2571\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.1949 - val_loss: 17.1646\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.3797 - val_loss: 17.0526\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 910ms/step - loss: 5.8095 - val_loss: 14.3700\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.9022 - val_loss: 14.5149\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.6740 - val_loss: 14.5461\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.9506 - val_loss: 14.5710\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4437 - val_loss: 14.5465\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.4756 - val_loss: 14.5367\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.2083 - val_loss: 14.4257\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2189 - val_loss: 14.3525\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.9490 - val_loss: 14.2189\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.7120 - val_loss: 14.0405\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.0034 - val_loss: 13.9440\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8245 - val_loss: 13.8977\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.7975 - val_loss: 13.7912\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6239 - val_loss: 13.6055\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.7322 - val_loss: 13.5049\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.6208 - val_loss: 13.4139\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.4305 - val_loss: 13.3153\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3674 - val_loss: 13.2252\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.1601 - val_loss: 13.1564\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.3572 - val_loss: 13.1123\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3277 - val_loss: 13.0322\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.0846 - val_loss: 12.9025\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.8528 - val_loss: 12.8704\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.7920 - val_loss: 12.8429\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.7777 - val_loss: 12.7783\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7176 - val_loss: 12.6944\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.9287 - val_loss: 12.6626\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6954 - val_loss: 12.6460\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.5809 - val_loss: 12.6892\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.6578 - val_loss: 12.6703\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.8253 - val_loss: 12.5635\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4814 - val_loss: 12.4941\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.3656 - val_loss: 12.5400\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3044 - val_loss: 12.5776\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.1109 - val_loss: 12.5955\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.2284 - val_loss: 12.6060\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.2645 - val_loss: 12.5281\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0972 - val_loss: 12.4777\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.9834 - val_loss: 12.4800\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.9888 - val_loss: 12.4607\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.9764 - val_loss: 12.4906\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.6174 - val_loss: 12.6389\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.7094 - val_loss: 12.7988\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.8633 - val_loss: 12.9164\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.7705 - val_loss: 12.9952\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.6509 - val_loss: 12.9335\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.6773 - val_loss: 12.8644\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.5874 - val_loss: 12.8749\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.7176 - val_loss: 12.7482\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.7765 - val_loss: 12.6577\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 839ms/step - loss: 6.1944 - val_loss: 23.5261\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0543 - val_loss: 22.8450\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.5616 - val_loss: 22.4720\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.8521 - val_loss: 22.0466\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.6814 - val_loss: 21.8271\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.2801 - val_loss: 21.5570\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.4148 - val_loss: 21.4267\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.5166 - val_loss: 21.3385\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.5104 - val_loss: 21.3313\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9558 - val_loss: 21.1084\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.7791 - val_loss: 20.9783\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.3370 - val_loss: 20.8754\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.4162 - val_loss: 20.7529\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.8940 - val_loss: 20.5907\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4353 - val_loss: 20.4697\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.7713 - val_loss: 20.4136\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0156 - val_loss: 20.2738\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.9226 - val_loss: 20.2976\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.5544 - val_loss: 20.3142\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0001 - val_loss: 20.1456\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.1539 - val_loss: 20.1888\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.1338 - val_loss: 20.1476\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.8211 - val_loss: 20.0736\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.8956 - val_loss: 19.9902\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.9534 - val_loss: 19.8465\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4490 - val_loss: 19.8631\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.1400 - val_loss: 19.9113\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4868 - val_loss: 19.9730\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.6448 - val_loss: 20.0789\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.8067 - val_loss: 20.0823\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6659 - val_loss: 20.0019\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.5944 - val_loss: 19.9060\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0143 - val_loss: 19.9405\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5209 - val_loss: 19.8947\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4529 - val_loss: 19.9133\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 793ms/step - loss: 5.3946 - val_loss: 16.8631\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.7574 - val_loss: 17.1722\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.6184 - val_loss: 17.3048\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.5569 - val_loss: 17.5024\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.2531 - val_loss: 17.7047\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.3657 - val_loss: 17.7745\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6622 - val_loss: 17.6396\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6579 - val_loss: 17.6056\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4027 - val_loss: 17.4690\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.8510 - val_loss: 17.4330\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4214 - val_loss: 17.4069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 834ms/step - loss: 12.7831 - val_loss: 4.0705\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.1196 - val_loss: 3.8336\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.4666 - val_loss: 3.6523\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.3934 - val_loss: 3.5516\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.3752 - val_loss: 3.4765\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.3844 - val_loss: 3.4076\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.6911 - val_loss: 3.3674\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6860 - val_loss: 3.3375\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.8717 - val_loss: 3.2948\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.0675 - val_loss: 3.2799\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.6171 - val_loss: 3.2787\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3970 - val_loss: 3.2877\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.7498 - val_loss: 3.3010\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.0771 - val_loss: 3.3344\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.9063 - val_loss: 3.3410\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.4075 - val_loss: 3.3278\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.3714 - val_loss: 3.2913\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.4265 - val_loss: 3.2869\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4397 - val_loss: 3.2823\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.9923 - val_loss: 3.2804\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.4339 - val_loss: 3.2733\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.5017 - val_loss: 3.2906\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.5907 - val_loss: 3.3038\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.8309 - val_loss: 3.2782\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5172 - val_loss: 3.2892\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.5983 - val_loss: 3.3089\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.0003 - val_loss: 3.3026\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.1208 - val_loss: 3.2985\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.1638 - val_loss: 3.2756\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.1504 - val_loss: 3.2862\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.9328 - val_loss: 3.3151\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 891ms/step - loss: 10.8955 - val_loss: 3.4382\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.1285 - val_loss: 3.3448\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.4495 - val_loss: 3.2622\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.4402 - val_loss: 3.2084\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.5840 - val_loss: 3.1755\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3379 - val_loss: 3.1401\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.0049 - val_loss: 3.1196\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6558 - val_loss: 3.1008\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.5897 - val_loss: 3.0927\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.3607 - val_loss: 3.0776\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.5724 - val_loss: 3.0725\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.5572 - val_loss: 3.0987\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6463 - val_loss: 3.1217\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.6457 - val_loss: 3.1533\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.0764 - val_loss: 3.2028\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.2763 - val_loss: 3.2386\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.9047 - val_loss: 3.2914\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.2919 - val_loss: 3.3463\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.5966 - val_loss: 3.3944\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.5803 - val_loss: 3.4471\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.6544 - val_loss: 3.4913\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 831ms/step - loss: 13.7786 - val_loss: 3.8327\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.8967 - val_loss: 3.7062\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 13.6160 - val_loss: 3.6125\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.5640 - val_loss: 3.5373\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.7361 - val_loss: 3.4536\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.8956 - val_loss: 3.4069\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.5750 - val_loss: 3.3595\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.9147 - val_loss: 3.3103\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.9666 - val_loss: 3.2664\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.2825 - val_loss: 3.2222\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.1850 - val_loss: 3.1863\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.0207 - val_loss: 3.1695\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.6672 - val_loss: 3.1641\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.4749 - val_loss: 3.1593\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.5141 - val_loss: 3.1597\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.2049 - val_loss: 3.1625\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.7286 - val_loss: 3.1532\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.5152 - val_loss: 3.1577\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.1855 - val_loss: 3.1579\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4016 - val_loss: 3.1536\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.2839 - val_loss: 3.1663\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.0261 - val_loss: 3.1897\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.1923 - val_loss: 3.2240\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.1376 - val_loss: 3.2532\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.2875 - val_loss: 3.2781\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.0258 - val_loss: 3.3093\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.9728 - val_loss: 3.3556\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 804ms/step - loss: 13.7474 - val_loss: 7.0429\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.1576 - val_loss: 6.9873\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.2379 - val_loss: 6.9175\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.7961 - val_loss: 6.8544\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.3457 - val_loss: 6.7829\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 11.2105 - val_loss: 6.7096\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.1235 - val_loss: 6.6227\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.0824 - val_loss: 6.5147\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.8025 - val_loss: 6.3572\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.5992 - val_loss: 6.2111\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.8569 - val_loss: 6.1132\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.5387 - val_loss: 6.0409\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.9507 - val_loss: 5.9753\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.0349 - val_loss: 5.8639\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.8308 - val_loss: 5.7681\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.6261 - val_loss: 5.7108\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.7782 - val_loss: 5.6762\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.9176 - val_loss: 5.6798\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.1667 - val_loss: 5.6440\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.2568 - val_loss: 5.5940\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.4332 - val_loss: 5.5765\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.5493 - val_loss: 5.5400\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.2409 - val_loss: 5.4848\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.7608 - val_loss: 5.4550\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.8708 - val_loss: 5.4206\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.8963 - val_loss: 5.3993\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.1839 - val_loss: 5.3960\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.9659 - val_loss: 5.3678\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.3162 - val_loss: 5.3465\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.1467 - val_loss: 5.3666\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.8911 - val_loss: 5.3641\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3820 - val_loss: 5.3676\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.7628 - val_loss: 5.4388\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.8748 - val_loss: 5.4691\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.6186 - val_loss: 5.5511\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.7742 - val_loss: 5.6122\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.3403 - val_loss: 5.6095\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.6144 - val_loss: 5.5838\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8894 - val_loss: 5.6249\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 828ms/step - loss: 13.3927 - val_loss: 4.3325\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.4583 - val_loss: 4.3107\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.3881 - val_loss: 4.3351\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.1839 - val_loss: 4.3610\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.8891 - val_loss: 4.4010\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.9786 - val_loss: 4.4201\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.8007 - val_loss: 4.4909\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.1446 - val_loss: 4.5542\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.1599 - val_loss: 4.6312\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.3020 - val_loss: 4.7064\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.5855 - val_loss: 4.6964\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.5180 - val_loss: 4.7085\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 911ms/step - loss: 13.8839 - val_loss: 1.8406\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.8868 - val_loss: 1.8487\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.2436 - val_loss: 1.8901\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 13.0841 - val_loss: 1.9247\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.7553 - val_loss: 1.9597\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.8611 - val_loss: 1.9882\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.5384 - val_loss: 2.0517\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.2458 - val_loss: 2.1104\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.3823 - val_loss: 2.1636\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.0619 - val_loss: 2.2209\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.4021 - val_loss: 2.2554\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 851ms/step - loss: 14.3299 - val_loss: 4.5347\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.3967 - val_loss: 4.4338\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.3255 - val_loss: 4.4275\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.5585 - val_loss: 4.4332\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.3600 - val_loss: 4.4240\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.0025 - val_loss: 4.3904\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.7946 - val_loss: 4.4084\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.8256 - val_loss: 4.4435\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.2455 - val_loss: 4.4826\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.5650 - val_loss: 4.5155\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.0871 - val_loss: 4.4871\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.3859 - val_loss: 4.4729\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.8312 - val_loss: 4.4948\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.5366 - val_loss: 4.5165\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.4273 - val_loss: 4.5001\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.4419 - val_loss: 4.5145\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 801ms/step - loss: 17.8531 - val_loss: 1.9609\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 17.4005 - val_loss: 1.8447\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 16.2563 - val_loss: 1.8051\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 15.4204 - val_loss: 1.7698\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 16.6452 - val_loss: 1.7512\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.4116 - val_loss: 1.7458\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.5478 - val_loss: 1.7824\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 15.2172 - val_loss: 1.8195\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 15.9390 - val_loss: 1.8773\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.3466 - val_loss: 1.9259\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.6493 - val_loss: 1.9421\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.2235 - val_loss: 1.9216\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.7595 - val_loss: 1.9444\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.8458 - val_loss: 1.9716\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.9142 - val_loss: 1.9809\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.2172 - val_loss: 2.0020\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 817ms/step - loss: 10.1932 - val_loss: 63.8960\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.1246 - val_loss: 64.1780\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.5919 - val_loss: 64.6227\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.4189 - val_loss: 64.6337\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6156 - val_loss: 65.1485\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.0981 - val_loss: 65.2598\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.7361 - val_loss: 65.4012\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.9242 - val_loss: 65.2357\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.0597 - val_loss: 65.6959\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.1673 - val_loss: 66.0850\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3739 - val_loss: 66.3447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 884ms/step - loss: 9.0187 - val_loss: 67.0628\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.6793 - val_loss: 66.9923\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6244 - val_loss: 66.9473\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.8231 - val_loss: 66.7244\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.9338 - val_loss: 66.8830\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.4090 - val_loss: 66.8217\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.9729 - val_loss: 66.7863\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.0439 - val_loss: 66.8001\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.6511 - val_loss: 67.0395\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.6275 - val_loss: 67.1263\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.2827 - val_loss: 67.1410\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.0291 - val_loss: 67.0249\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.1618 - val_loss: 67.2988\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.9235 - val_loss: 67.4457\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 2s/step - loss: 8.9016 - val_loss: 76.9294\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.8798 - val_loss: 77.0563\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.0275 - val_loss: 77.2090\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.3038 - val_loss: 77.0299\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.6092 - val_loss: 77.1433\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.4283 - val_loss: 77.1101\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.5633 - val_loss: 77.0849\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.8292 - val_loss: 77.1009\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.3863 - val_loss: 77.1764\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.9059 - val_loss: 77.0878\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.6337 - val_loss: 76.9526\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 17s 813ms/step - loss: 8.0529 - val_loss: 93.3233\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.2505 - val_loss: 93.4033\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.2950 - val_loss: 93.4991\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6589 - val_loss: 93.5478\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.1781 - val_loss: 93.6909\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4271 - val_loss: 93.7869\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.9825 - val_loss: 93.8970\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.8574 - val_loss: 94.0164\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8006 - val_loss: 94.1889\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.1473 - val_loss: 94.3512\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.1071 - val_loss: 94.5024\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 18s 809ms/step - loss: 16.1993 - val_loss: 9.2286\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.7087 - val_loss: 9.1316\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.9312 - val_loss: 9.0976\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.7251 - val_loss: 9.0886\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.1930 - val_loss: 9.0570\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.4812 - val_loss: 9.0015\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.7096 - val_loss: 8.9672\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.8412 - val_loss: 8.9475\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.0479 - val_loss: 8.9525\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.2312 - val_loss: 8.9601\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.8027 - val_loss: 8.9612\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.6978 - val_loss: 8.9840\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.0651 - val_loss: 9.0003\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.7802 - val_loss: 9.0136\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.9323 - val_loss: 9.0404\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.1965 - val_loss: 9.0595\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.2666 - val_loss: 9.0202\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.4297 - val_loss: 8.9826\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 869ms/step - loss: 13.6250 - val_loss: 7.4226\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.8821 - val_loss: 7.4576\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.4173 - val_loss: 7.4859\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.2392 - val_loss: 7.5027\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.2071 - val_loss: 7.5318\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.6814 - val_loss: 7.5566\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.4560 - val_loss: 7.5924\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.7132 - val_loss: 7.6267\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.7672 - val_loss: 7.6699\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.3150 - val_loss: 7.7027\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.0704 - val_loss: 7.7370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 830ms/step - loss: 10.7946 - val_loss: 12.0818\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.4857 - val_loss: 12.3238\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.3558 - val_loss: 12.5507\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.9164 - val_loss: 12.8269\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.8732 - val_loss: 13.1519\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.3831 - val_loss: 13.4228\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4733 - val_loss: 13.7503\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.5191 - val_loss: 14.0489\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.9543 - val_loss: 14.2680\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5805 - val_loss: 14.5106\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.9916 - val_loss: 14.8313\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 794ms/step - loss: 12.0263 - val_loss: 7.1052\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.8889 - val_loss: 7.0912\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.0955 - val_loss: 7.0815\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.7703 - val_loss: 7.0579\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.3329 - val_loss: 7.0360\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.6216 - val_loss: 7.0167\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.1159 - val_loss: 6.9961\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.3124 - val_loss: 6.9836\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.0247 - val_loss: 6.9815\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.0251 - val_loss: 6.9700\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.5782 - val_loss: 6.9679\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.7711 - val_loss: 6.9770\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.4431 - val_loss: 6.9734\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.0614 - val_loss: 6.9743\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.4895 - val_loss: 6.9828\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.3893 - val_loss: 6.9959\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.8878 - val_loss: 7.0086\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.8980 - val_loss: 7.0364\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.9677 - val_loss: 7.0600\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.6533 - val_loss: 7.0774\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.7043 - val_loss: 7.0989\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 829ms/step - loss: 17.6715 - val_loss: 5.5702\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 16.3932 - val_loss: 5.6249\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 17.6829 - val_loss: 5.6068\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.8741 - val_loss: 5.6102\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.5374 - val_loss: 5.6596\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.7875 - val_loss: 5.7227\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.2438 - val_loss: 5.7874\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.5236 - val_loss: 5.8564\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 15.6622 - val_loss: 5.8797\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.5615 - val_loss: 5.9169\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.0770 - val_loss: 5.9191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 900ms/step - loss: 16.7328 - val_loss: 4.9440\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.7762 - val_loss: 4.9609\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.8045 - val_loss: 4.9318\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.6245 - val_loss: 4.9129\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.4717 - val_loss: 4.8924\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.7055 - val_loss: 4.8543\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 15.3615 - val_loss: 4.8544\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.9117 - val_loss: 4.8470\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.9121 - val_loss: 4.8308\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.7525 - val_loss: 4.8116\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.9331 - val_loss: 4.7961\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.0850 - val_loss: 4.7743\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.9045 - val_loss: 4.7502\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.4006 - val_loss: 4.7271\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.2167 - val_loss: 4.7176\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.0083 - val_loss: 4.6996\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.5612 - val_loss: 4.6770\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3633 - val_loss: 4.6676\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.6830 - val_loss: 4.6624\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.3484 - val_loss: 4.6551\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.7988 - val_loss: 4.6379\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.1742 - val_loss: 4.6200\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.2728 - val_loss: 4.5983\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.2508 - val_loss: 4.5853\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.5777 - val_loss: 4.5674\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.5711 - val_loss: 4.5443\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.4426 - val_loss: 4.5201\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7049 - val_loss: 4.5011\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.9694 - val_loss: 4.4793\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.0994 - val_loss: 4.4864\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.5794 - val_loss: 4.4948\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.2769 - val_loss: 4.4687\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.3854 - val_loss: 4.4733\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.1217 - val_loss: 4.4648\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.6669 - val_loss: 4.5024\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.3680 - val_loss: 4.4844\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6228 - val_loss: 4.4650\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3684 - val_loss: 4.4132\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6958 - val_loss: 4.3877\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.7152 - val_loss: 4.3286\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.9115 - val_loss: 4.2676\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.9858 - val_loss: 4.2591\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9357 - val_loss: 4.2370\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4161 - val_loss: 4.1930\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0879 - val_loss: 4.1588\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.0246 - val_loss: 4.1149\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.2287 - val_loss: 4.0704\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.1621 - val_loss: 4.0584\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9971 - val_loss: 4.0360\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9081 - val_loss: 3.9855\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.0792 - val_loss: 3.9524\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.5233 - val_loss: 3.9495\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.9210 - val_loss: 3.9649\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.9288 - val_loss: 3.9562\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4120 - val_loss: 3.9303\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4185 - val_loss: 3.9096\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.3336 - val_loss: 3.8786\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.5062 - val_loss: 3.8646\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.0037 - val_loss: 3.8274\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.4434 - val_loss: 3.7790\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.2046 - val_loss: 3.7710\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9074 - val_loss: 3.7849\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.7775 - val_loss: 3.7919\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4142 - val_loss: 3.8017\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.1253 - val_loss: 3.7550\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.0036 - val_loss: 3.7189\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.4194 - val_loss: 3.6937\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.1443 - val_loss: 3.7273\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.5371 - val_loss: 3.7736\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.2202 - val_loss: 3.8324\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.5605 - val_loss: 3.8185\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.4250 - val_loss: 3.8301\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.1059 - val_loss: 3.8438\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.4022 - val_loss: 3.8684\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.9791 - val_loss: 3.9131\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.0521 - val_loss: 3.9697\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.4301 - val_loss: 3.9663\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 795ms/step - loss: 18.2714 - val_loss: 6.1254\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.0399 - val_loss: 5.8972\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.4676 - val_loss: 5.6152\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 14.0601 - val_loss: 5.3741\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 14.8145 - val_loss: 5.1733\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.8997 - val_loss: 4.9295\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 14.8951 - val_loss: 4.6915\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.8028 - val_loss: 4.5022\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.1515 - val_loss: 4.3142\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.6927 - val_loss: 4.1824\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.0537 - val_loss: 4.0707\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.0720 - val_loss: 3.9591\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.6095 - val_loss: 3.8555\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 11.4629 - val_loss: 3.7766\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.1084 - val_loss: 3.7259\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.7789 - val_loss: 3.6084\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.2249 - val_loss: 3.5290\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.1194 - val_loss: 3.4666\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.7332 - val_loss: 3.4075\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.8782 - val_loss: 3.3012\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.1634 - val_loss: 3.2219\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3375 - val_loss: 3.2037\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.5873 - val_loss: 3.1281\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.3189 - val_loss: 3.0572\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4727 - val_loss: 3.0125\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.0170 - val_loss: 2.9421\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4087 - val_loss: 2.9084\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.0857 - val_loss: 2.8433\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.1223 - val_loss: 2.7880\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.7793 - val_loss: 2.7258\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.8017 - val_loss: 2.6781\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.1836 - val_loss: 2.6163\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.9537 - val_loss: 2.5759\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.8845 - val_loss: 2.5187\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.9122 - val_loss: 2.4886\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.5158 - val_loss: 2.3988\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.1856 - val_loss: 2.3352\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.4113 - val_loss: 2.2590\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8972 - val_loss: 2.2266\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.8980 - val_loss: 2.1751\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6684 - val_loss: 2.1226\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.0366 - val_loss: 2.0933\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.2267 - val_loss: 2.0929\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.8514 - val_loss: 2.0675\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.7956 - val_loss: 2.0333\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.9424 - val_loss: 1.9915\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.9378 - val_loss: 1.9741\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.6171 - val_loss: 1.9569\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.7680 - val_loss: 1.9541\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.1354 - val_loss: 1.9293\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.8611 - val_loss: 1.9119\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4757 - val_loss: 1.8995\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.6223 - val_loss: 1.8790\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6698 - val_loss: 1.8511\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.9223 - val_loss: 1.8309\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.2619 - val_loss: 1.8371\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.8249 - val_loss: 1.8417\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.0317 - val_loss: 1.8632\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.5097 - val_loss: 1.8147\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.8596 - val_loss: 1.7443\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.5393 - val_loss: 1.7088\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9179 - val_loss: 1.7045\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.8405 - val_loss: 1.7056\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8069 - val_loss: 1.6927\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9054 - val_loss: 1.6543\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.6540 - val_loss: 1.6240\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.8223 - val_loss: 1.6024\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.5631 - val_loss: 1.5686\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.7229 - val_loss: 1.5607\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9027 - val_loss: 1.5552\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5395 - val_loss: 1.5284\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.5559 - val_loss: 1.5279\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.3677 - val_loss: 1.5254\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4048 - val_loss: 1.5087\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2955 - val_loss: 1.4913\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5831 - val_loss: 1.4518\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8299 - val_loss: 1.4350\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.6269 - val_loss: 1.4244\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.2563 - val_loss: 1.4134\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8261 - val_loss: 1.4195\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9255 - val_loss: 1.4313\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.6156 - val_loss: 1.4370\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.1340 - val_loss: 1.4295\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.3506 - val_loss: 1.4248\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0423 - val_loss: 1.4172\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1251 - val_loss: 1.4088\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.5707 - val_loss: 1.4129\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.5231 - val_loss: 1.3892\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9778 - val_loss: 1.3861\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.3612 - val_loss: 1.3741\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.7256 - val_loss: 1.3721\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.2873 - val_loss: 1.3663\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.8646 - val_loss: 1.3600\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.4493 - val_loss: 1.3456\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.4935 - val_loss: 1.3386\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.1358 - val_loss: 1.3241\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1109 - val_loss: 1.2941\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.6348 - val_loss: 1.2509\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.5682 - val_loss: 1.2264\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.7956 - val_loss: 1.2180\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.6952 - val_loss: 1.2204\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.4110 - val_loss: 1.2341\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.3162 - val_loss: 1.2378\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.6426 - val_loss: 1.2467\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1947 - val_loss: 1.2467\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.4485 - val_loss: 1.2335\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.3946 - val_loss: 1.2148\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.5209 - val_loss: 1.2080\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.6956 - val_loss: 1.1945\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.6367 - val_loss: 1.1765\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.4991 - val_loss: 1.1615\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.8444 - val_loss: 1.1556\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.2829 - val_loss: 1.1571\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9564 - val_loss: 1.1645\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.7855 - val_loss: 1.1734\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.2487 - val_loss: 1.1827\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.8236 - val_loss: 1.1949\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.3101 - val_loss: 1.2131\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.1302 - val_loss: 1.2244\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.4365 - val_loss: 1.2302\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.0262 - val_loss: 1.2313\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.8071 - val_loss: 1.2272\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 766ms/step - loss: 19.8229 - val_loss: 8.3825\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 18.8115 - val_loss: 8.4086\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 17.3270 - val_loss: 8.4391\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.2926 - val_loss: 8.4807\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.0219 - val_loss: 8.4987\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.0594 - val_loss: 8.5077\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 16.3645 - val_loss: 8.4761\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.4905 - val_loss: 8.4575\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 15.0683 - val_loss: 8.4119\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 16.0864 - val_loss: 8.3518\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 15.6142 - val_loss: 8.2657\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 15.1246 - val_loss: 8.1356\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.5453 - val_loss: 7.9943\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.4602 - val_loss: 7.8862\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.5043 - val_loss: 7.8129\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 15.7666 - val_loss: 7.7308\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.9897 - val_loss: 7.6372\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.7110 - val_loss: 7.5475\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.3065 - val_loss: 7.4807\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 13.8789 - val_loss: 7.4313\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.0282 - val_loss: 7.3486\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.6000 - val_loss: 7.2817\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.4081 - val_loss: 7.2322\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.0935 - val_loss: 7.2012\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.7346 - val_loss: 7.1507\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 16.7023 - val_loss: 7.1298\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 11.0491 - val_loss: 7.0927\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.4580 - val_loss: 7.0523\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.7197 - val_loss: 7.0716\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 11.7029 - val_loss: 7.1323\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.4660 - val_loss: 7.1071\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.4108 - val_loss: 7.0641\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.3572 - val_loss: 7.0375\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.5530 - val_loss: 7.0168\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.2583 - val_loss: 6.9865\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 12.5915 - val_loss: 6.9545\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.9627 - val_loss: 6.9295\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.7854 - val_loss: 6.8977\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.6561 - val_loss: 6.8902\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.1178 - val_loss: 6.8533\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 12.3009 - val_loss: 6.8325\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.2168 - val_loss: 6.8278\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.9803 - val_loss: 6.8140\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.3490 - val_loss: 6.8006\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.8602 - val_loss: 6.7816\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.9677 - val_loss: 6.7750\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.4530 - val_loss: 6.7383\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.5469 - val_loss: 6.7162\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.3248 - val_loss: 6.7252\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.3201 - val_loss: 6.7110\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.9142 - val_loss: 6.7004\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.2586 - val_loss: 6.7098\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.7590 - val_loss: 6.7371\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.0370 - val_loss: 6.7634\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.1223 - val_loss: 6.8083\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.3799 - val_loss: 6.8473\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.9054 - val_loss: 6.8658\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 13.2288 - val_loss: 6.8737\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.7059 - val_loss: 6.8506\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.7316 - val_loss: 6.8380\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.7354 - val_loss: 6.8464\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 792ms/step - loss: 10.9913 - val_loss: 4.5955\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.3947 - val_loss: 4.5329\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.9241 - val_loss: 4.4766\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.8905 - val_loss: 4.4782\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.7964 - val_loss: 4.3554\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.1299 - val_loss: 4.3642\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.1766 - val_loss: 4.3292\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10.1659 - val_loss: 4.3034\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10.2037 - val_loss: 4.2430\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.0384 - val_loss: 4.1950\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.7847 - val_loss: 4.1894\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.6334 - val_loss: 4.1860\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.3118 - val_loss: 4.2290\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.4648 - val_loss: 4.1588\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.7114 - val_loss: 4.1043\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.9097 - val_loss: 4.0978\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.7781 - val_loss: 4.1126\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.0132 - val_loss: 4.1101\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.9959 - val_loss: 4.1101\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.9814 - val_loss: 4.0496\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.9349 - val_loss: 4.0222\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.0190 - val_loss: 4.0147\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.5650 - val_loss: 4.0043\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.9458 - val_loss: 4.0401\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.9301 - val_loss: 4.0366\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.3996 - val_loss: 4.0473\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.2368 - val_loss: 4.0557\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.5991 - val_loss: 4.0820\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.3803 - val_loss: 4.0747\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.3842 - val_loss: 4.0635\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.0410 - val_loss: 4.0742\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.3596 - val_loss: 4.0367\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.6659 - val_loss: 4.0018\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3546 - val_loss: 3.9750\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.3704 - val_loss: 4.0190\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.7327 - val_loss: 4.0422\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.4703 - val_loss: 3.9837\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.6760 - val_loss: 3.9774\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5568 - val_loss: 3.9206\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.1017 - val_loss: 3.8885\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.1448 - val_loss: 3.8444\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.9528 - val_loss: 3.8693\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.6510 - val_loss: 3.8689\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.7732 - val_loss: 3.8492\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.5016 - val_loss: 3.8514\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.6367 - val_loss: 3.8443\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.3885 - val_loss: 3.9202\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8955 - val_loss: 3.9566\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.3522 - val_loss: 3.9721\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.3871 - val_loss: 4.0004\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.1595 - val_loss: 3.9837\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.3123 - val_loss: 3.9809\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3789 - val_loss: 3.9926\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.5007 - val_loss: 4.0244\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.7570 - val_loss: 4.0037\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.6190 - val_loss: 4.0389\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 878ms/step - loss: 18.4143 - val_loss: 1.7247\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 17.8121 - val_loss: 1.8584\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 18.2271 - val_loss: 1.9940\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 15.0783 - val_loss: 2.1665\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.9115 - val_loss: 2.2628\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.1353 - val_loss: 2.4655\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 14.2367 - val_loss: 2.6252\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 13.8685 - val_loss: 2.7778\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.1692 - val_loss: 2.9048\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.0271 - val_loss: 3.0183\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.1679 - val_loss: 3.1631\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 812ms/step - loss: 21.1562 - val_loss: 4.9534\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 16.3346 - val_loss: 5.1100\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 16.2619 - val_loss: 5.4122\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 15.9315 - val_loss: 5.6352\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.4738 - val_loss: 5.6540\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13.6188 - val_loss: 5.7495\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.5393 - val_loss: 5.7065\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12.9780 - val_loss: 5.6911\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.4996 - val_loss: 5.6557\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 11.0584 - val_loss: 5.5764\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.3339 - val_loss: 5.4513\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 792ms/step - loss: 14.9094 - val_loss: 1.1559\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 14.9245 - val_loss: 1.1558\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 17.6265 - val_loss: 1.1597\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 13.8742 - val_loss: 1.1645\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 11.9438 - val_loss: 1.1654\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.6686 - val_loss: 1.1847\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 10.4930 - val_loss: 1.2028\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 10.6262 - val_loss: 1.2150\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 12.3620 - val_loss: 1.2265\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.3110 - val_loss: 1.2410\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.9729 - val_loss: 1.2547\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 12.2324 - val_loss: 1.2681\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 841ms/step - loss: 10.9011 - val_loss: 10.6518\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11.0514 - val_loss: 10.1908\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.8754 - val_loss: 9.7936\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.4741 - val_loss: 9.4600\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.2492 - val_loss: 9.1145\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.2118 - val_loss: 8.8726\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.2897 - val_loss: 8.6542\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.0132 - val_loss: 8.4884\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4062 - val_loss: 8.3393\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6780 - val_loss: 8.1978\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6921 - val_loss: 8.1146\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5262 - val_loss: 8.0403\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.1267 - val_loss: 7.9869\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.3819 - val_loss: 7.9385\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.0302 - val_loss: 7.8894\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.6569 - val_loss: 7.9040\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.3643 - val_loss: 7.8135\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9265 - val_loss: 7.7216\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.5841 - val_loss: 7.6526\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2535 - val_loss: 7.5509\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.1674 - val_loss: 7.4876\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.0349 - val_loss: 7.4172\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.9334 - val_loss: 7.3190\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.1834 - val_loss: 7.2253\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4023 - val_loss: 7.2179\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.7695 - val_loss: 7.2031\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4842 - val_loss: 7.2276\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.5025 - val_loss: 7.2444\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3410 - val_loss: 7.1899\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.2702 - val_loss: 7.1654\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2179 - val_loss: 7.2465\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.5360 - val_loss: 7.3272\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.9677 - val_loss: 7.3927\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.0512 - val_loss: 7.5373\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4677 - val_loss: 7.6673\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.1055 - val_loss: 7.6610\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.7993 - val_loss: 7.6587\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.7919 - val_loss: 7.7093\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.8378 - val_loss: 7.7376\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7796 - val_loss: 7.7527\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 923ms/step - loss: 10.8664 - val_loss: 8.8363\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.3608 - val_loss: 8.4991\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.9157 - val_loss: 8.2165\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.7295 - val_loss: 7.9531\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.1992 - val_loss: 7.6427\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.6349 - val_loss: 7.3363\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.7737 - val_loss: 7.1578\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.0833 - val_loss: 6.9807\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.5295 - val_loss: 6.8269\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.8385 - val_loss: 6.6606\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.5040 - val_loss: 6.5227\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.6854 - val_loss: 6.4390\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.0173 - val_loss: 6.3459\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.3266 - val_loss: 6.3005\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.5940 - val_loss: 6.2526\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4823 - val_loss: 6.2326\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.4500 - val_loss: 6.1913\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.2950 - val_loss: 6.1802\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.7928 - val_loss: 6.1663\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.6280 - val_loss: 6.1467\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.6353 - val_loss: 6.1450\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.2532 - val_loss: 6.1343\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.8240 - val_loss: 6.1151\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.1547 - val_loss: 6.1357\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.1782 - val_loss: 6.1340\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.3762 - val_loss: 6.1384\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.8323 - val_loss: 6.1921\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.9664 - val_loss: 6.2410\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.9422 - val_loss: 6.2484\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.6907 - val_loss: 6.2696\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7638 - val_loss: 6.2818\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4137 - val_loss: 6.2784\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0479 - val_loss: 6.3083\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 843ms/step - loss: 9.9096 - val_loss: 7.1494\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.0009 - val_loss: 6.5690\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.5216 - val_loss: 6.2018\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.3765 - val_loss: 5.8342\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.8316 - val_loss: 5.4839\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.3305 - val_loss: 5.2520\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.8845 - val_loss: 5.0759\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.1267 - val_loss: 4.9265\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4797 - val_loss: 4.7910\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.4446 - val_loss: 4.6985\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.5041 - val_loss: 4.6569\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.3640 - val_loss: 4.6515\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8601 - val_loss: 4.6962\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.9549 - val_loss: 4.7183\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4582 - val_loss: 4.7414\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.1661 - val_loss: 4.7854\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.7028 - val_loss: 4.7953\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.1099 - val_loss: 4.8291\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.6551 - val_loss: 4.8358\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6103 - val_loss: 4.8177\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.2163 - val_loss: 4.8224\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.1873 - val_loss: 4.8754\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 540us/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 840ms/step - loss: 9.5957 - val_loss: 6.8389\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.1542 - val_loss: 6.8439\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.8562 - val_loss: 6.8388\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.6379 - val_loss: 6.8159\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.7013 - val_loss: 6.7958\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.7422 - val_loss: 6.7616\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.6219 - val_loss: 6.7510\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.4671 - val_loss: 6.7336\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.2736 - val_loss: 6.7147\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.2949 - val_loss: 6.6951\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6703 - val_loss: 6.6890\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.9937 - val_loss: 6.6539\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.3871 - val_loss: 6.6213\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.8680 - val_loss: 6.6064\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.5307 - val_loss: 6.5956\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2582 - val_loss: 6.5949\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.5207 - val_loss: 6.5890\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6014 - val_loss: 6.6064\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.7834 - val_loss: 6.6206\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.3781 - val_loss: 6.6143\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.3099 - val_loss: 6.6097\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6575 - val_loss: 6.6069\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.3214 - val_loss: 6.6146\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6655 - val_loss: 6.6274\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.6546 - val_loss: 6.6428\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.4019 - val_loss: 6.6637\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.9833 - val_loss: 6.6873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 878ms/step - loss: 9.5216 - val_loss: 3.7084\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.2009 - val_loss: 3.5741\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.6376 - val_loss: 3.5153\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.2915 - val_loss: 3.4746\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.2726 - val_loss: 3.4140\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.6482 - val_loss: 3.3658\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.2819 - val_loss: 3.3154\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.3237 - val_loss: 3.2793\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.2460 - val_loss: 3.2757\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.9125 - val_loss: 3.2894\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.0221 - val_loss: 3.3124\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0386 - val_loss: 3.3212\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.5293 - val_loss: 3.3250\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.7419 - val_loss: 3.3483\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.7783 - val_loss: 3.3777\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.1408 - val_loss: 3.4028\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.8375 - val_loss: 3.4326\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.0279 - val_loss: 3.4464\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.9383 - val_loss: 3.4602\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 8.4188 - val_loss: 5.0704\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.0315 - val_loss: 5.1237\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.3327 - val_loss: 5.1613\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3712 - val_loss: 5.2099\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.4385 - val_loss: 5.2970\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.3208 - val_loss: 5.3565\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6146 - val_loss: 5.4070\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.1092 - val_loss: 5.4646\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.9097 - val_loss: 5.5228\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4444 - val_loss: 5.5599\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.7566 - val_loss: 5.5935\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 921ms/step - loss: 12.0715 - val_loss: 5.5124\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.9194 - val_loss: 5.6049\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 10.1585 - val_loss: 5.7294\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 10.0580 - val_loss: 5.8487\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.2004 - val_loss: 5.9377\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.7293 - val_loss: 5.9738\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.1909 - val_loss: 5.9644\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4894 - val_loss: 5.9421\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.1046 - val_loss: 5.9802\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6993 - val_loss: 5.9821\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.2229 - val_loss: 5.9539\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 923ms/step - loss: 9.9730 - val_loss: 4.8323\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.8574 - val_loss: 4.8325\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.8004 - val_loss: 4.8290\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.3394 - val_loss: 4.8529\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.5588 - val_loss: 4.9034\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.8894 - val_loss: 4.9295\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.5096 - val_loss: 4.9355\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.8495 - val_loss: 4.9410\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.3964 - val_loss: 4.9545\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4291 - val_loss: 4.9736\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.7145 - val_loss: 4.9932\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.0221 - val_loss: 5.0069\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3158 - val_loss: 5.0183\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 937ms/step - loss: 6.8375 - val_loss: 64.2491\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.1488 - val_loss: 61.9993\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.0167 - val_loss: 60.1193\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.5506 - val_loss: 58.2214\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.1326 - val_loss: 56.1222\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0655 - val_loss: 54.6348\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.1338 - val_loss: 53.2703\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.5284 - val_loss: 52.0370\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.1519 - val_loss: 50.8702\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.9383 - val_loss: 49.7750\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.4435 - val_loss: 48.9022\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.1060 - val_loss: 47.9096\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.1090 - val_loss: 47.1842\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.5328 - val_loss: 46.3222\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.6060 - val_loss: 45.4416\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.9537 - val_loss: 44.6290\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.0997 - val_loss: 43.7972\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.5870 - val_loss: 43.3787\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.3135 - val_loss: 42.6537\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3859 - val_loss: 41.7762\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.1772 - val_loss: 41.0427\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.6225 - val_loss: 40.5568\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.8151 - val_loss: 40.1283\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.5656 - val_loss: 39.9400\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.9716 - val_loss: 39.5830\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.3745 - val_loss: 39.2886\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.9149 - val_loss: 39.1147\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.8796 - val_loss: 39.0567\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.0615 - val_loss: 39.0574\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.6090 - val_loss: 38.7491\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.6352 - val_loss: 38.1748\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.5353 - val_loss: 37.9116\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.5872 - val_loss: 37.7018\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.3100 - val_loss: 37.6563\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.9022 - val_loss: 37.2460\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.7217 - val_loss: 36.8608\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.4513 - val_loss: 36.5493\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 2.9197 - val_loss: 36.3819\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.1565 - val_loss: 36.0913\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.0745 - val_loss: 36.3230\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.4891 - val_loss: 36.2107\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.4040 - val_loss: 36.2238\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1958 - val_loss: 36.6540\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.9682 - val_loss: 36.9708\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.1789 - val_loss: 37.3816\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.0823 - val_loss: 37.4818\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.9712 - val_loss: 37.4254\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.8821 - val_loss: 37.2157\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.3412 - val_loss: 36.7574\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 7.2418 - val_loss: 78.1936\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.8535 - val_loss: 76.7346\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.8198 - val_loss: 75.3572\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.3392 - val_loss: 74.0556\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.0415 - val_loss: 72.7472\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.7226 - val_loss: 71.8439\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.8756 - val_loss: 71.0851\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.5006 - val_loss: 69.8999\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.4972 - val_loss: 68.5214\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.1251 - val_loss: 67.1535\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.1170 - val_loss: 65.9839\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3683 - val_loss: 64.9674\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.0113 - val_loss: 64.1836\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.9496 - val_loss: 63.4611\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.2285 - val_loss: 62.9930\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.7956 - val_loss: 62.5733\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7626 - val_loss: 61.9643\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.5579 - val_loss: 61.7340\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.0211 - val_loss: 61.1606\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.8637 - val_loss: 60.5572\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.6648 - val_loss: 60.4505\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7457 - val_loss: 60.5551\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.9316 - val_loss: 60.4062\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.9405 - val_loss: 60.6974\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.0300 - val_loss: 60.7597\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.6955 - val_loss: 60.9736\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.5086 - val_loss: 61.0941\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.6260 - val_loss: 61.6560\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.4797 - val_loss: 62.3920\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.1803 - val_loss: 62.2899\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.0486 - val_loss: 62.2007\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.4866 - val_loss: 62.3749\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.3501 - val_loss: 62.8366\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 986ms/step - loss: 6.8871 - val_loss: 78.7432\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.5661 - val_loss: 77.0295\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.5670 - val_loss: 75.9466\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.1056 - val_loss: 74.5845\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.1223 - val_loss: 72.6546\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0178 - val_loss: 71.8717\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.0127 - val_loss: 71.2585\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.3862 - val_loss: 70.7456\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.0740 - val_loss: 70.6501\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.9180 - val_loss: 70.2232\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.9072 - val_loss: 70.2894\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.0033 - val_loss: 70.3070\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.7267 - val_loss: 71.0526\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.9891 - val_loss: 71.1103\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.2597 - val_loss: 71.2026\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7716 - val_loss: 71.1983\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.2623 - val_loss: 71.1921\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6340 - val_loss: 71.5871\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.4169 - val_loss: 71.4435\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.2936 - val_loss: 71.1838\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 874ms/step - loss: 8.3977 - val_loss: 67.1482\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4172 - val_loss: 66.7485\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.0535 - val_loss: 66.4725\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.5674 - val_loss: 66.1799\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.9350 - val_loss: 65.7254\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.2024 - val_loss: 65.5614\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.8873 - val_loss: 65.2382\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6014 - val_loss: 64.8546\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.7416 - val_loss: 64.4569\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.9003 - val_loss: 64.0800\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.9120 - val_loss: 63.7582\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.0393 - val_loss: 63.3158\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.5975 - val_loss: 63.1262\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.7556 - val_loss: 62.8604\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.6877 - val_loss: 62.6797\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.4906 - val_loss: 62.5581\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.0688 - val_loss: 62.3368\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.6396 - val_loss: 62.4526\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.5224 - val_loss: 62.2263\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.8428 - val_loss: 61.8343\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.9852 - val_loss: 61.5889\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.0503 - val_loss: 61.5779\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.2460 - val_loss: 61.4188\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.1848 - val_loss: 61.3088\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.7357 - val_loss: 61.0914\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.0106 - val_loss: 60.9270\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7461 - val_loss: 60.6717\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 3.6983 - val_loss: 60.6005\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.0017 - val_loss: 60.6099\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.0455 - val_loss: 60.3368\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.1223 - val_loss: 60.1421\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.2734 - val_loss: 60.0849\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.1641 - val_loss: 59.9427\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.6817 - val_loss: 60.0068\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4079 - val_loss: 59.7884\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.1845 - val_loss: 59.5581\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.5375 - val_loss: 59.4109\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.1107 - val_loss: 59.3019\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 3.4599 - val_loss: 58.9721\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.6846 - val_loss: 58.5386\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0348 - val_loss: 57.8852\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.2452 - val_loss: 57.5629\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.6675 - val_loss: 57.5800\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.3921 - val_loss: 57.3513\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.7453 - val_loss: 57.2232\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 2.6073 - val_loss: 56.9623\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.8207 - val_loss: 56.9913\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.6467 - val_loss: 57.2245\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.1469 - val_loss: 57.1038\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.2315 - val_loss: 56.8975\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.2301 - val_loss: 56.5927\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.0629 - val_loss: 56.3834\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.1568 - val_loss: 56.4161\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.6788 - val_loss: 56.4628\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.8724 - val_loss: 56.2177\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.0283 - val_loss: 55.9060\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.6836 - val_loss: 56.0959\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.2504 - val_loss: 55.9169\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.0682 - val_loss: 55.7401\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.1949 - val_loss: 55.7928\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.4234 - val_loss: 55.8965\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.3331 - val_loss: 55.5570\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0904 - val_loss: 55.3053\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 2.8512 - val_loss: 55.1213\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.0124 - val_loss: 55.1854\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.2665 - val_loss: 55.6243\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.2069 - val_loss: 55.8791\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.4550 - val_loss: 56.3501\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.4212 - val_loss: 56.5572\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.0527 - val_loss: 56.9186\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.1655 - val_loss: 56.5984\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.9691 - val_loss: 56.0659\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.7542 - val_loss: 56.0436\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.3487 - val_loss: 55.8053\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 905ms/step - loss: 9.5506 - val_loss: 15.9715\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.5780 - val_loss: 14.2043\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.3402 - val_loss: 12.7841\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8520 - val_loss: 11.8302\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.7381 - val_loss: 11.1394\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.7452 - val_loss: 10.4832\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.1387 - val_loss: 9.9848\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4056 - val_loss: 9.5497\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.8362 - val_loss: 9.2284\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.8445 - val_loss: 9.0475\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.3360 - val_loss: 8.8813\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.7385 - val_loss: 8.8054\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.2035 - val_loss: 8.7079\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.6723 - val_loss: 8.6700\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.3857 - val_loss: 8.5529\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.3807 - val_loss: 8.4672\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.3287 - val_loss: 8.4360\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.3453 - val_loss: 8.4825\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.6040 - val_loss: 8.4202\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.3999 - val_loss: 8.3876\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.9357 - val_loss: 8.2514\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.9986 - val_loss: 8.1229\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.1998 - val_loss: 8.0954\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.0305 - val_loss: 8.0629\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.8933 - val_loss: 8.0069\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.6427 - val_loss: 7.8961\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.5762 - val_loss: 7.7668\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.0321 - val_loss: 7.6842\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.7001 - val_loss: 7.5694\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.8179 - val_loss: 7.5291\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.6197 - val_loss: 7.4163\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3669 - val_loss: 7.3713\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.0579 - val_loss: 7.3395\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.7278 - val_loss: 7.3335\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.0616 - val_loss: 7.3587\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.4061 - val_loss: 7.3197\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.1935 - val_loss: 7.2057\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.5529 - val_loss: 7.0618\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 3.9461 - val_loss: 6.9646\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.0038 - val_loss: 6.9381\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.1468 - val_loss: 6.9450\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.2506 - val_loss: 6.8479\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.0788 - val_loss: 6.7741\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.8521 - val_loss: 6.8766\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.5412 - val_loss: 6.9471\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.7969 - val_loss: 6.9883\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.9625 - val_loss: 7.0355\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.6559 - val_loss: 7.0814\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.3251 - val_loss: 6.9997\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.5204 - val_loss: 6.9126\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.5521 - val_loss: 6.9382\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.2221 - val_loss: 6.9983\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.7744 - val_loss: 7.0403\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 33s 1s/step - loss: 7.9582 - val_loss: 6.5080\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.1691 - val_loss: 6.6108\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.9268 - val_loss: 6.6661\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.1814 - val_loss: 6.6951\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.5268 - val_loss: 6.7405\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.9616 - val_loss: 6.7639\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.2402 - val_loss: 6.5819\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.3046 - val_loss: 6.4761\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.1497 - val_loss: 6.4120\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8078 - val_loss: 6.3315\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.6418 - val_loss: 6.3637\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.0192 - val_loss: 6.4265\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.9595 - val_loss: 6.4997\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.0794 - val_loss: 6.5702\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.9117 - val_loss: 6.4792\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.6801 - val_loss: 6.3863\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.1638 - val_loss: 6.4961\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.3158 - val_loss: 6.6037\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7589 - val_loss: 6.6990\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.6427 - val_loss: 6.7782\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 915ms/step - loss: 7.9633 - val_loss: 7.2928\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.0274 - val_loss: 6.9888\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.6198 - val_loss: 6.7078\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.3095 - val_loss: 6.4382\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.7868 - val_loss: 6.2065\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.4563 - val_loss: 6.1042\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.3083 - val_loss: 6.0272\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.9992 - val_loss: 6.0913\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4727 - val_loss: 6.0067\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.2418 - val_loss: 5.9296\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.1427 - val_loss: 6.0823\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.0677 - val_loss: 6.2256\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.5148 - val_loss: 6.2400\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.7893 - val_loss: 6.3089\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4287 - val_loss: 6.2701\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.9417 - val_loss: 6.4021\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.3733 - val_loss: 6.6139\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.6427 - val_loss: 6.6475\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.2210 - val_loss: 6.7508\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.8682 - val_loss: 6.9227\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 899ms/step - loss: 10.7462 - val_loss: 23.7361\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.5906 - val_loss: 21.5735\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.4126 - val_loss: 19.3933\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.2952 - val_loss: 17.2601\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.2157 - val_loss: 15.7063\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.5999 - val_loss: 14.4209\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.9756 - val_loss: 13.5327\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.9179 - val_loss: 12.5370\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.5196 - val_loss: 11.4164\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.4802 - val_loss: 10.4718\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.0283 - val_loss: 9.9377\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.4728 - val_loss: 9.5891\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.3187 - val_loss: 9.2364\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.6877 - val_loss: 8.8586\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.2095 - val_loss: 8.6204\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.2178 - val_loss: 8.6904\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.4381 - val_loss: 8.7338\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6472 - val_loss: 8.7782\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.1910 - val_loss: 8.4832\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.8055 - val_loss: 8.5418\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.7950 - val_loss: 8.5443\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7807 - val_loss: 8.5356\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.9094 - val_loss: 8.6070\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.7222 - val_loss: 8.6968\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.2466 - val_loss: 8.9419\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.5751 - val_loss: 9.0986\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.1713 - val_loss: 8.8937\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.5558 - val_loss: 8.6256\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2436 - val_loss: 8.4754\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.0224 - val_loss: 8.4751\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4133 - val_loss: 8.5075\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.9904 - val_loss: 8.5516\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8498 - val_loss: 8.3805\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.3408 - val_loss: 7.9957\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.7777 - val_loss: 7.8941\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.7087 - val_loss: 7.6721\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.0039 - val_loss: 7.4537\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.2926 - val_loss: 7.5720\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.7220 - val_loss: 7.7411\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.3192 - val_loss: 8.1393\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.4125 - val_loss: 8.5076\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.5291 - val_loss: 8.7736\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.1633 - val_loss: 9.1283\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 3.6762 - val_loss: 9.3659\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.5043 - val_loss: 9.4206\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.1159 - val_loss: 9.4306\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.2311 - val_loss: 9.6255\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Executing 3adff093 iter 4\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 915ms/step - loss: 17.2330 - val_loss: 7.9454\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 17.3300 - val_loss: 7.8352\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.4113 - val_loss: 7.6929\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.7205 - val_loss: 7.5626\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.9520 - val_loss: 7.4125\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 15.4108 - val_loss: 7.2942\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 16.4217 - val_loss: 7.1695\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 16.3678 - val_loss: 7.0657\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 15.8086 - val_loss: 6.9853\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.9597 - val_loss: 6.9118\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.4814 - val_loss: 6.8455\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.2790 - val_loss: 6.7825\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 16.0087 - val_loss: 6.7247\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.4053 - val_loss: 6.6858\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.2190 - val_loss: 6.6275\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.0880 - val_loss: 6.5722\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.7436 - val_loss: 6.5309\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.6992 - val_loss: 6.4775\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.2099 - val_loss: 6.4352\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.9834 - val_loss: 6.3819\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.3059 - val_loss: 6.3325\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.8296 - val_loss: 6.3040\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.2361 - val_loss: 6.2633\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.5281 - val_loss: 6.2258\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.4030 - val_loss: 6.1967\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.9206 - val_loss: 6.1853\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.3506 - val_loss: 6.1773\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.0271 - val_loss: 6.1344\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.3318 - val_loss: 6.0939\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.4275 - val_loss: 6.0774\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.8674 - val_loss: 6.0723\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.7185 - val_loss: 6.0284\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8877 - val_loss: 5.9949\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.5866 - val_loss: 5.9594\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.4238 - val_loss: 5.9514\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.5027 - val_loss: 5.9475\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.5326 - val_loss: 5.9247\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.1980 - val_loss: 5.9131\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.2864 - val_loss: 5.9314\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.1267 - val_loss: 5.9112\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.2442 - val_loss: 5.9056\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8440 - val_loss: 5.8846\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.9884 - val_loss: 5.8665\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.7441 - val_loss: 5.8590\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.2761 - val_loss: 5.8436\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.7433 - val_loss: 5.8117\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.5133 - val_loss: 5.7949\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.3663 - val_loss: 5.7747\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.7158 - val_loss: 5.7479\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4522 - val_loss: 5.7178\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.3598 - val_loss: 5.7223\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.5784 - val_loss: 5.7116\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.3310 - val_loss: 5.7243\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.6076 - val_loss: 5.7613\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.8962 - val_loss: 5.7735\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.6664 - val_loss: 5.7878\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.8848 - val_loss: 5.7882\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.7127 - val_loss: 5.7769\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0001 - val_loss: 5.7550\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.6924 - val_loss: 5.7372\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.2833 - val_loss: 5.7131\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.0729 - val_loss: 5.7148\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 16.3520 - val_loss: 8.0759\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.5771 - val_loss: 7.9780\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.4158 - val_loss: 7.8815\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.2560 - val_loss: 7.7862\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.6004 - val_loss: 7.7057\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.1653 - val_loss: 7.6499\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.7659 - val_loss: 7.5889\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.2347 - val_loss: 7.5296\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.9064 - val_loss: 7.4752\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.1254 - val_loss: 7.4239\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.6783 - val_loss: 7.3784\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.6345 - val_loss: 7.3220\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.9522 - val_loss: 7.2601\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.5568 - val_loss: 7.1949\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.8651 - val_loss: 7.1221\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.4462 - val_loss: 7.0528\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.3269 - val_loss: 6.9956\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.8088 - val_loss: 6.9539\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.4701 - val_loss: 6.8931\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.3376 - val_loss: 6.8393\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.3374 - val_loss: 6.7896\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.1673 - val_loss: 6.7449\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.3909 - val_loss: 6.6899\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.0392 - val_loss: 6.6326\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.9673 - val_loss: 6.5779\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.2231 - val_loss: 6.5277\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.6288 - val_loss: 6.4706\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.4737 - val_loss: 6.4121\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.4737 - val_loss: 6.3514\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.3657 - val_loss: 6.2851\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.6284 - val_loss: 6.2294\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.5586 - val_loss: 6.1686\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 14.0408 - val_loss: 6.1060\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.0297 - val_loss: 6.0476\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.7979 - val_loss: 5.9791\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.4820 - val_loss: 5.9246\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.9008 - val_loss: 5.8778\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8870 - val_loss: 5.8268\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.1818 - val_loss: 5.7748\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.8085 - val_loss: 5.7322\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.9724 - val_loss: 5.6869\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.3702 - val_loss: 5.6483\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.8260 - val_loss: 5.6149\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.2334 - val_loss: 5.5761\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.6031 - val_loss: 5.5325\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.5495 - val_loss: 5.4938\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.1995 - val_loss: 5.4633\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0265 - val_loss: 5.4374\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.3800 - val_loss: 5.4112\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0966 - val_loss: 5.3892\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.6232 - val_loss: 5.3670\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.9678 - val_loss: 5.3523\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.9853 - val_loss: 5.3443\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.0466 - val_loss: 5.3336\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.9897 - val_loss: 5.3255\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.1964 - val_loss: 5.3290\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.5570 - val_loss: 5.3249\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.1384 - val_loss: 5.3124\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.2500 - val_loss: 5.3086\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.8748 - val_loss: 5.3000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.1848 - val_loss: 5.2837\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.4247 - val_loss: 5.2855\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.1550 - val_loss: 5.2737\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.8951 - val_loss: 5.2852\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1248 - val_loss: 5.2841\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.1016 - val_loss: 5.2989\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2101 - val_loss: 5.3010\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.6827 - val_loss: 5.3043\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.4236 - val_loss: 5.3080\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.2905 - val_loss: 5.3237\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5178 - val_loss: 5.3290\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.7529 - val_loss: 5.3438\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.6481 - val_loss: 5.3529\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 932ms/step - loss: 23.4104 - val_loss: 10.7162\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 22.2909 - val_loss: 10.3445\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 20.3909 - val_loss: 10.0014\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 20.2166 - val_loss: 9.6654\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 21.1493 - val_loss: 9.3468\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.4830 - val_loss: 9.0898\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 18.6258 - val_loss: 8.8198\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.4905 - val_loss: 8.5895\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 18.7915 - val_loss: 8.3623\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 18.9231 - val_loss: 8.1383\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 17.8623 - val_loss: 7.9566\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 17.7438 - val_loss: 7.7638\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 17.6226 - val_loss: 7.5896\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.7403 - val_loss: 7.4177\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 16.5667 - val_loss: 7.2640\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.3521 - val_loss: 7.1108\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.7838 - val_loss: 6.9408\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.9880 - val_loss: 6.8123\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.1615 - val_loss: 6.6807\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.9323 - val_loss: 6.5519\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.8400 - val_loss: 6.4387\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.5005 - val_loss: 6.3468\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.1158 - val_loss: 6.2406\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.8018 - val_loss: 6.1463\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.1120 - val_loss: 6.0700\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.9406 - val_loss: 5.9889\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.9044 - val_loss: 5.9165\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.7116 - val_loss: 5.8322\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.4712 - val_loss: 5.7642\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.1119 - val_loss: 5.6823\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.4381 - val_loss: 5.6289\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.9187 - val_loss: 5.5654\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.7854 - val_loss: 5.5096\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.9785 - val_loss: 5.4666\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.2402 - val_loss: 5.4091\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.0317 - val_loss: 5.3642\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.9248 - val_loss: 5.3318\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.7379 - val_loss: 5.2973\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.1381 - val_loss: 5.2540\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.2085 - val_loss: 5.2262\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.8955 - val_loss: 5.1985\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.0297 - val_loss: 5.1741\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.1951 - val_loss: 5.1482\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.4124 - val_loss: 5.1161\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.6872 - val_loss: 5.0772\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.4754 - val_loss: 5.0442\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6608 - val_loss: 5.0238\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.1337 - val_loss: 5.0030\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.6789 - val_loss: 4.9815\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.5206 - val_loss: 4.9597\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.5464 - val_loss: 4.9342\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.4291 - val_loss: 4.9161\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.3437 - val_loss: 4.9061\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.0464 - val_loss: 4.8982\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6617 - val_loss: 4.8915\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6447 - val_loss: 4.8944\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.1811 - val_loss: 4.8895\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6206 - val_loss: 4.8804\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.4426 - val_loss: 4.8716\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.4472 - val_loss: 4.8690\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.4188 - val_loss: 4.8673\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.4220 - val_loss: 4.8793\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.3230 - val_loss: 4.8744\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.4097 - val_loss: 4.8926\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.2365 - val_loss: 4.8917\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.0967 - val_loss: 4.8979\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.0194 - val_loss: 4.8989\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.4006 - val_loss: 4.9029\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.6823 - val_loss: 4.9083\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.9836 - val_loss: 4.9111\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.6040 - val_loss: 4.9172\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 902ms/step - loss: 16.5870 - val_loss: 9.0267\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 15.9743 - val_loss: 8.7730\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.7711 - val_loss: 8.5258\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 16.4639 - val_loss: 8.3251\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 16.9507 - val_loss: 8.1143\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.4164 - val_loss: 7.9602\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.7888 - val_loss: 7.7890\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 16.3356 - val_loss: 7.6393\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.5042 - val_loss: 7.4893\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.5867 - val_loss: 7.3596\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.2429 - val_loss: 7.2526\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.2491 - val_loss: 7.1172\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.6055 - val_loss: 7.0093\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.0143 - val_loss: 6.9075\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.3969 - val_loss: 6.8072\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.5034 - val_loss: 6.6984\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.3485 - val_loss: 6.5733\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.7552 - val_loss: 6.5003\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.3624 - val_loss: 6.3903\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.0564 - val_loss: 6.2985\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.4751 - val_loss: 6.2322\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.3694 - val_loss: 6.1844\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.2514 - val_loss: 6.1079\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.5396 - val_loss: 6.0335\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.3574 - val_loss: 5.9662\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.9618 - val_loss: 5.9078\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.5796 - val_loss: 5.8751\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.5826 - val_loss: 5.8348\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.0174 - val_loss: 5.7918\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.0494 - val_loss: 5.7390\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.4721 - val_loss: 5.7116\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.6790 - val_loss: 5.6694\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.2763 - val_loss: 5.6355\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.5331 - val_loss: 5.6068\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.2822 - val_loss: 5.5663\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.0642 - val_loss: 5.5347\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.3154 - val_loss: 5.5247\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 10.5743 - val_loss: 5.5109\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.5224 - val_loss: 5.4933\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.7916 - val_loss: 5.4794\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.3556 - val_loss: 5.4632\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.8191 - val_loss: 5.4675\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.9777 - val_loss: 5.4765\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.5196 - val_loss: 5.4744\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.7039 - val_loss: 5.4415\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.8151 - val_loss: 5.4067\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.6483 - val_loss: 5.4061\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.5978 - val_loss: 5.4275\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.4532 - val_loss: 5.4513\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.7214 - val_loss: 5.4700\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.7904 - val_loss: 5.4706\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.9780 - val_loss: 5.4860\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.7296 - val_loss: 5.5068\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.1606 - val_loss: 5.5220\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.1919 - val_loss: 5.5457\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.6864 - val_loss: 5.5851\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.8798 - val_loss: 5.5921\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 930ms/step - loss: 7.4533 - val_loss: 26.3006\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.1560 - val_loss: 26.2604\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.9475 - val_loss: 26.2492\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.3184 - val_loss: 26.1993\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.9619 - val_loss: 26.1887\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.4678 - val_loss: 26.1825\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.9520 - val_loss: 26.1657\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.2316 - val_loss: 26.1501\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.6957 - val_loss: 26.1529\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.7937 - val_loss: 26.0817\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.8541 - val_loss: 26.0430\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.4263 - val_loss: 26.0441\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.4874 - val_loss: 26.0607\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.5553 - val_loss: 26.1102\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.2820 - val_loss: 26.2111\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.3066 - val_loss: 26.2334\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.9635 - val_loss: 26.2328\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.2365 - val_loss: 26.2509\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.0492 - val_loss: 26.2438\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.8196 - val_loss: 26.2127\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.9574 - val_loss: 26.2169\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 6.8451 - val_loss: 23.8156\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.8413 - val_loss: 23.7662\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.5801 - val_loss: 23.7686\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.0037 - val_loss: 23.7080\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.0034 - val_loss: 23.7203\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.8078 - val_loss: 23.7155\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.5823 - val_loss: 23.6962\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.7535 - val_loss: 23.6991\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.6418 - val_loss: 23.7208\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.6219 - val_loss: 23.6893\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.4431 - val_loss: 23.6730\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.5517 - val_loss: 23.6664\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.4972 - val_loss: 23.6584\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.3424 - val_loss: 23.6142\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.4645 - val_loss: 23.6217\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.4493 - val_loss: 23.5974\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2683 - val_loss: 23.5496\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1089 - val_loss: 23.5371\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.2776 - val_loss: 23.5162\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.2551 - val_loss: 23.4994\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.1930 - val_loss: 23.5241\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1682 - val_loss: 23.4772\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.0225 - val_loss: 23.4633\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.8367 - val_loss: 23.4674\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.8098 - val_loss: 23.4650\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.5961 - val_loss: 23.4846\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.8071 - val_loss: 23.4708\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.8005 - val_loss: 23.4520\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.9048 - val_loss: 23.4848\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7969 - val_loss: 23.5137\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8798 - val_loss: 23.5188\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8812 - val_loss: 23.4756\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.6565 - val_loss: 23.5281\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7645 - val_loss: 23.5750\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.5445 - val_loss: 23.5907\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.5581 - val_loss: 23.6562\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.6758 - val_loss: 23.7793\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.5147 - val_loss: 23.8386\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 902ms/step - loss: 7.8454 - val_loss: 21.9624\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.7563 - val_loss: 22.1699\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.1939 - val_loss: 22.4649\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.3431 - val_loss: 22.5821\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.6241 - val_loss: 22.8839\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.1693 - val_loss: 23.1172\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.9359 - val_loss: 23.3418\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.9995 - val_loss: 23.6056\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.1749 - val_loss: 23.8905\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.9021 - val_loss: 24.0638\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4940 - val_loss: 24.2227\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 885ms/step - loss: 7.6465 - val_loss: 28.9286\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.1344 - val_loss: 28.9816\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8458 - val_loss: 29.0117\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.5529 - val_loss: 28.9748\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.5375 - val_loss: 28.9883\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.5011 - val_loss: 28.9605\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.5399 - val_loss: 28.9523\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.9642 - val_loss: 28.9612\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.6608 - val_loss: 29.0031\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8905 - val_loss: 28.9748\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.7863 - val_loss: 28.9460\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 206s 1s/step - loss: 14.4310 - val_loss: 4.5388\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.8164 - val_loss: 4.4721\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.1814 - val_loss: 4.4197\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.2373 - val_loss: 4.3716\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.5318 - val_loss: 4.3138\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.0390 - val_loss: 4.2735\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.8149 - val_loss: 4.2329\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.4666 - val_loss: 4.1979\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.1024 - val_loss: 4.1622\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.0997 - val_loss: 4.1252\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.9399 - val_loss: 4.0896\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.3133 - val_loss: 4.0602\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.2217 - val_loss: 4.0366\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.2042 - val_loss: 4.0015\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.0759 - val_loss: 3.9680\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.1216 - val_loss: 3.9465\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.8050 - val_loss: 3.8963\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.3983 - val_loss: 3.8775\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.6244 - val_loss: 3.8531\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.9109 - val_loss: 3.8357\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.1984 - val_loss: 3.8051\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.6123 - val_loss: 3.7760\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.2337 - val_loss: 3.7359\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.4699 - val_loss: 3.7022\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.6374 - val_loss: 3.6649\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.9856 - val_loss: 3.6248\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.9779 - val_loss: 3.5923\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.1033 - val_loss: 3.5738\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.6716 - val_loss: 3.5616\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.7830 - val_loss: 3.5646\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0721 - val_loss: 3.5747\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.3897 - val_loss: 3.5789\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.3765 - val_loss: 3.5869\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.3278 - val_loss: 3.5784\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.1381 - val_loss: 3.6048\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.9413 - val_loss: 3.6400\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1142 - val_loss: 3.6590\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.9523 - val_loss: 3.6815\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.5461 - val_loss: 3.7045\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 13.3910 - val_loss: 5.1371\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.3305 - val_loss: 5.0977\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.0953 - val_loss: 5.0682\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.2707 - val_loss: 5.0441\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.1529 - val_loss: 5.0222\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.6512 - val_loss: 5.0105\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8436 - val_loss: 5.0013\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.6521 - val_loss: 4.9897\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.5571 - val_loss: 4.9806\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.3794 - val_loss: 4.9576\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.8911 - val_loss: 4.9375\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.6591 - val_loss: 4.9262\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.9239 - val_loss: 4.9271\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.2229 - val_loss: 4.9123\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.3293 - val_loss: 4.9092\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.3692 - val_loss: 4.8879\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.1937 - val_loss: 4.8741\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.9867 - val_loss: 4.8812\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.7336 - val_loss: 4.8893\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.1459 - val_loss: 4.9137\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.7916 - val_loss: 4.9369\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.0003 - val_loss: 4.9504\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.3296 - val_loss: 4.9571\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.0152 - val_loss: 4.9943\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.5015 - val_loss: 5.0248\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.8893 - val_loss: 5.0591\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.5766 - val_loss: 5.0740\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 958ms/step - loss: 15.9276 - val_loss: 5.0188\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.1058 - val_loss: 4.9051\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.2785 - val_loss: 4.8394\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.8811 - val_loss: 4.7988\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.4768 - val_loss: 4.7391\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.8079 - val_loss: 4.6777\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.2064 - val_loss: 4.6360\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.4486 - val_loss: 4.5885\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.3432 - val_loss: 4.5553\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.4074 - val_loss: 4.5069\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.6685 - val_loss: 4.4523\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.9352 - val_loss: 4.4354\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.6900 - val_loss: 4.4168\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.9068 - val_loss: 4.3746\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.5353 - val_loss: 4.3476\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4650 - val_loss: 4.3125\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.6692 - val_loss: 4.2891\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.6950 - val_loss: 4.2672\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.2665 - val_loss: 4.2652\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.4886 - val_loss: 4.2808\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.2336 - val_loss: 4.2862\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.1359 - val_loss: 4.2668\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.0536 - val_loss: 4.2513\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.4846 - val_loss: 4.2598\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.5662 - val_loss: 4.2496\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.6165 - val_loss: 4.2500\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2412 - val_loss: 4.2608\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.9528 - val_loss: 4.2739\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.3638 - val_loss: 4.3107\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.0374 - val_loss: 4.3408\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.4028 - val_loss: 4.3787\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0740 - val_loss: 4.3989\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.9416 - val_loss: 4.4295\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.8236 - val_loss: 4.4621\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0990 - val_loss: 4.5113\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 19s 920ms/step - loss: 12.8223 - val_loss: 8.4125\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8856 - val_loss: 8.3910\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.6783 - val_loss: 8.3962\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.7148 - val_loss: 8.3998\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.9573 - val_loss: 8.3386\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.7700 - val_loss: 8.3112\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7710 - val_loss: 8.3089\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.7248 - val_loss: 8.2717\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8980 - val_loss: 8.2317\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.2493 - val_loss: 8.2088\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.3107 - val_loss: 8.1794\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8866 - val_loss: 8.1683\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.4464 - val_loss: 8.1799\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.8409 - val_loss: 8.1950\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.1016 - val_loss: 8.1804\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.8035 - val_loss: 8.1782\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8923 - val_loss: 8.1563\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.6011 - val_loss: 8.1660\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0396 - val_loss: 8.1516\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.9829 - val_loss: 8.1662\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.2054 - val_loss: 8.2094\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.4078 - val_loss: 8.2323\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.8758 - val_loss: 8.1659\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5906 - val_loss: 8.1182\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.7518 - val_loss: 8.1014\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.3959 - val_loss: 8.1079\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.6605 - val_loss: 8.1100\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.1411 - val_loss: 8.1338\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.7851 - val_loss: 8.1878\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.9040 - val_loss: 8.2213\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.1861 - val_loss: 8.2524\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.0607 - val_loss: 8.2698\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.7599 - val_loss: 8.2729\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8215 - val_loss: 8.2852\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.9577 - val_loss: 8.2125\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 962ms/step - loss: 18.7747 - val_loss: 3.0250\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 17.4826 - val_loss: 2.9538\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.6083 - val_loss: 2.9001\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 17.6120 - val_loss: 2.8729\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.4044 - val_loss: 2.8318\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.3862 - val_loss: 2.7798\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 17.8283 - val_loss: 2.7605\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.9900 - val_loss: 2.7492\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.4101 - val_loss: 2.7444\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.0909 - val_loss: 2.7451\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.7790 - val_loss: 2.7229\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.6009 - val_loss: 2.7308\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.8071 - val_loss: 2.7467\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.6972 - val_loss: 2.7518\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.5433 - val_loss: 2.7432\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.9828 - val_loss: 2.7429\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.1981 - val_loss: 2.7644\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 15.2614 - val_loss: 2.7653\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.3112 - val_loss: 2.7879\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.7298 - val_loss: 2.7984\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.8587 - val_loss: 2.7861\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 18.1625 - val_loss: 2.6884\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 18.1475 - val_loss: 2.6930\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.6972 - val_loss: 2.7193\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 18.1306 - val_loss: 2.7578\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.6698 - val_loss: 2.7835\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.7047 - val_loss: 2.7955\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 17.4353 - val_loss: 2.8279\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.3476 - val_loss: 2.8611\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.0809 - val_loss: 2.8929\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.0017 - val_loss: 2.9338\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.1921 - val_loss: 2.9461\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 959ms/step - loss: 18.3899 - val_loss: 1.9439\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 18.4412 - val_loss: 1.9023\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.5925 - val_loss: 1.9071\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.5796 - val_loss: 1.9153\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 18.4705 - val_loss: 1.9117\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.4608 - val_loss: 1.8777\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.8939 - val_loss: 1.8821\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.8359 - val_loss: 1.8722\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.8082 - val_loss: 1.8628\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.5111 - val_loss: 1.8825\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 17.1688 - val_loss: 1.8747\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.0741 - val_loss: 1.8723\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.4508 - val_loss: 1.8699\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.3980 - val_loss: 1.8694\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.5832 - val_loss: 1.8533\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 16.6698 - val_loss: 1.8463\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.3006 - val_loss: 1.8557\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.2428 - val_loss: 1.8534\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.6763 - val_loss: 1.8691\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.9272 - val_loss: 1.8639\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 16.6821 - val_loss: 1.8562\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.5456 - val_loss: 1.8533\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.8349 - val_loss: 1.8724\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.3492 - val_loss: 1.8793\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.4495 - val_loss: 1.8920\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.1616 - val_loss: 1.9060\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 945ms/step - loss: 20.7614 - val_loss: 2.5031\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 21.3361 - val_loss: 2.4764\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.0280 - val_loss: 2.4705\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 20.6772 - val_loss: 2.4739\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.7235 - val_loss: 2.4738\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.1825 - val_loss: 2.4478\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.9146 - val_loss: 2.4606\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 20.8650 - val_loss: 2.4573\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.4679 - val_loss: 2.4569\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.2383 - val_loss: 2.4714\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 18.7768 - val_loss: 2.4622\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 19.0120 - val_loss: 2.4783\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 19.4698 - val_loss: 2.4915\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.6454 - val_loss: 2.4956\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.1263 - val_loss: 2.5075\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.3770 - val_loss: 2.5208\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 985ms/step - loss: 12.1119 - val_loss: 72.1418\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.3047 - val_loss: 72.8668\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.8283 - val_loss: 73.5561\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.7584 - val_loss: 74.2262\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.2598 - val_loss: 74.9786\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.0597 - val_loss: 75.6970\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.6540 - val_loss: 76.2997\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.3573 - val_loss: 76.9183\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.2880 - val_loss: 77.5410\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8434 - val_loss: 78.0307\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.9866 - val_loss: 78.5341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 12.2457 - val_loss: 86.0035\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.8637 - val_loss: 86.1747\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.0413 - val_loss: 86.3551\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.0868 - val_loss: 86.4847\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.1723 - val_loss: 86.7643\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8533 - val_loss: 86.9350\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.3215 - val_loss: 87.0450\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.7052 - val_loss: 87.1293\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.3832 - val_loss: 87.3477\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.5114 - val_loss: 87.5491\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.6674 - val_loss: 87.7192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 981ms/step - loss: 11.4366 - val_loss: 76.3336\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.7699 - val_loss: 76.9899\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.2299 - val_loss: 77.6917\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.2157 - val_loss: 78.2296\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.7739 - val_loss: 78.9484\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.9669 - val_loss: 79.4625\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.5949 - val_loss: 79.9615\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.5862 - val_loss: 80.4484\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1405 - val_loss: 81.0440\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.4313 - val_loss: 81.3894\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.2094 - val_loss: 81.6822\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 161s 1s/step - loss: 13.0380 - val_loss: 85.2726\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.3542 - val_loss: 86.0047\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.4331 - val_loss: 86.6246\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.4208 - val_loss: 87.1464\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.1800 - val_loss: 87.6861\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.9698 - val_loss: 88.0449\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.0856 - val_loss: 88.4053\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.8955 - val_loss: 88.7213\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.9796 - val_loss: 89.1175\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.9278 - val_loss: 89.3515\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.2705 - val_loss: 89.4900\n",
      "2/2 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 944ms/step - loss: 16.7642 - val_loss: 7.1304\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 16.4546 - val_loss: 7.0963\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.9674 - val_loss: 7.0549\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.6095 - val_loss: 6.9647\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.2166 - val_loss: 6.9176\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.6141 - val_loss: 6.8602\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.8404 - val_loss: 6.8382\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8382 - val_loss: 6.8204\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.5237 - val_loss: 6.8023\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.3899 - val_loss: 6.7776\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.5467 - val_loss: 6.7625\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.7471 - val_loss: 6.7674\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8826 - val_loss: 6.7476\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.8014 - val_loss: 6.7346\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.5968 - val_loss: 6.7360\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.3014 - val_loss: 6.7255\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.3749 - val_loss: 6.6719\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.9648 - val_loss: 6.6426\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.4474 - val_loss: 6.6055\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.5950 - val_loss: 6.5665\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.6496 - val_loss: 6.5112\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.0398 - val_loss: 6.4850\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.0455 - val_loss: 6.4271\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.5767 - val_loss: 6.3689\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8865 - val_loss: 6.3046\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3132 - val_loss: 6.2544\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.0294 - val_loss: 6.1851\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.2079 - val_loss: 6.1573\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.9761 - val_loss: 6.0927\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.9628 - val_loss: 6.0650\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.8673 - val_loss: 6.0412\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.5714 - val_loss: 5.9815\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.0740 - val_loss: 5.9213\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.9911 - val_loss: 5.8569\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.0680 - val_loss: 5.7967\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3266 - val_loss: 5.7517\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.4534 - val_loss: 5.7173\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.5782 - val_loss: 5.6883\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.1873 - val_loss: 5.6677\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.9891 - val_loss: 5.6300\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.0003 - val_loss: 5.6177\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.0630 - val_loss: 5.5849\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.1551 - val_loss: 5.5389\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3264 - val_loss: 5.4755\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.5297 - val_loss: 5.4230\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.0612 - val_loss: 5.3419\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3955 - val_loss: 5.2872\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.9299 - val_loss: 5.2479\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.1957 - val_loss: 5.2165\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.1049 - val_loss: 5.1640\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.6093 - val_loss: 5.1195\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.0587 - val_loss: 5.0817\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5203 - val_loss: 5.0103\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6924 - val_loss: 4.9555\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.5757 - val_loss: 4.9027\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.6163 - val_loss: 4.8717\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.8526 - val_loss: 4.8452\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6516 - val_loss: 4.8087\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.5943 - val_loss: 4.7739\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1988 - val_loss: 4.7475\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.8235 - val_loss: 4.7158\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.0468 - val_loss: 4.7092\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.4475 - val_loss: 4.6903\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8898 - val_loss: 4.6670\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.4608 - val_loss: 4.6612\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.6626 - val_loss: 4.6242\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.9955 - val_loss: 4.6072\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.7390 - val_loss: 4.5930\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.5812 - val_loss: 4.5730\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.6600 - val_loss: 4.5595\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9169 - val_loss: 4.5677\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.6470 - val_loss: 4.5766\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.4683 - val_loss: 4.6000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.6203 - val_loss: 4.6156\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.7245 - val_loss: 4.6628\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2400 - val_loss: 4.6700\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.6212 - val_loss: 4.6258\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.0646 - val_loss: 4.6464\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4082 - val_loss: 4.6006\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.9613 - val_loss: 4.5845\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 995ms/step - loss: 16.4676 - val_loss: 7.6414\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.4904 - val_loss: 7.5898\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.3496 - val_loss: 7.5429\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.7944 - val_loss: 7.4786\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.9426 - val_loss: 7.4318\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.8179 - val_loss: 7.3854\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.6840 - val_loss: 7.3722\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.3416 - val_loss: 7.3507\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.5308 - val_loss: 7.3328\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.3219 - val_loss: 7.3103\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.3486 - val_loss: 7.2931\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.7243 - val_loss: 7.2796\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.5511 - val_loss: 7.2580\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.8036 - val_loss: 7.2402\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.8068 - val_loss: 7.2316\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.5966 - val_loss: 7.2130\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.0174 - val_loss: 7.1875\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.4475 - val_loss: 7.1638\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.4101 - val_loss: 7.1402\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.4850 - val_loss: 7.1203\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.0868 - val_loss: 7.0888\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.3681 - val_loss: 7.0744\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.6682 - val_loss: 7.0430\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.9247 - val_loss: 7.0198\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.5093 - val_loss: 6.9974\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.5788 - val_loss: 6.9837\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.4257 - val_loss: 6.9568\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.5794 - val_loss: 6.9489\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.2718 - val_loss: 6.9217\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.2657 - val_loss: 6.9133\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4979 - val_loss: 6.9072\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.8744 - val_loss: 6.8952\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.6340 - val_loss: 6.8743\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.9844 - val_loss: 6.8406\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.4746 - val_loss: 6.8111\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.3343 - val_loss: 6.7943\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.0486 - val_loss: 6.7744\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.8581 - val_loss: 6.7507\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.0280 - val_loss: 6.7321\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.6629 - val_loss: 6.7067\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.3901 - val_loss: 6.6958\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.5246 - val_loss: 6.6750\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.7091 - val_loss: 6.6568\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.1429 - val_loss: 6.6149\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.4844 - val_loss: 6.5765\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.2862 - val_loss: 6.5369\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2446 - val_loss: 6.5032\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0316 - val_loss: 6.4804\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.5058 - val_loss: 6.4677\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.4963 - val_loss: 6.4299\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.3218 - val_loss: 6.3917\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.0661 - val_loss: 6.3544\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6649 - val_loss: 6.2968\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3984 - val_loss: 6.2587\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.3618 - val_loss: 6.2127\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.0116 - val_loss: 6.1903\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8775 - val_loss: 6.1644\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.4338 - val_loss: 6.1488\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.3347 - val_loss: 6.1033\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7567 - val_loss: 6.0689\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.3681 - val_loss: 6.0416\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.4352 - val_loss: 6.0179\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5368 - val_loss: 5.9636\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.7242 - val_loss: 5.8960\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7082 - val_loss: 5.8750\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9904 - val_loss: 5.8474\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.1714 - val_loss: 5.8239\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.4108 - val_loss: 5.7812\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.8027 - val_loss: 5.7604\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9013 - val_loss: 5.7189\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4359 - val_loss: 5.6600\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.3774 - val_loss: 5.5868\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.4193 - val_loss: 5.5409\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.4418 - val_loss: 5.4910\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.4847 - val_loss: 5.4677\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.9366 - val_loss: 5.4434\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.9539 - val_loss: 5.3815\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.7464 - val_loss: 5.3474\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3661 - val_loss: 5.3041\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.7612 - val_loss: 5.2657\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3574 - val_loss: 5.2486\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2510 - val_loss: 5.2276\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2098 - val_loss: 5.1578\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.3352 - val_loss: 5.1230\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.5773 - val_loss: 5.1194\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.6321 - val_loss: 5.0538\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.7098 - val_loss: 5.0051\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.4451 - val_loss: 5.0060\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.9508 - val_loss: 4.9842\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.2691 - val_loss: 4.9865\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.9473 - val_loss: 4.9902\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.7896 - val_loss: 4.9169\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3264 - val_loss: 4.9339\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.2391 - val_loss: 4.9181\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9340 - val_loss: 4.8377\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.0958 - val_loss: 4.8312\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.9793 - val_loss: 4.7884\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.3512 - val_loss: 4.7715\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.6196 - val_loss: 4.7106\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.9667 - val_loss: 4.7172\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.3621 - val_loss: 4.6681\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.8820 - val_loss: 4.6747\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.9838 - val_loss: 4.6324\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.7454 - val_loss: 4.6274\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6421 - val_loss: 4.6106\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.7469 - val_loss: 4.6149\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.8341 - val_loss: 4.5847\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.2420 - val_loss: 4.5850\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1504 - val_loss: 4.5963\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9199 - val_loss: 4.6154\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.1908 - val_loss: 4.6504\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.4129 - val_loss: 4.6692\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.2638 - val_loss: 4.6489\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7885 - val_loss: 4.6773\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.3662 - val_loss: 4.7085\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.7265 - val_loss: 4.6911\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.8919 - val_loss: 4.6605\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 915ms/step - loss: 17.2782 - val_loss: 6.0317\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.5389 - val_loss: 5.9810\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.5419 - val_loss: 5.9369\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.5074 - val_loss: 5.8884\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.0593 - val_loss: 5.8481\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.0378 - val_loss: 5.8019\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.2304 - val_loss: 5.7558\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.8328 - val_loss: 5.7185\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.1334 - val_loss: 5.6918\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.5232 - val_loss: 5.6701\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.7270 - val_loss: 5.6484\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.7409 - val_loss: 5.6374\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.4315 - val_loss: 5.6049\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.0888 - val_loss: 5.5847\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.5319 - val_loss: 5.5764\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.5559 - val_loss: 5.5661\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.0817 - val_loss: 5.5533\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.5568 - val_loss: 5.5374\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.5344 - val_loss: 5.5290\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3252 - val_loss: 5.5149\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.5369 - val_loss: 5.4912\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.0335 - val_loss: 5.4944\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.4778 - val_loss: 5.4797\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.8123 - val_loss: 5.4870\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.2148 - val_loss: 5.4750\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.9994 - val_loss: 5.4732\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.5620 - val_loss: 5.4483\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1359 - val_loss: 5.4609\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.7826 - val_loss: 5.4503\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.4632 - val_loss: 5.4449\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.1092 - val_loss: 5.4479\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.2828 - val_loss: 5.4326\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.9223 - val_loss: 5.4185\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.0043 - val_loss: 5.4002\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.1942 - val_loss: 5.3722\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2902 - val_loss: 5.3687\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.7435 - val_loss: 5.3564\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.0248 - val_loss: 5.3683\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.6341 - val_loss: 5.3660\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1114 - val_loss: 5.3553\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.6840 - val_loss: 5.3414\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.3543 - val_loss: 5.3386\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.4545 - val_loss: 5.3337\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.0246 - val_loss: 5.3232\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.0619 - val_loss: 5.2915\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.7086 - val_loss: 5.2696\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1964 - val_loss: 5.2485\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.2144 - val_loss: 5.2500\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.3800 - val_loss: 5.2539\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.1584 - val_loss: 5.2514\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.3939 - val_loss: 5.2441\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.8473 - val_loss: 5.2435\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.6168 - val_loss: 5.2026\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.9500 - val_loss: 5.2149\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4870 - val_loss: 5.2221\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.7603 - val_loss: 5.2428\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0653 - val_loss: 5.2415\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.7154 - val_loss: 5.2196\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.2227 - val_loss: 5.2002\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3181 - val_loss: 5.1928\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.3273 - val_loss: 5.1881\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2199 - val_loss: 5.2251\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2924 - val_loss: 5.2326\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.8235 - val_loss: 5.1872\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.7067 - val_loss: 5.1812\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8854 - val_loss: 5.1490\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.3710 - val_loss: 5.1562\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.4110 - val_loss: 5.1858\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.2695 - val_loss: 5.2067\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.6075 - val_loss: 5.2148\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.0814 - val_loss: 5.2099\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.3495 - val_loss: 5.1899\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2231 - val_loss: 5.2176\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.6880 - val_loss: 5.2164\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.0789 - val_loss: 5.2447\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2236 - val_loss: 5.2507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 891ms/step - loss: 18.4796 - val_loss: 6.2343\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 19.1520 - val_loss: 6.2587\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.7803 - val_loss: 6.2681\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 17.5889 - val_loss: 6.2744\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 17.3597 - val_loss: 6.2799\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.3431 - val_loss: 6.2834\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.8235 - val_loss: 6.2879\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.9952 - val_loss: 6.2926\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.3876 - val_loss: 6.2965\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.6529 - val_loss: 6.3074\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.5153 - val_loss: 6.3249\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 940ms/step - loss: 21.3815 - val_loss: 5.8672\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 21.9678 - val_loss: 6.0146\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.8503 - val_loss: 6.1312\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.7559 - val_loss: 6.2337\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.5828 - val_loss: 6.3750\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.7766 - val_loss: 6.4935\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.3431 - val_loss: 6.6006\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.3861 - val_loss: 6.7401\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.6895 - val_loss: 6.8640\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.2580 - val_loss: 6.9664\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.8776 - val_loss: 7.0513\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 990ms/step - loss: 23.5236 - val_loss: 7.9604\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 23.6841 - val_loss: 7.9003\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 21.0647 - val_loss: 7.7352\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.6548 - val_loss: 7.5472\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 20.9574 - val_loss: 7.4362\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 21.8829 - val_loss: 7.2996\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 19.6981 - val_loss: 7.1856\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 20.4151 - val_loss: 7.1190\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 19.9394 - val_loss: 7.0635\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.7097 - val_loss: 7.0230\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.2780 - val_loss: 6.9424\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.0962 - val_loss: 6.8642\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.3099 - val_loss: 6.8031\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 18.4564 - val_loss: 6.7501\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.9991 - val_loss: 6.7563\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.5708 - val_loss: 6.7035\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.4271 - val_loss: 6.6836\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.6655 - val_loss: 6.7052\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.5002 - val_loss: 6.6715\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.3708 - val_loss: 6.6735\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 17.2343 - val_loss: 6.6759\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.5354 - val_loss: 6.7214\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.8899 - val_loss: 6.7308\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.4426 - val_loss: 6.7513\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 16.1975 - val_loss: 6.7872\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.3886 - val_loss: 6.7937\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.5556 - val_loss: 6.7996\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.8882 - val_loss: 6.8252\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.0897 - val_loss: 6.8578\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 921ms/step - loss: 22.7663 - val_loss: 7.6201\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 23.0917 - val_loss: 7.5941\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 21.0487 - val_loss: 7.5023\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 18.7159 - val_loss: 7.4795\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.8637 - val_loss: 7.4782\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 20.7324 - val_loss: 7.4387\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.6123 - val_loss: 7.4095\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.7684 - val_loss: 7.4656\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 18.6983 - val_loss: 7.5475\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 19.4704 - val_loss: 7.6157\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.8559 - val_loss: 7.6666\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 18.5056 - val_loss: 7.6915\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.8980 - val_loss: 7.7398\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.4554 - val_loss: 7.7909\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.8546 - val_loss: 7.9052\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.0392 - val_loss: 7.9658\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.4940 - val_loss: 8.0085\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 20s 893ms/step - loss: 18.5455 - val_loss: 6.1912\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.2786 - val_loss: 6.2524\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.0256 - val_loss: 6.2976\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.8860 - val_loss: 6.3215\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.6782 - val_loss: 6.3607\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 18.1220 - val_loss: 6.3820\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.6907 - val_loss: 6.4100\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.6243 - val_loss: 6.4589\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 17.6135 - val_loss: 6.5095\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.4161 - val_loss: 6.5333\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 17.3642 - val_loss: 6.5613\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 907ms/step - loss: 15.9293 - val_loss: 2.6307\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.3629 - val_loss: 2.7257\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.3022 - val_loss: 2.8439\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.5256 - val_loss: 2.9159\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8490 - val_loss: 2.9511\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.8216 - val_loss: 3.0281\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.3091 - val_loss: 3.1005\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7135 - val_loss: 3.1972\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.7049 - val_loss: 3.2721\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.5134 - val_loss: 3.3562\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.4978 - val_loss: 3.4378\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 977ms/step - loss: 16.6678 - val_loss: 1.8168\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.9649 - val_loss: 1.8604\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.6783 - val_loss: 1.9155\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.6566 - val_loss: 1.9566\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.7640 - val_loss: 1.9821\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.5457 - val_loss: 2.0287\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.4960 - val_loss: 2.0719\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.3601 - val_loss: 2.1226\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8493 - val_loss: 2.1525\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.8027 - val_loss: 2.1869\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.2467 - val_loss: 2.2273\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 935ms/step - loss: 16.1268 - val_loss: 1.8095\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.0349 - val_loss: 1.8576\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.4868 - val_loss: 1.9351\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.1971 - val_loss: 1.9803\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.9096 - val_loss: 2.0031\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.3454 - val_loss: 2.0735\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.0655 - val_loss: 2.1356\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.3914 - val_loss: 2.1859\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.3367 - val_loss: 2.2184\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.7519 - val_loss: 2.2624\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.0084 - val_loss: 2.3087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 943ms/step - loss: 14.1688 - val_loss: 2.3472\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8192 - val_loss: 2.2989\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.6135 - val_loss: 2.2934\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.9020 - val_loss: 2.2472\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.1940 - val_loss: 2.1868\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.3966 - val_loss: 2.1414\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.2397 - val_loss: 2.0980\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.1067 - val_loss: 2.0545\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.7537 - val_loss: 2.0016\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.9081 - val_loss: 1.9661\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.4559 - val_loss: 1.9294\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.7993 - val_loss: 1.9146\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.0050 - val_loss: 1.8837\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.2981 - val_loss: 1.8584\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.6864 - val_loss: 1.8270\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.5145 - val_loss: 1.8116\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 10.5377 - val_loss: 1.7985\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.0748 - val_loss: 1.7737\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.3765 - val_loss: 1.7691\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.0172 - val_loss: 1.7482\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.1547 - val_loss: 1.7463\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.3904 - val_loss: 1.7305\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.1946 - val_loss: 1.7247\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.0349 - val_loss: 1.7115\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.4158 - val_loss: 1.6840\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.4751 - val_loss: 1.6725\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.4861 - val_loss: 1.6673\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.8261 - val_loss: 1.6648\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.3333 - val_loss: 1.6474\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.5808 - val_loss: 1.6331\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.4656 - val_loss: 1.6165\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.1267 - val_loss: 1.6159\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.1353 - val_loss: 1.6100\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.6493 - val_loss: 1.5953\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0263 - val_loss: 1.5878\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2936 - val_loss: 1.5785\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.6441 - val_loss: 1.5646\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.4729 - val_loss: 1.5510\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.9203 - val_loss: 1.5355\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.8364 - val_loss: 1.5222\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.2563 - val_loss: 1.5056\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.0683 - val_loss: 1.4942\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.0094 - val_loss: 1.4867\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.9241 - val_loss: 1.4770\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.3680 - val_loss: 1.4620\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.6062 - val_loss: 1.4572\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.4159 - val_loss: 1.4562\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5069 - val_loss: 1.4437\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.4686 - val_loss: 1.4357\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.2960 - val_loss: 1.4381\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.6237 - val_loss: 1.4300\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.8154 - val_loss: 1.4207\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.5327 - val_loss: 1.4072\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.0782 - val_loss: 1.4013\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.5073 - val_loss: 1.3868\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.4821 - val_loss: 1.3801\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.5245 - val_loss: 1.3683\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.2143 - val_loss: 1.3677\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.2707 - val_loss: 1.3683\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.9126 - val_loss: 1.3725\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.0857 - val_loss: 1.3666\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.0937 - val_loss: 1.3658\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.6635 - val_loss: 1.3751\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.5479 - val_loss: 1.3741\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.0285 - val_loss: 1.3692\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6278 - val_loss: 1.3465\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.8436 - val_loss: 1.3356\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.9638 - val_loss: 1.3255\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.3228 - val_loss: 1.3167\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.2567 - val_loss: 1.3175\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.0484 - val_loss: 1.3234\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.1118 - val_loss: 1.3162\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.1305 - val_loss: 1.3051\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.7341 - val_loss: 1.3016\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.2368 - val_loss: 1.3118\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.5739 - val_loss: 1.3058\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3610 - val_loss: 1.2941\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.4978 - val_loss: 1.2894\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.0324 - val_loss: 1.2961\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.2838 - val_loss: 1.2921\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.8581 - val_loss: 1.2954\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.1795 - val_loss: 1.2858\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.7180 - val_loss: 1.2754\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.4879 - val_loss: 1.2729\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.9984 - val_loss: 1.2724\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.0538 - val_loss: 1.2769\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3569 - val_loss: 1.2720\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.4723 - val_loss: 1.2720\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7827 - val_loss: 1.2483\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.0748 - val_loss: 1.2475\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.8967 - val_loss: 1.2398\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4000 - val_loss: 1.2294\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.9959 - val_loss: 1.2195\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.0557 - val_loss: 1.2285\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.8963 - val_loss: 1.2252\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.8908 - val_loss: 1.2303\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.6291 - val_loss: 1.2179\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.2697 - val_loss: 1.2123\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.1525 - val_loss: 1.2032\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.1190 - val_loss: 1.2077\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.0726 - val_loss: 1.2028\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.6500 - val_loss: 1.1872\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.0494 - val_loss: 1.1705\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.2470 - val_loss: 1.1594\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9038 - val_loss: 1.1783\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.0880 - val_loss: 1.1972\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5339 - val_loss: 1.1956\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.9079 - val_loss: 1.1912\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.6911 - val_loss: 1.1658\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7249 - val_loss: 1.1538\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.5143 - val_loss: 1.1402\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.9689 - val_loss: 1.1361\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.4451 - val_loss: 1.1338\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.8796 - val_loss: 1.1355\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7772 - val_loss: 1.1494\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.2966 - val_loss: 1.1571\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.0946 - val_loss: 1.1447\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7932 - val_loss: 1.1476\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.2326 - val_loss: 1.1385\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.6549 - val_loss: 1.1282\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.4891 - val_loss: 1.1455\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.4900 - val_loss: 1.1469\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.7905 - val_loss: 1.1271\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8057 - val_loss: 1.1047\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.2202 - val_loss: 1.0974\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.7377 - val_loss: 1.0995\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.7113 - val_loss: 1.0773\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.7733 - val_loss: 1.0743\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1380 - val_loss: 1.0705\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 5.6130 - val_loss: 1.0724\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4583 - val_loss: 1.0648\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.3382 - val_loss: 1.0638\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.7508 - val_loss: 1.0657\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.2515 - val_loss: 1.0657\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.1383 - val_loss: 1.0576\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.8181 - val_loss: 1.0604\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.0660 - val_loss: 1.0596\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.7408 - val_loss: 1.0640\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.7701 - val_loss: 1.0618\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.8719 - val_loss: 1.0646\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.6594 - val_loss: 1.0499\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.7583 - val_loss: 1.0532\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.9376 - val_loss: 1.0482\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.0238 - val_loss: 1.0367\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.6540 - val_loss: 1.0304\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.3501 - val_loss: 1.0294\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.4785 - val_loss: 1.0406\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.0368 - val_loss: 1.0412\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.7227 - val_loss: 1.0473\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.3435 - val_loss: 1.0406\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.9944 - val_loss: 1.0307\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.6876 - val_loss: 1.0057\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.1919 - val_loss: 0.9827\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.3786 - val_loss: 0.9694\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.3389 - val_loss: 0.9530\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.4754 - val_loss: 0.9392\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.9871 - val_loss: 0.9492\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.0586 - val_loss: 0.9435\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.7878 - val_loss: 0.9517\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.2235 - val_loss: 0.9486\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.9590 - val_loss: 0.9500\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.9073 - val_loss: 0.9624\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.2126 - val_loss: 0.9685\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.1598 - val_loss: 0.9706\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.0392 - val_loss: 0.9761\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.0786 - val_loss: 0.9921\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 922ms/step - loss: 18.2055 - val_loss: 7.3833\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 18.6775 - val_loss: 7.2933\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.0069 - val_loss: 7.2360\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.5133 - val_loss: 7.2191\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.8925 - val_loss: 7.2231\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.6539 - val_loss: 7.1842\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.3582 - val_loss: 7.1852\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.3370 - val_loss: 7.1744\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.2276 - val_loss: 7.1834\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.5473 - val_loss: 7.2326\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.3099 - val_loss: 7.2462\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 16.4582 - val_loss: 7.2533\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.5649 - val_loss: 7.2588\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.9364 - val_loss: 7.2594\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.8559 - val_loss: 7.3084\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.3822 - val_loss: 7.3376\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.4664 - val_loss: 7.3471\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.6359 - val_loss: 7.3585\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 18.7431 - val_loss: 8.9260\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 18.6517 - val_loss: 8.6057\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.7422 - val_loss: 8.3074\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.1107 - val_loss: 8.0212\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.9967 - val_loss: 7.7404\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.4307 - val_loss: 7.5302\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.6898 - val_loss: 7.3422\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.5581 - val_loss: 7.1416\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.5697 - val_loss: 6.9474\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.0453 - val_loss: 6.8144\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.4974 - val_loss: 6.7016\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.1734 - val_loss: 6.5966\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.9484 - val_loss: 6.5400\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.2407 - val_loss: 6.4894\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.4875 - val_loss: 6.4598\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.2285 - val_loss: 6.3743\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 14.6815 - val_loss: 6.2319\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.6768 - val_loss: 6.1732\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.2290 - val_loss: 6.1245\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8336 - val_loss: 6.0889\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.6018 - val_loss: 6.0628\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.9558 - val_loss: 6.0485\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.5868 - val_loss: 6.0586\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.2918 - val_loss: 6.0527\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.9446 - val_loss: 6.0832\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.3468 - val_loss: 6.1010\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.1550 - val_loss: 6.1344\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.3680 - val_loss: 6.1870\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.8812 - val_loss: 6.2280\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.8111 - val_loss: 6.2844\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3023 - val_loss: 6.3462\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.0104 - val_loss: 6.4032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 902ms/step - loss: 18.3005 - val_loss: 7.9602\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 17.8274 - val_loss: 7.8062\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.7156 - val_loss: 7.6873\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.1969 - val_loss: 7.5831\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.2698 - val_loss: 7.4323\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.9875 - val_loss: 7.3289\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 16.7123 - val_loss: 7.2619\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 16.2195 - val_loss: 7.1812\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.9460 - val_loss: 7.1029\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 15.6013 - val_loss: 7.0403\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.8968 - val_loss: 6.9976\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.9005 - val_loss: 6.9173\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.4815 - val_loss: 6.8797\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.8878 - val_loss: 6.8530\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8839 - val_loss: 6.8514\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.4831 - val_loss: 6.8595\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.9491 - val_loss: 6.8548\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8883 - val_loss: 6.8857\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.8141 - val_loss: 6.9192\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.0765 - val_loss: 6.9621\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8326 - val_loss: 6.9774\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.0137 - val_loss: 6.9619\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.6157 - val_loss: 7.0063\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.2613 - val_loss: 7.0215\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.1460 - val_loss: 7.0608\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 857ms/step - loss: 17.9795 - val_loss: 5.2730\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 17.6203 - val_loss: 4.9348\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14.8058 - val_loss: 4.6642\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.5856 - val_loss: 4.4264\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 16.2751 - val_loss: 4.2088\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 13.9230 - val_loss: 4.0174\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 15.3893 - val_loss: 3.8369\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.7007 - val_loss: 3.6646\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 15.1297 - val_loss: 3.5074\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.1539 - val_loss: 3.4039\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.9244 - val_loss: 3.2992\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.9884 - val_loss: 3.1925\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.6649 - val_loss: 3.1092\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 14.3004 - val_loss: 3.0314\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.9970 - val_loss: 2.9642\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 13.9083 - val_loss: 2.8933\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 14.0116 - val_loss: 2.8283\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.5144 - val_loss: 2.7818\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.9928 - val_loss: 2.7461\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.2055 - val_loss: 2.7211\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.4326 - val_loss: 2.7067\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.7791 - val_loss: 2.7033\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.0528 - val_loss: 2.6989\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.9178 - val_loss: 2.6880\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.9692 - val_loss: 2.6850\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.0692 - val_loss: 2.6948\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.2035 - val_loss: 2.7151\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.6417 - val_loss: 2.7383\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.1138 - val_loss: 2.7734\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 12.2104 - val_loss: 2.8145\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.9684 - val_loss: 2.8607\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 12.7445 - val_loss: 2.9073\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.2263 - val_loss: 2.9579\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5039 - val_loss: 3.0038\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3154 - val_loss: 3.0545\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 905ms/step - loss: 14.5681 - val_loss: 6.6218\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.8971 - val_loss: 6.4989\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.1538 - val_loss: 6.3890\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 14.5317 - val_loss: 6.3366\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.9948 - val_loss: 6.2743\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 12.4950 - val_loss: 6.2127\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.1918 - val_loss: 6.1579\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.9724 - val_loss: 6.0887\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 12.4514 - val_loss: 6.0221\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7929 - val_loss: 5.9684\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.3540 - val_loss: 5.9378\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.5923 - val_loss: 5.8936\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.2572 - val_loss: 5.8329\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 11.6712 - val_loss: 5.7927\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.6700 - val_loss: 5.7711\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.4461 - val_loss: 5.7330\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 10.9758 - val_loss: 5.7024\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5592 - val_loss: 5.6516\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.6839 - val_loss: 5.6218\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 11.1504 - val_loss: 5.6028\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.3520 - val_loss: 5.5848\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.0021 - val_loss: 5.5641\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.5881 - val_loss: 5.5236\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.3639 - val_loss: 5.4950\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.2490 - val_loss: 5.4573\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.0275 - val_loss: 5.4388\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.8687 - val_loss: 5.4377\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.0077 - val_loss: 5.4237\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.2194 - val_loss: 5.3959\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.2578 - val_loss: 5.3443\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.6177 - val_loss: 5.3177\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.5479 - val_loss: 5.2971\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.7860 - val_loss: 5.2870\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.1229 - val_loss: 5.2831\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.6329 - val_loss: 5.2753\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.4077 - val_loss: 5.2615\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.9455 - val_loss: 5.2616\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.3213 - val_loss: 5.2602\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.6465 - val_loss: 5.2390\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.2202 - val_loss: 5.2220\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.3802 - val_loss: 5.2031\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.3750 - val_loss: 5.1872\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.2728 - val_loss: 5.1772\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.0463 - val_loss: 5.1869\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.3163 - val_loss: 5.1837\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.5612 - val_loss: 5.2308\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7757 - val_loss: 5.2684\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.6410 - val_loss: 5.3122\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.3146 - val_loss: 5.3215\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7627 - val_loss: 5.3157\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.8414 - val_loss: 5.3303\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.4261 - val_loss: 5.3210\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.4143 - val_loss: 5.3192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 12.9174 - val_loss: 4.4572\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3575 - val_loss: 4.4371\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.5666 - val_loss: 4.4012\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8641 - val_loss: 4.3857\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.0072 - val_loss: 4.3686\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7768 - val_loss: 4.3630\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.9090 - val_loss: 4.3561\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.5997 - val_loss: 4.3386\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.3085 - val_loss: 4.3044\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.5562 - val_loss: 4.2787\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.6498 - val_loss: 4.2667\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.3313 - val_loss: 4.2513\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.8831 - val_loss: 4.2341\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.4656 - val_loss: 4.2164\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.2753 - val_loss: 4.2095\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.8308 - val_loss: 4.2019\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.0439 - val_loss: 4.1931\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.7033 - val_loss: 4.1871\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.5882 - val_loss: 4.1733\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5039 - val_loss: 4.1674\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.3270 - val_loss: 4.1620\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.2870 - val_loss: 4.1641\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8775 - val_loss: 4.1603\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.8373 - val_loss: 4.1604\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.9956 - val_loss: 4.1609\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.1013 - val_loss: 4.1618\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.9923 - val_loss: 4.1630\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.7807 - val_loss: 4.1671\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.9513 - val_loss: 4.1670\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.5766 - val_loss: 4.1656\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.2063 - val_loss: 4.1679\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5744 - val_loss: 4.1771\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5495 - val_loss: 4.1885\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 32s 938ms/step - loss: 15.1856 - val_loss: 4.8939\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 14.0636 - val_loss: 4.8105\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 14.9248 - val_loss: 4.7349\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 14.2578 - val_loss: 4.6853\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 13.1596 - val_loss: 4.6566\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.7509 - val_loss: 4.6214\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 13.2679 - val_loss: 4.6039\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 13.2382 - val_loss: 4.6043\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 12.5233 - val_loss: 4.6202\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.1574 - val_loss: 4.6332\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.5748 - val_loss: 4.6512\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.5495 - val_loss: 4.6682\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7194 - val_loss: 4.6805\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.8360 - val_loss: 4.7059\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7720 - val_loss: 4.7380\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.6922 - val_loss: 4.7677\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.3544 - val_loss: 4.7991\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 931ms/step - loss: 10.5550 - val_loss: 4.6712\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.8422 - val_loss: 4.6618\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.7860 - val_loss: 4.6526\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 10.8922 - val_loss: 4.6440\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 10.0354 - val_loss: 4.6515\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.3407 - val_loss: 4.6899\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.5775 - val_loss: 4.7300\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 10.2669 - val_loss: 4.7670\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.9385 - val_loss: 4.7641\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.4143 - val_loss: 4.7721\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.3303 - val_loss: 4.8006\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.9632 - val_loss: 4.8528\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.4657 - val_loss: 4.9190\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.3693 - val_loss: 4.9446\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 955ms/step - loss: 11.1484 - val_loss: 87.5314\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.5233 - val_loss: 87.8755\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 10.5610 - val_loss: 88.3071\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.0844 - val_loss: 88.5684\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.7359 - val_loss: 88.5839\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.4672 - val_loss: 89.0179\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.0546 - val_loss: 89.1951\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.2015 - val_loss: 89.4607\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 9.4233 - val_loss: 89.4011\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7957 - val_loss: 89.6350\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.2388 - val_loss: 89.9569\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 9.9768 - val_loss: 85.0524\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3703 - val_loss: 85.7323\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.0239 - val_loss: 86.3075\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.7875 - val_loss: 86.8057\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5573 - val_loss: 87.2397\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4868 - val_loss: 87.8482\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.9641 - val_loss: 88.3129\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.9051 - val_loss: 88.7359\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.8136 - val_loss: 89.0539\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.8559 - val_loss: 89.4758\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.5146 - val_loss: 89.8623\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 995ms/step - loss: 9.9201 - val_loss: 85.7356\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8958 - val_loss: 87.7718\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.7335 - val_loss: 89.5131\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.1631 - val_loss: 91.0978\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.3228 - val_loss: 92.2198\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.9875 - val_loss: 93.7262\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.0472 - val_loss: 94.8155\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.0289 - val_loss: 95.7692\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.0238 - val_loss: 96.3037\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.7202 - val_loss: 96.9560\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.7218 - val_loss: 97.4009\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 972ms/step - loss: 9.9647 - val_loss: 69.9484\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7275 - val_loss: 70.0582\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.4365 - val_loss: 70.3064\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.5573 - val_loss: 70.5579\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.8648 - val_loss: 70.7063\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.0104 - val_loss: 70.8581\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.1662 - val_loss: 71.0277\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 8.2157 - val_loss: 71.1447\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.4071 - val_loss: 71.2555\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.9979 - val_loss: 71.4398\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.8661 - val_loss: 71.5661\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 13.2762 - val_loss: 20.9978\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.9660 - val_loss: 20.7326\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.3820 - val_loss: 20.4116\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.4031 - val_loss: 20.1908\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 13.0838 - val_loss: 20.0030\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.4735 - val_loss: 19.8016\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.7345 - val_loss: 19.6990\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.2200 - val_loss: 19.5691\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.4866 - val_loss: 19.3196\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.7587 - val_loss: 19.0718\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 11.5903 - val_loss: 18.8382\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.6142 - val_loss: 18.7217\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.4422 - val_loss: 18.4365\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 11.6646 - val_loss: 18.2056\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.6631 - val_loss: 18.0692\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.3091 - val_loss: 17.8660\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.1380 - val_loss: 17.6679\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.3303 - val_loss: 17.4984\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.4385 - val_loss: 17.2111\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.3665 - val_loss: 17.0659\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.6558 - val_loss: 16.9477\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.9453 - val_loss: 16.7318\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.1625 - val_loss: 16.5282\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.6383 - val_loss: 16.3474\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.1475 - val_loss: 16.0983\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.7100 - val_loss: 15.9622\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.4151 - val_loss: 15.7161\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0133 - val_loss: 15.5940\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.4707 - val_loss: 15.3094\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.1596 - val_loss: 15.1454\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.9721 - val_loss: 15.0271\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.6047 - val_loss: 14.8239\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.3240 - val_loss: 14.6809\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3809 - val_loss: 14.5512\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.6935 - val_loss: 14.4955\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.7853 - val_loss: 14.4976\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.6120 - val_loss: 14.4344\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.6707 - val_loss: 14.3271\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.8914 - val_loss: 14.1775\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.8559 - val_loss: 14.0100\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.4556 - val_loss: 13.8973\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.3553 - val_loss: 13.8468\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 10.3114 - val_loss: 13.7832\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.6678 - val_loss: 13.6711\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.4949 - val_loss: 13.6666\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.5659 - val_loss: 13.6200\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.7868 - val_loss: 13.5786\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.3705 - val_loss: 13.5650\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.3883 - val_loss: 13.4907\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.9269 - val_loss: 13.3203\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.1292 - val_loss: 13.2564\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.8411 - val_loss: 13.1819\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7746 - val_loss: 13.1091\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8452 - val_loss: 12.9071\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7437 - val_loss: 12.7560\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2037 - val_loss: 12.6398\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.5254 - val_loss: 12.6620\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.1376 - val_loss: 12.6786\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.6565 - val_loss: 12.6366\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.6168 - val_loss: 12.5054\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.7115 - val_loss: 12.4369\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.8113 - val_loss: 12.3619\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8529 - val_loss: 12.3235\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8171 - val_loss: 12.2960\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5796 - val_loss: 12.1943\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.1563 - val_loss: 12.1178\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8807 - val_loss: 12.0728\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.7338 - val_loss: 12.0485\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8490 - val_loss: 12.0075\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.2430 - val_loss: 11.8913\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.2127 - val_loss: 11.8487\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.9496 - val_loss: 11.8289\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.9705 - val_loss: 11.8679\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8155 - val_loss: 11.8558\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.0638 - val_loss: 11.7546\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.3395 - val_loss: 11.7338\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5030 - val_loss: 11.6846\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5572 - val_loss: 11.5798\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5665 - val_loss: 11.5082\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7255 - val_loss: 11.4748\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.4871 - val_loss: 11.4427\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9309 - val_loss: 11.4013\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.5262 - val_loss: 11.3427\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.3847 - val_loss: 11.1807\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.0318 - val_loss: 11.1311\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6594 - val_loss: 11.0390\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.9106 - val_loss: 11.0102\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.3830 - val_loss: 10.9199\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.7349 - val_loss: 10.8824\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.5796 - val_loss: 10.7834\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.8364 - val_loss: 10.6877\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.3678 - val_loss: 10.5962\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.4451 - val_loss: 10.4880\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4614 - val_loss: 10.4052\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.1540 - val_loss: 10.3755\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.8336 - val_loss: 10.2183\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.9159 - val_loss: 10.2589\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.0919 - val_loss: 10.1670\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.3304 - val_loss: 10.2236\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.9878 - val_loss: 10.2232\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9960 - val_loss: 10.1727\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6414 - val_loss: 10.1316\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.0999 - val_loss: 10.0661\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.0864 - val_loss: 9.9752\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.0897 - val_loss: 9.9324\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1873 - val_loss: 9.9788\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9982 - val_loss: 9.9573\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.5997 - val_loss: 9.9204\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.7287 - val_loss: 9.9126\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.4646 - val_loss: 9.8789\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.8392 - val_loss: 9.9341\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.7905 - val_loss: 9.9814\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.2269 - val_loss: 9.9542\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7290 - val_loss: 9.8415\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.4606 - val_loss: 9.8051\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.0433 - val_loss: 9.7727\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2033 - val_loss: 9.7707\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 8.5119 - val_loss: 9.6786\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.0078 - val_loss: 9.7293\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.3135 - val_loss: 9.6347\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.3395 - val_loss: 9.5964\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2333 - val_loss: 9.5387\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5915 - val_loss: 9.3546\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.8042 - val_loss: 9.3310\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.1864 - val_loss: 9.2215\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1891 - val_loss: 9.0784\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6951 - val_loss: 9.1097\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9145 - val_loss: 9.0490\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.6131 - val_loss: 9.0565\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5272 - val_loss: 9.0202\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.3203 - val_loss: 9.0435\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.8509 - val_loss: 8.9074\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2798 - val_loss: 8.8152\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1556 - val_loss: 8.8729\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.5261 - val_loss: 8.8883\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.2162 - val_loss: 8.7534\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.9274 - val_loss: 8.7466\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.0650 - val_loss: 8.7399\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3082 - val_loss: 8.7055\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8807 - val_loss: 8.7037\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.3183 - val_loss: 8.7042\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.1655 - val_loss: 8.7292\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.2285 - val_loss: 8.7889\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.6337 - val_loss: 8.8448\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.8397 - val_loss: 8.7798\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.7689 - val_loss: 8.7793\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.4526 - val_loss: 8.8067\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.6701 - val_loss: 8.8327\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4187 - val_loss: 8.7422\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2187 - val_loss: 8.6735\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.2275 - val_loss: 8.7051\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.2629 - val_loss: 8.6684\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.3763 - val_loss: 8.7220\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.8839 - val_loss: 8.7070\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7811 - val_loss: 8.7403\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.5960 - val_loss: 8.7287\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.7871 - val_loss: 8.6164\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.5483 - val_loss: 8.5421\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.4526 - val_loss: 8.3819\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.2714 - val_loss: 8.3020\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 7.2317 - val_loss: 8.2600\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0502 - val_loss: 8.2126\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.8195 - val_loss: 8.2659\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3543 - val_loss: 8.3792\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.4812 - val_loss: 8.3090\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.0502 - val_loss: 8.2157\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.1792 - val_loss: 8.1227\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3543 - val_loss: 8.1473\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.5654 - val_loss: 8.2714\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7082 - val_loss: 8.3167\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.4082 - val_loss: 8.3923\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4004 - val_loss: 8.2539\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.4920 - val_loss: 8.1664\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.8382 - val_loss: 8.0484\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0045 - val_loss: 8.0625\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9808 - val_loss: 8.0621\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.8217 - val_loss: 8.0170\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.6490 - val_loss: 7.9334\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9208 - val_loss: 7.8193\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4952 - val_loss: 7.8089\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0831 - val_loss: 7.7877\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.3364 - val_loss: 7.8736\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9549 - val_loss: 7.9617\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6124 - val_loss: 7.9510\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2863 - val_loss: 7.9394\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.8433 - val_loss: 7.9970\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.5727 - val_loss: 8.0699\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.2939 - val_loss: 8.0066\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.4616 - val_loss: 7.9658\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.6122 - val_loss: 7.8553\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.3284 - val_loss: 7.9900\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 12.2837 - val_loss: 16.6526\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.8075 - val_loss: 16.4399\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.2358 - val_loss: 16.1115\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8764 - val_loss: 15.8699\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.5409 - val_loss: 15.7496\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.7033 - val_loss: 15.5756\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.4492 - val_loss: 15.4607\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 12.1775 - val_loss: 15.3455\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.6407 - val_loss: 15.1670\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.6292 - val_loss: 14.9733\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.1092 - val_loss: 14.8404\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.8553 - val_loss: 14.7862\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.0865 - val_loss: 14.6734\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 10.7745 - val_loss: 14.5998\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.4391 - val_loss: 14.5802\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.0057 - val_loss: 14.4636\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.0837 - val_loss: 14.3902\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.7430 - val_loss: 14.3657\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.7063 - val_loss: 14.2578\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8183 - val_loss: 14.2653\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.4140 - val_loss: 14.2639\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.1072 - val_loss: 14.1261\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.5904 - val_loss: 14.0777\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.8333 - val_loss: 14.0467\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.5216 - val_loss: 13.9537\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.9572 - val_loss: 13.9568\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.8944 - val_loss: 13.8843\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.8742 - val_loss: 13.8997\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.2079 - val_loss: 13.7949\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.6243 - val_loss: 13.7696\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.1125 - val_loss: 13.7568\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.5549 - val_loss: 13.6487\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.5809 - val_loss: 13.5291\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.9311 - val_loss: 13.3959\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.9812 - val_loss: 13.3453\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.7609 - val_loss: 13.3322\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.8656 - val_loss: 13.2936\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.9017 - val_loss: 13.1798\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.8242 - val_loss: 13.0473\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.7795 - val_loss: 12.9544\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.5660 - val_loss: 12.9006\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.6788 - val_loss: 12.8801\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3240 - val_loss: 12.8981\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.5476 - val_loss: 12.8670\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3130 - val_loss: 12.9132\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.7596 - val_loss: 12.8972\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2625 - val_loss: 12.8703\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.1149 - val_loss: 12.8697\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.7195 - val_loss: 12.8355\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.4793 - val_loss: 12.7115\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.2957 - val_loss: 12.6288\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.1117 - val_loss: 12.5661\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.6447 - val_loss: 12.5091\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.4217 - val_loss: 12.3994\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.8697 - val_loss: 12.3232\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2920 - val_loss: 12.2332\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.7244 - val_loss: 12.2776\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7669 - val_loss: 12.2405\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.9209 - val_loss: 12.1384\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.7150 - val_loss: 11.9750\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.3506 - val_loss: 11.8881\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1386 - val_loss: 11.8101\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5405 - val_loss: 11.7831\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.9904 - val_loss: 11.7520\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.1680 - val_loss: 11.6556\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.0622 - val_loss: 11.6017\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.9547 - val_loss: 11.5511\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.5512 - val_loss: 11.5104\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.1732 - val_loss: 11.4375\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.3284 - val_loss: 11.3034\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.9607 - val_loss: 11.2709\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.1820 - val_loss: 11.2715\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.0844 - val_loss: 11.3355\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.6103 - val_loss: 11.2787\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.3843 - val_loss: 11.1243\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.5811 - val_loss: 11.0635\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7346 - val_loss: 11.0703\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.1401 - val_loss: 11.0291\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.3167 - val_loss: 10.9264\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.0502 - val_loss: 10.8224\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7162 - val_loss: 10.7560\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.8905 - val_loss: 10.7043\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.1508 - val_loss: 10.6494\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2183 - val_loss: 10.5915\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.0206 - val_loss: 10.5735\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.2160 - val_loss: 10.5106\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.0720 - val_loss: 10.5432\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.2822 - val_loss: 10.5176\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.9968 - val_loss: 10.4944\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.2844 - val_loss: 10.3431\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.8035 - val_loss: 10.2588\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7190 - val_loss: 10.2338\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.3015 - val_loss: 10.1768\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.8604 - val_loss: 10.0605\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.9486 - val_loss: 9.9723\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.5279 - val_loss: 9.8464\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.3403 - val_loss: 9.9869\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.2626 - val_loss: 9.9399\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.4853 - val_loss: 10.1230\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9039 - val_loss: 10.1806\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.2721 - val_loss: 10.1426\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7983 - val_loss: 10.1273\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.2928 - val_loss: 9.9615\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.0169 - val_loss: 9.6229\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.1418 - val_loss: 9.5041\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.1245 - val_loss: 9.5031\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3398 - val_loss: 9.4065\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.3042 - val_loss: 9.3691\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.7569 - val_loss: 9.3765\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3382 - val_loss: 9.3317\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.4920 - val_loss: 9.3686\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4154 - val_loss: 9.3997\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.9364 - val_loss: 9.3642\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.6687 - val_loss: 9.3506\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5626 - val_loss: 9.3532\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3457 - val_loss: 9.3779\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.0804 - val_loss: 9.3834\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.5411 - val_loss: 9.3364\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.8312 - val_loss: 9.3465\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.6532 - val_loss: 9.2182\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.8968 - val_loss: 9.2102\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9000 - val_loss: 9.1742\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.5998 - val_loss: 9.0501\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1701 - val_loss: 8.9955\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.0503 - val_loss: 8.9143\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.3765 - val_loss: 8.9048\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.0821 - val_loss: 8.9383\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2241 - val_loss: 8.9276\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.8459 - val_loss: 8.9444\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2551 - val_loss: 8.9589\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.4959 - val_loss: 8.9900\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.1187 - val_loss: 8.9357\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3834 - val_loss: 8.8555\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.0321 - val_loss: 8.8620\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.2569 - val_loss: 8.8670\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.1596 - val_loss: 8.8697\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.4887 - val_loss: 8.9067\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3865 - val_loss: 8.8551\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3359 - val_loss: 8.7946\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8712 - val_loss: 8.7415\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.6235 - val_loss: 8.6864\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7996 - val_loss: 8.7142\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.5698 - val_loss: 8.7290\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.5958 - val_loss: 8.7000\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.5510 - val_loss: 8.6272\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9786 - val_loss: 8.6129\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.1117 - val_loss: 8.5739\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.0324 - val_loss: 8.5655\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.5975 - val_loss: 8.5548\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.4844 - val_loss: 8.5394\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.6385 - val_loss: 8.5590\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7743 - val_loss: 8.5335\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3195 - val_loss: 8.5224\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.6331 - val_loss: 8.5445\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.5414 - val_loss: 8.5716\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7892 - val_loss: 8.6035\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7068 - val_loss: 8.5951\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.5383 - val_loss: 8.5841\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.0843 - val_loss: 8.5981\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9374 - val_loss: 8.6073\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9758 - val_loss: 8.5948\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.8988 - val_loss: 8.5918\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.0129 - val_loss: 8.6403\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 14.7241 - val_loss: 18.5056\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.8797 - val_loss: 18.2250\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 13.8562 - val_loss: 17.8962\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.8517 - val_loss: 17.7031\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.8038 - val_loss: 17.5782\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 13.4164 - val_loss: 17.3470\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.6796 - val_loss: 17.2220\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.4870 - val_loss: 17.0491\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.1153 - val_loss: 16.8087\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.3139 - val_loss: 16.4845\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.9594 - val_loss: 16.2644\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.8961 - val_loss: 16.1667\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 12.1191 - val_loss: 15.9013\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.7550 - val_loss: 15.6741\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5151 - val_loss: 15.5270\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.3369 - val_loss: 15.2684\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.0749 - val_loss: 15.0904\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.6587 - val_loss: 15.0552\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.2654 - val_loss: 14.8431\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.0215 - val_loss: 14.7090\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.7623 - val_loss: 14.6155\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8671 - val_loss: 14.3091\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.6375 - val_loss: 14.1829\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1519 - val_loss: 14.1165\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.4423 - val_loss: 13.9895\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5260 - val_loss: 13.9850\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.0565 - val_loss: 13.8737\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.2578 - val_loss: 13.9252\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.4595 - val_loss: 13.7507\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.5706 - val_loss: 13.7493\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.9539 - val_loss: 13.7181\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.1081 - val_loss: 13.5586\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1153 - val_loss: 13.4611\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.9119 - val_loss: 13.2885\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.8898 - val_loss: 13.2207\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2076 - val_loss: 13.2003\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.9532 - val_loss: 13.1361\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.1693 - val_loss: 13.0249\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1100 - val_loss: 12.9133\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.7111 - val_loss: 12.9254\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.5581 - val_loss: 12.9253\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.6967 - val_loss: 12.9662\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.0784 - val_loss: 12.9421\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.3949 - val_loss: 12.8075\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.2062 - val_loss: 12.8128\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.5079 - val_loss: 12.7844\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.2085 - val_loss: 12.7591\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.8448 - val_loss: 12.9111\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.8178 - val_loss: 13.0014\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.3430 - val_loss: 12.9206\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.3228 - val_loss: 12.8951\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.9968 - val_loss: 12.9619\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.3425 - val_loss: 13.0072\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.9464 - val_loss: 12.9152\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.4727 - val_loss: 12.8103\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5252 - val_loss: 12.7087\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.3940 - val_loss: 12.8256\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.1047 - val_loss: 12.7956\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.1124 - val_loss: 12.7536\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.6560 - val_loss: 12.6754\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6234 - val_loss: 12.6212\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.9462 - val_loss: 12.6147\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.3528 - val_loss: 12.6710\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.2679 - val_loss: 12.7234\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4860 - val_loss: 12.6551\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.0888 - val_loss: 12.6661\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1689 - val_loss: 12.6501\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.5168 - val_loss: 12.6918\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5317 - val_loss: 12.6032\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.0656 - val_loss: 12.4450\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.9475 - val_loss: 12.4319\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.8704 - val_loss: 12.3492\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0733 - val_loss: 12.3928\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.1490 - val_loss: 12.3935\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6077 - val_loss: 12.2826\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.7576 - val_loss: 12.3036\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.3524 - val_loss: 12.2478\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.7924 - val_loss: 12.1288\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.6952 - val_loss: 12.0822\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8840 - val_loss: 12.1180\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.0498 - val_loss: 12.1611\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.1916 - val_loss: 12.2053\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2946 - val_loss: 12.1857\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3078 - val_loss: 12.0448\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8009 - val_loss: 12.0470\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8426 - val_loss: 11.9547\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6105 - val_loss: 11.9567\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.4767 - val_loss: 11.8779\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.5782 - val_loss: 11.8908\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.1521 - val_loss: 11.9053\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.2486 - val_loss: 11.8422\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.5784 - val_loss: 11.8902\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.5918 - val_loss: 11.8752\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9405 - val_loss: 11.8513\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5014 - val_loss: 11.8586\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.7331 - val_loss: 11.6680\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5315 - val_loss: 11.7094\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.1412 - val_loss: 11.5399\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.3519 - val_loss: 11.6145\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.2851 - val_loss: 11.5466\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.8117 - val_loss: 11.5156\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2071 - val_loss: 11.5388\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2916 - val_loss: 11.5280\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7994 - val_loss: 11.3538\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.8884 - val_loss: 11.3794\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.8827 - val_loss: 11.4523\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.9708 - val_loss: 11.4673\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.9254 - val_loss: 11.4515\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.1414 - val_loss: 11.3207\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.8431 - val_loss: 11.0966\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.2803 - val_loss: 11.0504\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.9468 - val_loss: 11.1217\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6321 - val_loss: 11.0853\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.3288 - val_loss: 10.9844\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.2512 - val_loss: 10.9892\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.5523 - val_loss: 10.9209\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6276 - val_loss: 10.8857\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.6921 - val_loss: 10.7270\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.9793 - val_loss: 10.8347\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.3190 - val_loss: 10.7705\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4277 - val_loss: 10.8252\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.5861 - val_loss: 10.8638\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5411 - val_loss: 10.6808\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.0092 - val_loss: 10.7558\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.8872 - val_loss: 10.7439\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.4005 - val_loss: 10.7525\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.5755 - val_loss: 10.8848\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4862 - val_loss: 10.8970\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.4667 - val_loss: 10.9250\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.0208 - val_loss: 11.0455\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7817 - val_loss: 11.0947\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.2084 - val_loss: 11.0333\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4058 - val_loss: 11.0004\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 38s 1s/step - loss: 12.5517 - val_loss: 13.4984\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.0831 - val_loss: 13.4729\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.8893 - val_loss: 13.3270\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.1974 - val_loss: 13.2511\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.1821 - val_loss: 13.2703\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.7092 - val_loss: 13.2573\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 11.1421 - val_loss: 13.2411\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.7264 - val_loss: 13.2284\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 11.5282 - val_loss: 13.2027\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.4321 - val_loss: 13.1237\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.8295 - val_loss: 13.0591\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.8925 - val_loss: 13.0648\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.0904 - val_loss: 13.0042\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 11.0603 - val_loss: 12.9133\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.8578 - val_loss: 12.8824\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.0758 - val_loss: 12.7999\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.1092 - val_loss: 12.7790\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5163 - val_loss: 12.7250\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.4759 - val_loss: 12.6008\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0509 - val_loss: 12.6128\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7951 - val_loss: 12.5604\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.4381 - val_loss: 12.3990\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.9003 - val_loss: 12.3169\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.6741 - val_loss: 12.2920\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5532 - val_loss: 12.2275\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7482 - val_loss: 12.2433\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.7683 - val_loss: 12.1569\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3919 - val_loss: 12.1255\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.4681 - val_loss: 12.0237\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.4583 - val_loss: 11.9787\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.4007 - val_loss: 11.9599\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.8437 - val_loss: 11.8781\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.6376 - val_loss: 11.7320\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.8128 - val_loss: 11.6051\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.3671 - val_loss: 11.5596\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.7043 - val_loss: 11.5182\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.5149 - val_loss: 11.5134\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.1685 - val_loss: 11.4672\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.6143 - val_loss: 11.3555\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.4313 - val_loss: 11.2310\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.5851 - val_loss: 11.2277\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.4762 - val_loss: 11.2170\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.1232 - val_loss: 11.2072\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.4823 - val_loss: 11.1622\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.5681 - val_loss: 11.1836\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.5654 - val_loss: 11.1259\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.4780 - val_loss: 11.1063\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5598 - val_loss: 11.1386\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.7731 - val_loss: 11.2019\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.5545 - val_loss: 11.2108\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.3194 - val_loss: 11.2331\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.1133 - val_loss: 11.2100\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2433 - val_loss: 11.1771\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7595 - val_loss: 11.0645\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.0987 - val_loss: 10.9087\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.7281 - val_loss: 10.7582\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3558 - val_loss: 10.7756\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.3605 - val_loss: 10.8384\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.7464 - val_loss: 10.8610\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.6161 - val_loss: 10.8856\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.9257 - val_loss: 10.8544\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.1640 - val_loss: 10.7614\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.4200 - val_loss: 10.7418\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.0236 - val_loss: 10.7664\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5149 - val_loss: 10.7700\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.0274 - val_loss: 10.8428\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.6367 - val_loss: 10.9096\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5336 - val_loss: 10.9493\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.0635 - val_loss: 10.9713\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.4719 - val_loss: 10.9620\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.5405 - val_loss: 10.9328\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.3223 - val_loss: 10.9566\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.9124 - val_loss: 11.0269\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Executing 311dd366 iter 5\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 31s 1s/step - loss: 20.5016 - val_loss: 7.6945\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 20.9330 - val_loss: 7.5529\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.0927 - val_loss: 7.4229\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 17.9303 - val_loss: 7.2921\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 19.0086 - val_loss: 7.1614\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 16.5081 - val_loss: 7.0633\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.9845 - val_loss: 6.9498\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 16.7946 - val_loss: 6.8446\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.1602 - val_loss: 6.7545\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.7497 - val_loss: 6.6663\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.9791 - val_loss: 6.5903\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.7737 - val_loss: 6.5062\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.8774 - val_loss: 6.4199\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.9664 - val_loss: 6.3477\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.9467 - val_loss: 6.2821\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 14.9640 - val_loss: 6.2192\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.1247 - val_loss: 6.1492\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.7164 - val_loss: 6.0875\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.6465 - val_loss: 6.0196\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.1092 - val_loss: 5.9602\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.6563 - val_loss: 5.9034\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 13.2383 - val_loss: 5.8522\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.8876 - val_loss: 5.8068\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.1156 - val_loss: 5.7623\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.1261 - val_loss: 5.7254\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.4765 - val_loss: 5.6896\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.6720 - val_loss: 5.6622\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.2180 - val_loss: 5.6265\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.2716 - val_loss: 5.5917\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0270 - val_loss: 5.5419\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.6364 - val_loss: 5.5096\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.2930 - val_loss: 5.4726\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.4184 - val_loss: 5.4138\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1517 - val_loss: 5.3297\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.9405 - val_loss: 5.2365\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.3890 - val_loss: 5.1699\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0900 - val_loss: 5.1068\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.7192 - val_loss: 5.0306\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.4830 - val_loss: 4.9663\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.3782 - val_loss: 4.9010\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.1588 - val_loss: 4.8459\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5012 - val_loss: 4.8001\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4924 - val_loss: 4.7623\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3473 - val_loss: 4.7259\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.8387 - val_loss: 4.6931\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.7555 - val_loss: 4.6611\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1481 - val_loss: 4.6499\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0736 - val_loss: 4.6424\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.5876 - val_loss: 4.6215\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.9463 - val_loss: 4.6075\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.2842 - val_loss: 4.5945\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5060 - val_loss: 4.5837\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.1171 - val_loss: 4.5830\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.5692 - val_loss: 4.5843\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.6059 - val_loss: 4.5696\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9320 - val_loss: 4.5706\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6918 - val_loss: 4.5622\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3679 - val_loss: 4.5708\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.0538 - val_loss: 4.5894\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3195 - val_loss: 4.6011\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.6048 - val_loss: 4.6082\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.2340 - val_loss: 4.6202\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3547 - val_loss: 4.6373\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.3520 - val_loss: 4.6585\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.0254 - val_loss: 4.6877\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9305 - val_loss: 4.7049\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.4816 - val_loss: 4.6965\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 34s 1s/step - loss: 16.5965 - val_loss: 7.9260\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 16.6406 - val_loss: 7.8468\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.4424 - val_loss: 7.7762\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 16.1735 - val_loss: 7.6988\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.5571 - val_loss: 7.6259\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.0282 - val_loss: 7.5584\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.5826 - val_loss: 7.4850\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 16.0218 - val_loss: 7.4250\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 15.6009 - val_loss: 7.3625\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.8577 - val_loss: 7.2971\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 15.3820 - val_loss: 7.2363\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.1528 - val_loss: 7.1735\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.4680 - val_loss: 7.1058\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 15.0202 - val_loss: 7.0370\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 15.1594 - val_loss: 6.9610\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.6029 - val_loss: 6.8855\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 14.5192 - val_loss: 6.7913\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.8521 - val_loss: 6.7268\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 14.3730 - val_loss: 6.6471\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 14.2080 - val_loss: 6.5731\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 14.1522 - val_loss: 6.5154\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.8288 - val_loss: 6.4610\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.8262 - val_loss: 6.3910\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.2391 - val_loss: 6.3253\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.1296 - val_loss: 6.2649\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.4605 - val_loss: 6.2054\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.7745 - val_loss: 6.1355\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.3046 - val_loss: 6.0748\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 12.2896 - val_loss: 6.0104\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.1024 - val_loss: 5.9581\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 11.6981 - val_loss: 5.9183\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.7922 - val_loss: 5.8732\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.1831 - val_loss: 5.8245\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.6952 - val_loss: 5.7662\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.1072 - val_loss: 5.6870\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.4488 - val_loss: 5.6361\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.1903 - val_loss: 5.6078\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.6744 - val_loss: 5.5756\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.6710 - val_loss: 5.5215\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.2446 - val_loss: 5.4893\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.9783 - val_loss: 5.4546\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.7230 - val_loss: 5.4370\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3143 - val_loss: 5.4191\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3593 - val_loss: 5.3912\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.8204 - val_loss: 5.3729\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.3994 - val_loss: 5.3730\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.8889 - val_loss: 5.4055\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6987 - val_loss: 5.4511\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.6708 - val_loss: 5.4674\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3516 - val_loss: 5.4978\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.8496 - val_loss: 5.5095\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.4976 - val_loss: 5.5441\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.8971 - val_loss: 5.5589\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.1221 - val_loss: 5.5580\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6867 - val_loss: 5.5738\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 33s 1s/step - loss: 16.2167 - val_loss: 6.9882\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.4606 - val_loss: 6.7933\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.3328 - val_loss: 6.6039\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 15.3539 - val_loss: 6.4266\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.3329 - val_loss: 6.2721\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.8794 - val_loss: 6.1483\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.6507 - val_loss: 6.0281\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.4448 - val_loss: 5.9114\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.1817 - val_loss: 5.7986\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.5417 - val_loss: 5.6960\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0800 - val_loss: 5.6186\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.2120 - val_loss: 5.5508\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.2400 - val_loss: 5.4834\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5054 - val_loss: 5.4164\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.3830 - val_loss: 5.3575\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 11.6380 - val_loss: 5.2985\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.2996 - val_loss: 5.2396\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.9547 - val_loss: 5.1962\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.3612 - val_loss: 5.1523\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.7190 - val_loss: 5.1162\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 10.1464 - val_loss: 5.0825\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.2931 - val_loss: 5.0506\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.0467 - val_loss: 5.0097\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.8669 - val_loss: 4.9898\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.6655 - val_loss: 4.9786\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.4706 - val_loss: 4.9691\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.0106 - val_loss: 4.9698\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.5219 - val_loss: 4.9628\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.7279 - val_loss: 4.9547\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.0651 - val_loss: 4.9472\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.7961 - val_loss: 4.9462\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.8238 - val_loss: 4.9338\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.4368 - val_loss: 4.9152\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.3982 - val_loss: 4.9050\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.0648 - val_loss: 4.8817\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.6742 - val_loss: 4.8669\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.6320 - val_loss: 4.8569\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.1401 - val_loss: 4.8564\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.7491 - val_loss: 4.8592\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.1390 - val_loss: 4.8625\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.4956 - val_loss: 4.8743\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9898 - val_loss: 4.8908\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.9979 - val_loss: 4.8838\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.6198 - val_loss: 4.8607\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9769 - val_loss: 4.8481\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.6384 - val_loss: 4.8284\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.3309 - val_loss: 4.8323\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.7563 - val_loss: 4.8458\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.4734 - val_loss: 4.8545\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.5008 - val_loss: 4.8804\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.1215 - val_loss: 4.8818\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.4603 - val_loss: 4.8871\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.0350 - val_loss: 4.8819\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.7425 - val_loss: 4.8863\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.1150 - val_loss: 4.9129\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7419 - val_loss: 4.9362\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 26.5967 - val_loss: 9.6963\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 23.7266 - val_loss: 9.4893\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 22.3729 - val_loss: 9.2846\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 22.9665 - val_loss: 9.0528\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 22.0827 - val_loss: 8.8504\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 19.5554 - val_loss: 8.6798\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 19.4005 - val_loss: 8.4842\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 20.7074 - val_loss: 8.3073\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 18.7006 - val_loss: 8.1330\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 19.8455 - val_loss: 7.9581\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 19.1220 - val_loss: 7.7993\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 17.9355 - val_loss: 7.6318\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 18.4194 - val_loss: 7.4557\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.7392 - val_loss: 7.2957\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 17.3022 - val_loss: 7.0877\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 16.6789 - val_loss: 6.9115\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 15.9629 - val_loss: 6.7250\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 16.5051 - val_loss: 6.5893\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.7978 - val_loss: 6.4363\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 14.8042 - val_loss: 6.2873\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 14.8553 - val_loss: 6.1752\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.7808 - val_loss: 6.0986\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 13.3950 - val_loss: 6.0046\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.6263 - val_loss: 5.9119\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.8660 - val_loss: 5.8225\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.5175 - val_loss: 5.7540\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 13.9154 - val_loss: 5.6833\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.6470 - val_loss: 5.6113\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.4062 - val_loss: 5.5411\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.2809 - val_loss: 5.4746\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.9142 - val_loss: 5.4225\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 12.0333 - val_loss: 5.3706\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.3774 - val_loss: 5.3138\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.7772 - val_loss: 5.2599\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.2825 - val_loss: 5.1998\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.5902 - val_loss: 5.1563\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.2310 - val_loss: 5.1163\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.6096 - val_loss: 5.0638\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.2472 - val_loss: 5.0083\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.5692 - val_loss: 4.9656\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.0924 - val_loss: 4.9186\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2226 - val_loss: 4.8760\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.6489 - val_loss: 4.8402\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 10.2920 - val_loss: 4.8021\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.4456 - val_loss: 4.7626\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.8052 - val_loss: 4.7228\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3911 - val_loss: 4.6945\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.9122 - val_loss: 4.6741\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.2112 - val_loss: 4.6475\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.1332 - val_loss: 4.6267\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.4734 - val_loss: 4.5956\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.0359 - val_loss: 4.5712\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.4097 - val_loss: 4.5445\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.0086 - val_loss: 4.5217\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.9130 - val_loss: 4.5002\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.4864 - val_loss: 4.4929\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.8215 - val_loss: 4.4799\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.4653 - val_loss: 4.4593\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1294 - val_loss: 4.4369\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2600 - val_loss: 4.4193\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.8564 - val_loss: 4.3916\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.5039 - val_loss: 4.3776\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.0841 - val_loss: 4.3676\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.4548 - val_loss: 4.3553\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.1457 - val_loss: 4.3386\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5858 - val_loss: 4.3326\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.1123 - val_loss: 4.3215\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.5739 - val_loss: 4.3181\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.0593 - val_loss: 4.3141\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7593 - val_loss: 4.3180\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.8734 - val_loss: 4.3155\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.6144 - val_loss: 4.3142\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.2753 - val_loss: 4.3144\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.0037 - val_loss: 4.3078\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.3226 - val_loss: 4.3003\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.0173 - val_loss: 4.2905\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.7845 - val_loss: 4.2866\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.6385 - val_loss: 4.2853\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.0428 - val_loss: 4.2730\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.8123 - val_loss: 4.2659\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.2366 - val_loss: 4.2570\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2075 - val_loss: 4.2548\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.9579 - val_loss: 4.2623\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.5287 - val_loss: 4.2632\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.7874 - val_loss: 4.2605\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.1422 - val_loss: 4.2460\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.1656 - val_loss: 4.2425\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.0371 - val_loss: 4.2494\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4201 - val_loss: 4.2511\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.4279 - val_loss: 4.2550\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7515 - val_loss: 4.2538\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.1384 - val_loss: 4.2562\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.9148 - val_loss: 4.2616\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.5518 - val_loss: 4.2700\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.8738 - val_loss: 4.2825\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.3072 - val_loss: 4.2901\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.6740 - val_loss: 4.2975\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 7.2286 - val_loss: 17.3273\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2394 - val_loss: 17.1556\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.8716 - val_loss: 17.0275\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.8712 - val_loss: 16.7831\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8105 - val_loss: 16.6935\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.1244 - val_loss: 16.4591\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.1495 - val_loss: 16.2831\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.1173 - val_loss: 16.1180\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.0946 - val_loss: 16.0033\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.9890 - val_loss: 15.8266\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.3219 - val_loss: 15.6817\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.8192 - val_loss: 15.5786\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.6677 - val_loss: 15.4430\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.8650 - val_loss: 15.2451\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.3726 - val_loss: 15.0430\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.7437 - val_loss: 14.9224\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.9628 - val_loss: 14.8314\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.1446 - val_loss: 14.7327\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.1490 - val_loss: 14.7401\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.9331 - val_loss: 14.7505\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.8333 - val_loss: 14.8306\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.7092 - val_loss: 14.8586\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.8303 - val_loss: 14.8958\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.6977 - val_loss: 14.9923\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.7669 - val_loss: 15.0048\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.9588 - val_loss: 14.9626\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9937 - val_loss: 14.8803\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9489 - val_loss: 14.7510\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 6.2935 - val_loss: 22.1874\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4835 - val_loss: 21.8685\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.9770 - val_loss: 21.6107\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.3816 - val_loss: 21.3434\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.2499 - val_loss: 21.1610\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.9769 - val_loss: 20.9239\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.9254 - val_loss: 20.7360\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.0126 - val_loss: 20.5789\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4983 - val_loss: 20.4153\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.5687 - val_loss: 20.1844\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.4108 - val_loss: 19.9819\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.2587 - val_loss: 19.7992\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.2905 - val_loss: 19.6126\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.0815 - val_loss: 19.4084\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.9158 - val_loss: 19.2328\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.0233 - val_loss: 19.0932\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.7563 - val_loss: 18.9566\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.6977 - val_loss: 18.8855\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.7696 - val_loss: 18.8504\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5645 - val_loss: 18.7921\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.5673 - val_loss: 18.7575\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.5022 - val_loss: 18.6415\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.2217 - val_loss: 18.5850\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.9495 - val_loss: 18.6144\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.1096 - val_loss: 18.6194\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.7679 - val_loss: 18.5690\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.9743 - val_loss: 18.4564\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9459 - val_loss: 18.3188\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.6115 - val_loss: 18.3006\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.6651 - val_loss: 18.2234\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.7725 - val_loss: 18.1849\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.8955 - val_loss: 18.0470\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.4129 - val_loss: 17.9867\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.3630 - val_loss: 17.9454\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0905 - val_loss: 17.9138\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.1882 - val_loss: 17.8832\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.1951 - val_loss: 17.8368\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.8587 - val_loss: 17.7564\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.0803 - val_loss: 17.7187\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8234 - val_loss: 17.5561\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.8031 - val_loss: 17.5152\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.6349 - val_loss: 17.5379\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.5639 - val_loss: 17.4920\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.7173 - val_loss: 17.4650\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.7418 - val_loss: 17.5053\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4621 - val_loss: 17.5649\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4707 - val_loss: 17.5917\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3176 - val_loss: 17.6818\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.4660 - val_loss: 17.7114\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.2612 - val_loss: 17.7837\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0768 - val_loss: 17.8379\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.3514 - val_loss: 17.8838\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.0188 - val_loss: 17.9852\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.2916 - val_loss: 18.0259\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 671us/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 6.6940 - val_loss: 16.4848\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.9760 - val_loss: 16.6473\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.4175 - val_loss: 16.8349\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.1591 - val_loss: 17.0226\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.7848 - val_loss: 17.2419\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.6827 - val_loss: 17.2783\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.3109 - val_loss: 17.2667\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.5619 - val_loss: 17.3103\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.6263 - val_loss: 17.2829\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4145 - val_loss: 17.1866\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.1013 - val_loss: 17.1529\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 7.7488 - val_loss: 27.7110\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.2989 - val_loss: 27.4482\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.6568 - val_loss: 27.1308\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.9854 - val_loss: 26.7814\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8115 - val_loss: 26.5032\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.0522 - val_loss: 26.2606\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.8556 - val_loss: 26.0787\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8135 - val_loss: 25.8742\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.8899 - val_loss: 25.6355\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.5325 - val_loss: 25.3503\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.9366 - val_loss: 25.1086\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.4368 - val_loss: 24.9131\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.8626 - val_loss: 24.7159\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4642 - val_loss: 24.4825\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.1092 - val_loss: 24.3548\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.0049 - val_loss: 24.2436\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5414 - val_loss: 24.0754\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.1589 - val_loss: 23.9378\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.3606 - val_loss: 23.8331\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.9036 - val_loss: 23.7086\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.8435 - val_loss: 23.6671\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.8434 - val_loss: 23.6138\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.0360 - val_loss: 23.5810\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4411 - val_loss: 23.6048\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.7708 - val_loss: 23.6065\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.3216 - val_loss: 23.5695\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.6031 - val_loss: 23.5259\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5493 - val_loss: 23.4811\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.2148 - val_loss: 23.5136\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.3916 - val_loss: 23.4823\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0842 - val_loss: 23.4336\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.0633 - val_loss: 23.3239\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0948 - val_loss: 23.3169\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.4196 - val_loss: 23.2692\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.0425 - val_loss: 23.2420\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.9285 - val_loss: 23.1811\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8669 - val_loss: 23.0908\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.1754 - val_loss: 22.9913\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.8942 - val_loss: 22.8768\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.8048 - val_loss: 22.7860\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.7715 - val_loss: 22.7231\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6285 - val_loss: 22.7921\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3812 - val_loss: 22.8287\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.7578 - val_loss: 22.8288\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.2578 - val_loss: 22.8043\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.4690 - val_loss: 22.8077\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.5676 - val_loss: 22.8336\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3900 - val_loss: 22.8864\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.6760 - val_loss: 22.9667\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.7851 - val_loss: 23.0004\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.4783 - val_loss: 22.9806\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 10.1921 - val_loss: 5.4742\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5919 - val_loss: 5.3769\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.2769 - val_loss: 5.2956\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.1863 - val_loss: 5.2676\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.7721 - val_loss: 5.3053\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.9639 - val_loss: 5.2962\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3169 - val_loss: 5.3116\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.5429 - val_loss: 5.3347\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9728 - val_loss: 5.3588\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.0710 - val_loss: 5.4119\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8510 - val_loss: 5.4413\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.8262 - val_loss: 5.4786\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 7.2495 - val_loss: 5.5094\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8669 - val_loss: 5.5402\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 8.9001 - val_loss: 2.9765\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6832 - val_loss: 2.9263\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.4723 - val_loss: 2.8838\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.0499 - val_loss: 2.8588\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6269 - val_loss: 2.8446\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1803 - val_loss: 2.8316\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7005 - val_loss: 2.8321\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2327 - val_loss: 2.8326\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3907 - val_loss: 2.8368\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.7823 - val_loss: 2.8317\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9780 - val_loss: 2.8343\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.7734 - val_loss: 2.8597\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.3501 - val_loss: 2.8888\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.6278 - val_loss: 2.9137\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.1073 - val_loss: 2.9480\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.6268 - val_loss: 2.9797\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 235s 1s/step - loss: 13.0601 - val_loss: 6.2309\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 12.5798 - val_loss: 6.0440\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.6069 - val_loss: 5.9166\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.1737 - val_loss: 5.8169\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 13.5543 - val_loss: 5.6903\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.4186 - val_loss: 5.5962\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.2171 - val_loss: 5.5094\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.2249 - val_loss: 5.4446\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.9373 - val_loss: 5.4101\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.1300 - val_loss: 5.3104\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.7025 - val_loss: 5.2236\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.5382 - val_loss: 5.1522\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6189 - val_loss: 5.1123\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.9623 - val_loss: 5.0076\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.0484 - val_loss: 4.9031\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.5738 - val_loss: 4.8160\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.6449 - val_loss: 4.7313\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.8814 - val_loss: 4.6795\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 12.4642 - val_loss: 4.6218\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 10.4990 - val_loss: 4.6010\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.4835 - val_loss: 4.5790\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.9173 - val_loss: 4.5354\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 10.3943 - val_loss: 4.4719\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.4750 - val_loss: 4.3953\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.8305 - val_loss: 4.3282\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.8754 - val_loss: 4.2728\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.5623 - val_loss: 4.2467\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.4762 - val_loss: 4.2311\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 11.0102 - val_loss: 4.2426\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.8020 - val_loss: 4.2698\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.5941 - val_loss: 4.2765\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.9348 - val_loss: 4.2566\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.1274 - val_loss: 4.2561\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.4068 - val_loss: 4.2533\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.5065 - val_loss: 4.2823\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.2853 - val_loss: 4.2909\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.3622 - val_loss: 4.3016\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 6.9230 - val_loss: 4.3213\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 10.6222 - val_loss: 2.4754\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.9827 - val_loss: 2.4713\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.5601 - val_loss: 2.5049\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.8935 - val_loss: 2.5293\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.1417 - val_loss: 2.5517\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.2059 - val_loss: 2.5634\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.4368 - val_loss: 2.5932\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.4630 - val_loss: 2.6146\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2715 - val_loss: 2.6542\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5681 - val_loss: 2.6961\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.3280 - val_loss: 2.7173\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.3906 - val_loss: 2.7437\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 12.0128 - val_loss: 2.8112\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.3512 - val_loss: 2.7628\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.6095 - val_loss: 2.7774\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.3980 - val_loss: 2.8061\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.9546 - val_loss: 2.8517\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.7599 - val_loss: 2.8684\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.2611 - val_loss: 2.9109\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.1871 - val_loss: 2.9606\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.7364 - val_loss: 2.9779\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.1360 - val_loss: 3.0262\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.8710 - val_loss: 3.0454\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.8295 - val_loss: 3.0181\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 13.7343 - val_loss: 2.9023\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.3178 - val_loss: 2.9292\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0185 - val_loss: 2.9936\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.9741 - val_loss: 3.0652\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.2416 - val_loss: 3.1230\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.8895 - val_loss: 3.1655\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.0191 - val_loss: 3.2254\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.7067 - val_loss: 3.2947\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.4092 - val_loss: 3.3621\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.2245 - val_loss: 3.4431\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.6773 - val_loss: 3.5019\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 13.8117 - val_loss: 1.7498\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.8724 - val_loss: 1.7646\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.0896 - val_loss: 1.8035\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.3659 - val_loss: 1.8491\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.0699 - val_loss: 1.8601\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.6275 - val_loss: 1.8836\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.6696 - val_loss: 1.9264\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.0595 - val_loss: 1.9671\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2632 - val_loss: 1.9908\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.2374 - val_loss: 2.0224\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7542 - val_loss: 2.0403\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 12.6906 - val_loss: 1.8695\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.9060 - val_loss: 1.8631\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1175 - val_loss: 1.8715\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.4481 - val_loss: 1.9148\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.5367 - val_loss: 1.9778\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.1219 - val_loss: 2.0162\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.4067 - val_loss: 2.0683\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.6880 - val_loss: 2.1113\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.0761 - val_loss: 2.1602\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.0694 - val_loss: 2.2155\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.4054 - val_loss: 2.2564\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.1620 - val_loss: 2.3019\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 9.6622 - val_loss: 77.4932\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.5668 - val_loss: 76.5960\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.0253 - val_loss: 75.9553\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3305 - val_loss: 75.0807\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.8871 - val_loss: 74.5098\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3366 - val_loss: 73.7918\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.8926 - val_loss: 72.8128\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3825 - val_loss: 71.6465\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2900 - val_loss: 70.8900\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.6611 - val_loss: 70.1229\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0275 - val_loss: 69.5544\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2616 - val_loss: 68.8350\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.2637 - val_loss: 68.6607\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7390 - val_loss: 68.4643\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.0304 - val_loss: 67.6333\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.8906 - val_loss: 67.0113\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.6301 - val_loss: 66.1958\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.0466 - val_loss: 65.3776\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.0706 - val_loss: 64.7467\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.6389 - val_loss: 64.2974\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.1844 - val_loss: 63.5622\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 6.1174 - val_loss: 63.0730\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.8374 - val_loss: 62.5727\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.2197 - val_loss: 61.7299\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.5793 - val_loss: 61.4644\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.3977 - val_loss: 60.8665\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.1040 - val_loss: 60.3921\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.9680 - val_loss: 60.1396\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.8850 - val_loss: 59.6830\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.8532 - val_loss: 58.9380\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.4316 - val_loss: 58.6118\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3443 - val_loss: 57.8248\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.4254 - val_loss: 57.5995\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.7916 - val_loss: 57.5540\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.8029 - val_loss: 57.0502\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.2214 - val_loss: 57.0535\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.2359 - val_loss: 56.8397\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.2933 - val_loss: 56.5090\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8527 - val_loss: 56.0393\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.0782 - val_loss: 55.6051\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.3020 - val_loss: 54.9006\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.6034 - val_loss: 54.5286\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6151 - val_loss: 53.9849\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6243 - val_loss: 53.9394\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.3105 - val_loss: 54.1507\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5771 - val_loss: 54.2015\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4159 - val_loss: 54.0602\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0675 - val_loss: 54.1668\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3850 - val_loss: 53.7557\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.8525 - val_loss: 53.7737\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2718 - val_loss: 52.9693\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.6842 - val_loss: 52.4409\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.1921 - val_loss: 52.4116\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.9347 - val_loss: 52.7544\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.8971 - val_loss: 52.7257\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.0235 - val_loss: 52.6543\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.3099 - val_loss: 52.0923\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4801 - val_loss: 51.8592\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.1606 - val_loss: 51.1178\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7252 - val_loss: 50.9277\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.9434 - val_loss: 50.9290\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.4082 - val_loss: 50.8809\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.7466 - val_loss: 50.6635\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.4121 - val_loss: 50.3573\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.1801 - val_loss: 50.2483\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.0965 - val_loss: 49.5199\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.5914 - val_loss: 48.9229\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.7103 - val_loss: 48.1719\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.9302 - val_loss: 47.9170\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8071 - val_loss: 48.2507\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.1605 - val_loss: 48.2939\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.4928 - val_loss: 48.0220\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.7576 - val_loss: 47.9782\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.9854 - val_loss: 48.1665\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.5910 - val_loss: 48.7548\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.4154 - val_loss: 48.9232\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.7657 - val_loss: 49.2358\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.3635 - val_loss: 49.1876\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.9825 - val_loss: 48.7435\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 9.7216 - val_loss: 76.4298\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.5885 - val_loss: 76.3446\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.5580 - val_loss: 76.2401\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3528 - val_loss: 76.1433\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.1005 - val_loss: 76.2056\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.8265 - val_loss: 76.2491\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.4150 - val_loss: 76.1650\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2513 - val_loss: 76.0539\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9045 - val_loss: 76.0359\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.9602 - val_loss: 75.9696\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2787 - val_loss: 75.9172\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3643 - val_loss: 75.6665\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3518 - val_loss: 75.6872\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.9289 - val_loss: 75.5449\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.0926 - val_loss: 75.2885\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.2859 - val_loss: 75.1488\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.8218 - val_loss: 74.8204\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.0335 - val_loss: 74.6079\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.3383 - val_loss: 74.4902\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.7226 - val_loss: 74.4085\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.2987 - val_loss: 74.1825\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.7985 - val_loss: 74.1523\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.8185 - val_loss: 74.0831\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.1258 - val_loss: 73.9029\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.7462 - val_loss: 73.8578\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.3807 - val_loss: 73.7196\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.9899 - val_loss: 73.3905\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.8326 - val_loss: 73.1455\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.3756 - val_loss: 72.8607\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.1691 - val_loss: 72.4958\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.3538 - val_loss: 72.3280\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.6152 - val_loss: 71.9856\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.5354 - val_loss: 71.7430\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.4057 - val_loss: 71.4541\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.3887 - val_loss: 71.0913\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.9306 - val_loss: 70.8995\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.0311 - val_loss: 70.6793\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3892 - val_loss: 70.4874\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.6292 - val_loss: 70.3136\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.5239 - val_loss: 70.1952\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.5953 - val_loss: 70.1259\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.8240 - val_loss: 70.1759\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.3113 - val_loss: 70.1558\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.4803 - val_loss: 70.2589\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.2720 - val_loss: 70.3818\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.2354 - val_loss: 70.4074\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7881 - val_loss: 70.3968\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6737 - val_loss: 70.5071\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.9076 - val_loss: 70.0939\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.7542 - val_loss: 70.0544\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.7969 - val_loss: 69.8489\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6296 - val_loss: 69.5143\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.4825 - val_loss: 69.1408\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.7306 - val_loss: 68.8605\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3949 - val_loss: 68.6248\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.6106 - val_loss: 68.3161\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.4478 - val_loss: 68.0649\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6364 - val_loss: 68.1430\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.1049 - val_loss: 68.2439\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.0192 - val_loss: 68.3001\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.5078 - val_loss: 68.1524\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.2759 - val_loss: 67.9147\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.9081 - val_loss: 67.7860\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.3597 - val_loss: 67.3889\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.8450 - val_loss: 67.2577\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.7988 - val_loss: 67.0016\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.7808 - val_loss: 66.8209\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.7158 - val_loss: 66.5608\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.6492 - val_loss: 66.4006\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.3813 - val_loss: 66.3237\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.7459 - val_loss: 66.0178\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.6532 - val_loss: 65.7013\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.8082 - val_loss: 65.3338\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.6315 - val_loss: 64.9958\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.3846 - val_loss: 64.9024\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.5238 - val_loss: 64.4748\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4104 - val_loss: 64.3059\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.5166 - val_loss: 64.0301\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.2579 - val_loss: 63.7619\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8657 - val_loss: 63.3668\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.4798 - val_loss: 62.9288\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.1514 - val_loss: 62.4378\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1.3824 - val_loss: 61.9003\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.4536 - val_loss: 61.6233\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.4345 - val_loss: 61.2569\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.1063 - val_loss: 61.1620\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9776 - val_loss: 61.1821\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.3197 - val_loss: 61.0731\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.3831 - val_loss: 61.0712\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.1638 - val_loss: 60.8801\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.2876 - val_loss: 60.4835\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.3902 - val_loss: 59.8000\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.0280 - val_loss: 59.8622\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.2457 - val_loss: 60.1373\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0525 - val_loss: 60.5695\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4077 - val_loss: 61.1459\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9675 - val_loss: 61.1605\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.7559 - val_loss: 61.2003\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.7169 - val_loss: 61.1281\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8414 - val_loss: 61.2657\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8684 - val_loss: 61.0675\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1.0385 - val_loss: 60.9497\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 9.8959 - val_loss: 59.5157\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.4256 - val_loss: 59.7271\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3335 - val_loss: 59.9798\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.8572 - val_loss: 59.9345\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.6550 - val_loss: 60.2135\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.4331 - val_loss: 60.2027\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.4411 - val_loss: 60.2238\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3171 - val_loss: 60.2165\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0063 - val_loss: 60.4053\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.5103 - val_loss: 60.5305\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.7775 - val_loss: 60.5708\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 8.3696 - val_loss: 69.6406\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.4836 - val_loss: 70.0632\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6090 - val_loss: 70.3441\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.1722 - val_loss: 70.6269\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4470 - val_loss: 70.9925\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4857 - val_loss: 71.1308\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5391 - val_loss: 71.1933\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7360 - val_loss: 71.4536\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4391 - val_loss: 71.7187\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.5445 - val_loss: 71.9285\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2229 - val_loss: 72.1043\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 9.1933 - val_loss: 7.9994\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5249 - val_loss: 8.0050\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6855 - val_loss: 8.0055\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2763 - val_loss: 7.9501\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.5365 - val_loss: 7.9428\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6015 - val_loss: 7.9023\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.8549 - val_loss: 7.8737\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4562 - val_loss: 7.9000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.8217 - val_loss: 7.9267\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.5992 - val_loss: 7.8773\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3070 - val_loss: 7.8302\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.6028 - val_loss: 7.8629\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2869 - val_loss: 7.8313\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.8139 - val_loss: 7.8327\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.2657 - val_loss: 7.8541\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.6538 - val_loss: 7.8328\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.4571 - val_loss: 7.8215\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.9869 - val_loss: 7.7949\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.2168 - val_loss: 7.7946\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.7742 - val_loss: 7.8356\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.0532 - val_loss: 7.9066\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.4714 - val_loss: 7.9231\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.9125 - val_loss: 7.9241\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.7836 - val_loss: 7.9351\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.3922 - val_loss: 7.9026\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.1566 - val_loss: 7.9017\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.6699 - val_loss: 7.9282\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.3366 - val_loss: 7.9648\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.3700 - val_loss: 7.9848\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 10.7486 - val_loss: 9.1094\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.0602 - val_loss: 9.1385\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.7228 - val_loss: 9.1480\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9196 - val_loss: 9.1719\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9246 - val_loss: 9.2256\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.3416 - val_loss: 9.2614\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.4647 - val_loss: 9.2852\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8953 - val_loss: 9.3264\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.1108 - val_loss: 9.3614\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2283 - val_loss: 9.3737\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.6551 - val_loss: 9.4161\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 207s 1s/step - loss: 11.2926 - val_loss: 11.1995\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.9119 - val_loss: 11.2154\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3492 - val_loss: 11.1580\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.2494 - val_loss: 11.1036\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.3289 - val_loss: 11.1040\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.9148 - val_loss: 11.1019\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5843 - val_loss: 11.1264\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8664 - val_loss: 11.1864\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.5056 - val_loss: 11.2098\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.4895 - val_loss: 11.2077\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.3824 - val_loss: 11.2115\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.7464 - val_loss: 11.2783\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6963 - val_loss: 11.2458\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.5657 - val_loss: 11.2692\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2669 - val_loss: 11.2900\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.8310 - val_loss: 11.2644\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 872us/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 1s/step - loss: 12.5259 - val_loss: 8.1861\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.2087 - val_loss: 8.1737\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.1697 - val_loss: 8.1605\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2674 - val_loss: 8.1508\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.2782 - val_loss: 8.1626\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8844 - val_loss: 8.1604\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.9491 - val_loss: 8.1702\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.4129 - val_loss: 8.1755\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7235 - val_loss: 8.1840\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.4294 - val_loss: 8.2092\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.1952 - val_loss: 8.2177\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.7633 - val_loss: 8.2669\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.4620 - val_loss: 8.2870\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.7394 - val_loss: 8.3027\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 14.4526 - val_loss: 5.8621\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.2931 - val_loss: 5.9391\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 13.5615 - val_loss: 5.9467\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.6670 - val_loss: 5.9362\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.4478 - val_loss: 6.0200\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.0799 - val_loss: 6.0820\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.3684 - val_loss: 6.1657\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.4890 - val_loss: 6.2844\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.4020 - val_loss: 6.3221\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.3260 - val_loss: 6.3808\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.0416 - val_loss: 6.4048\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 19.5519 - val_loss: 6.8406\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 16.5443 - val_loss: 6.8055\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 17.3758 - val_loss: 6.6808\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.5819 - val_loss: 6.5603\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.6305 - val_loss: 6.5262\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.3346 - val_loss: 6.4643\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 14.7518 - val_loss: 6.4091\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.1596 - val_loss: 6.3754\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.2463 - val_loss: 6.3179\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.1977 - val_loss: 6.2998\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5471 - val_loss: 6.3041\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4389 - val_loss: 6.3218\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.2202 - val_loss: 6.3448\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.2806 - val_loss: 6.3474\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.7355 - val_loss: 6.3969\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1302 - val_loss: 6.3815\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.4618 - val_loss: 6.4089\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.5196 - val_loss: 6.4576\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.8964 - val_loss: 6.4930\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.9558 - val_loss: 6.5287\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 12.6757 - val_loss: 6.8035\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.5584 - val_loss: 6.7685\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.5051 - val_loss: 6.6999\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4370 - val_loss: 6.6323\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.6088 - val_loss: 6.5452\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.7764 - val_loss: 6.4577\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.1833 - val_loss: 6.3923\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.0110 - val_loss: 6.3685\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.7869 - val_loss: 6.3367\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.6737 - val_loss: 6.3335\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.7055 - val_loss: 6.3457\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.6042 - val_loss: 6.3444\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.6248 - val_loss: 6.3797\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.4011 - val_loss: 6.4332\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.9084 - val_loss: 6.5078\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.7100 - val_loss: 6.5560\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.9636 - val_loss: 6.6018\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.3539 - val_loss: 6.6701\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.5998 - val_loss: 6.6924\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.3641 - val_loss: 6.6983\n",
      "2/2 [==============================] - 0s 439us/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 21s 1s/step - loss: 13.9837 - val_loss: 9.1241\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.9533 - val_loss: 9.1879\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 12.0499 - val_loss: 9.1652\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.6175 - val_loss: 9.1104\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.6280 - val_loss: 9.0856\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.5698 - val_loss: 9.0266\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.4768 - val_loss: 9.0009\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.3651 - val_loss: 8.9702\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.2782 - val_loss: 8.9211\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.8829 - val_loss: 8.9004\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 12.0051 - val_loss: 8.9181\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.5721 - val_loss: 8.9043\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.6449 - val_loss: 8.9181\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.7506 - val_loss: 8.9602\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.0803 - val_loss: 9.0272\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2936 - val_loss: 9.0676\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.0465 - val_loss: 9.1438\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6088 - val_loss: 9.2132\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.6789 - val_loss: 9.2225\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.0789 - val_loss: 9.1696\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 31s 1s/step - loss: 16.7872 - val_loss: 3.4475\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.3871 - val_loss: 3.5359\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.7100 - val_loss: 3.6243\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.6171 - val_loss: 3.8008\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 14.4774 - val_loss: 3.9105\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 15.4921 - val_loss: 4.1809\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.1581 - val_loss: 4.3789\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.4931 - val_loss: 4.5408\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.9708 - val_loss: 4.6806\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.4514 - val_loss: 4.8256\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.3540 - val_loss: 5.0100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 17.2923 - val_loss: 2.3694\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 16.9726 - val_loss: 2.5525\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.6547 - val_loss: 2.7662\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.3663 - val_loss: 3.0335\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.2856 - val_loss: 3.1798\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.7226 - val_loss: 3.3920\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.3066 - val_loss: 3.5466\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.8560 - val_loss: 3.7027\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 11.8786 - val_loss: 3.8377\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3240 - val_loss: 3.9599\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.9650 - val_loss: 4.1000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 12.0510 - val_loss: 2.6473\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7933 - val_loss: 2.6925\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.6703 - val_loss: 2.7647\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.9688 - val_loss: 2.8166\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.9773 - val_loss: 2.8103\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3728 - val_loss: 2.8853\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3067 - val_loss: 2.9381\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.5058 - val_loss: 3.0012\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.0253 - val_loss: 3.0315\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.0570 - val_loss: 3.0520\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.9659 - val_loss: 3.0785\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 22s 1s/step - loss: 13.4245 - val_loss: 3.4671\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.1476 - val_loss: 3.4703\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.9359 - val_loss: 3.4744\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 10.8205 - val_loss: 3.4805\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.5554 - val_loss: 3.4732\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.4736 - val_loss: 3.5077\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.2929 - val_loss: 3.5331\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.7764 - val_loss: 3.5632\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.2321 - val_loss: 3.5649\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.2770 - val_loss: 3.5828\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.1362 - val_loss: 3.6159\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 15.9145 - val_loss: 15.8910\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 16.3032 - val_loss: 14.9150\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 13.8253 - val_loss: 14.0738\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.4442 - val_loss: 13.2945\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.8509 - val_loss: 12.5004\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.7702 - val_loss: 11.9870\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 10.4360 - val_loss: 11.3910\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.4048 - val_loss: 10.8539\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8609 - val_loss: 10.4325\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.6973 - val_loss: 9.9469\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9030 - val_loss: 9.5425\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.4221 - val_loss: 9.1087\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4835 - val_loss: 8.7773\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.4506 - val_loss: 8.4977\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.2279 - val_loss: 8.2301\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.1993 - val_loss: 7.9275\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.3864 - val_loss: 7.7031\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.5482 - val_loss: 7.4708\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.6398 - val_loss: 7.3538\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.1040 - val_loss: 7.3055\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.3871 - val_loss: 7.1732\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.4908 - val_loss: 7.1233\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.8174 - val_loss: 7.1871\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.7793 - val_loss: 7.2099\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.1459 - val_loss: 7.2104\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.4763 - val_loss: 7.1160\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.3511 - val_loss: 7.1077\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.1803 - val_loss: 7.1468\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.1812 - val_loss: 7.1766\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.6170 - val_loss: 6.9998\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.0288 - val_loss: 6.8066\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.7385 - val_loss: 6.6413\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.4871 - val_loss: 6.5289\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.9600 - val_loss: 6.7134\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.7341 - val_loss: 6.7770\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.2803 - val_loss: 6.7514\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4382 - val_loss: 6.5726\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.0172 - val_loss: 6.3745\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.7328 - val_loss: 6.2917\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.6954 - val_loss: 6.2366\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.1846 - val_loss: 6.2775\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.4953 - val_loss: 6.3466\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5016 - val_loss: 6.3841\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.9278 - val_loss: 6.4794\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.8541 - val_loss: 6.2933\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.8304 - val_loss: 6.1245\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.6401 - val_loss: 6.0052\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.6046 - val_loss: 5.9437\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.9944 - val_loss: 5.9388\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.9660 - val_loss: 5.9500\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.1391 - val_loss: 5.9244\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.3914 - val_loss: 5.9895\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0151 - val_loss: 6.2137\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.0958 - val_loss: 6.2451\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.0491 - val_loss: 6.3237\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.9049 - val_loss: 6.3374\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.1585 - val_loss: 6.3839\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.1307 - val_loss: 6.4458\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.7112 - val_loss: 6.5297\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4914 - val_loss: 6.6211\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.4908 - val_loss: 6.6647\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 9.7084 - val_loss: 10.4344\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.1017 - val_loss: 10.1699\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8898 - val_loss: 9.9534\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1323 - val_loss: 9.7277\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6627 - val_loss: 9.4780\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.4966 - val_loss: 9.3309\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.8505 - val_loss: 9.2199\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.5230 - val_loss: 9.1298\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.3032 - val_loss: 9.0429\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.1759 - val_loss: 8.9547\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.6514 - val_loss: 8.9110\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.4953 - val_loss: 8.8632\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.7138 - val_loss: 8.8248\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.6337 - val_loss: 8.7922\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.6110 - val_loss: 8.7722\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.0331 - val_loss: 8.7951\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.0158 - val_loss: 8.8124\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.4330 - val_loss: 8.8319\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.2943 - val_loss: 8.8572\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.9430 - val_loss: 8.8637\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.4983 - val_loss: 8.9089\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.6990 - val_loss: 8.9955\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.3730 - val_loss: 9.0754\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0234 - val_loss: 9.1348\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.4596 - val_loss: 9.1742\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 29s 2s/step - loss: 8.5732 - val_loss: 10.7487\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.2734 - val_loss: 10.0529\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.7472 - val_loss: 9.5466\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1832 - val_loss: 9.0561\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.4450 - val_loss: 8.5528\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.1111 - val_loss: 8.1717\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4977 - val_loss: 7.8186\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.2246 - val_loss: 7.5835\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6880 - val_loss: 7.3680\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.5593 - val_loss: 7.1483\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.5114 - val_loss: 6.9474\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.2887 - val_loss: 6.7973\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.0648 - val_loss: 6.6453\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.9423 - val_loss: 6.5532\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8743 - val_loss: 6.5535\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7193 - val_loss: 6.5787\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.0171 - val_loss: 6.5157\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.3418 - val_loss: 6.5203\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.5941 - val_loss: 6.5022\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.7414 - val_loss: 6.4202\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.3876 - val_loss: 6.3839\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.9376 - val_loss: 6.3728\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.6704 - val_loss: 6.3537\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.1666 - val_loss: 6.2945\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.6300 - val_loss: 6.2181\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7641 - val_loss: 6.2268\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.7334 - val_loss: 6.2323\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3190 - val_loss: 6.2460\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.5708 - val_loss: 6.1522\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8217 - val_loss: 6.0698\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.9694 - val_loss: 6.0452\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.4684 - val_loss: 6.0349\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9251 - val_loss: 6.0042\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.7130 - val_loss: 6.0014\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.1229 - val_loss: 5.9571\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.3946 - val_loss: 5.9281\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.1333 - val_loss: 5.9118\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.2974 - val_loss: 5.9737\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.5624 - val_loss: 5.9516\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.4820 - val_loss: 5.9993\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.3516 - val_loss: 5.9880\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.9789 - val_loss: 5.8981\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5244 - val_loss: 5.8690\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.3310 - val_loss: 5.8051\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.2479 - val_loss: 5.7261\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5764 - val_loss: 5.6909\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.1831 - val_loss: 5.8267\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.8301 - val_loss: 5.8729\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.3791 - val_loss: 5.9171\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.3264 - val_loss: 5.8966\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.2445 - val_loss: 5.7568\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.9444 - val_loss: 5.6323\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.2933 - val_loss: 5.6270\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.8572 - val_loss: 5.7371\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 2.9384 - val_loss: 5.8441\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.9138 - val_loss: 5.8460\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.3847 - val_loss: 5.7485\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.0167 - val_loss: 5.5426\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.5726 - val_loss: 5.3793\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.7916 - val_loss: 5.3132\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.0534 - val_loss: 5.2955\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.8048 - val_loss: 5.2200\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5047 - val_loss: 5.3366\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.0529 - val_loss: 5.2275\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4973 - val_loss: 5.2142\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.3747 - val_loss: 5.1806\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0244 - val_loss: 5.2265\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.6509 - val_loss: 5.2019\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.6824 - val_loss: 5.0020\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.2852 - val_loss: 4.8315\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.8799 - val_loss: 4.7787\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.1540 - val_loss: 4.7625\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4306 - val_loss: 4.8293\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1185 - val_loss: 4.7866\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.2960 - val_loss: 4.7170\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3182 - val_loss: 4.5927\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.9465 - val_loss: 4.4665\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.1151 - val_loss: 4.4275\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0290 - val_loss: 4.3330\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1006 - val_loss: 4.3088\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.4577 - val_loss: 4.3148\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.6994 - val_loss: 4.1757\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.9418 - val_loss: 4.0467\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.1387 - val_loss: 3.8845\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9842 - val_loss: 3.8194\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6102 - val_loss: 3.9714\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7851 - val_loss: 4.0154\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.6265 - val_loss: 4.0644\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.1416 - val_loss: 3.9775\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7262 - val_loss: 3.8673\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.4848 - val_loss: 3.8402\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.8675 - val_loss: 3.8913\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.6734 - val_loss: 3.9214\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.6776 - val_loss: 4.0105\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.9775 - val_loss: 4.0520\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 12.9041 - val_loss: 10.5460\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.2643 - val_loss: 9.8913\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 10.3533 - val_loss: 9.4364\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.7549 - val_loss: 9.0475\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.6564 - val_loss: 8.6452\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.0956 - val_loss: 8.3131\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 9.2196 - val_loss: 8.0094\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.2471 - val_loss: 7.7651\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.1760 - val_loss: 7.5670\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 8.7839 - val_loss: 7.4066\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2493 - val_loss: 7.2844\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.4669 - val_loss: 7.1662\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.9563 - val_loss: 7.0667\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5694 - val_loss: 7.0104\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 9.0492 - val_loss: 6.9758\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5602 - val_loss: 6.9525\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.9199 - val_loss: 6.9211\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.5374 - val_loss: 6.8890\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.5071 - val_loss: 6.8727\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.9233 - val_loss: 6.8685\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9550 - val_loss: 6.8724\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.6559 - val_loss: 6.8962\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.1848 - val_loss: 6.9273\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.7064 - val_loss: 6.9388\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.3484 - val_loss: 6.9589\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.4633 - val_loss: 7.0036\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.0003 - val_loss: 7.0663\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6363 - val_loss: 7.1276\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.8652 - val_loss: 7.1654\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6908 - val_loss: 7.2381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 9.1782 - val_loss: 4.6570\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.7141 - val_loss: 5.0607\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.2101 - val_loss: 5.4040\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.5958 - val_loss: 5.6469\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6981 - val_loss: 5.8545\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.9720 - val_loss: 6.0381\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.2037 - val_loss: 6.1069\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.9014 - val_loss: 6.1407\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.5120 - val_loss: 6.1609\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.9408 - val_loss: 6.1453\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7527 - val_loss: 6.0827\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 9.5890 - val_loss: 6.8118\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.4262 - val_loss: 6.7773\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 9.5658 - val_loss: 6.6857\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 8.6647 - val_loss: 6.6088\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3014 - val_loss: 6.5459\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.3804 - val_loss: 6.5152\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 7.7030 - val_loss: 6.4129\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.0036 - val_loss: 6.3273\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7932 - val_loss: 6.2683\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6773 - val_loss: 6.1496\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.9797 - val_loss: 6.0602\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.0676 - val_loss: 6.0285\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.2036 - val_loss: 5.9641\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.8393 - val_loss: 5.8669\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.2670 - val_loss: 5.8028\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.0484 - val_loss: 5.7708\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.0140 - val_loss: 5.7493\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.5807 - val_loss: 5.7275\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.8556 - val_loss: 5.7047\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.9696 - val_loss: 5.6908\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.0287 - val_loss: 5.7052\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.1316 - val_loss: 5.7087\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.2824 - val_loss: 5.7138\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.8568 - val_loss: 5.7013\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.2349 - val_loss: 5.7003\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.6711 - val_loss: 5.7214\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.3690 - val_loss: 5.7756\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.7493 - val_loss: 5.7823\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.8102 - val_loss: 5.7970\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9718 - val_loss: 5.8159\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 7.2742 - val_loss: 4.8236\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.1979 - val_loss: 4.9345\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.1804 - val_loss: 5.0579\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.6094 - val_loss: 5.2187\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.2822 - val_loss: 5.4033\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.4687 - val_loss: 5.5203\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.1542 - val_loss: 5.5765\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.2275 - val_loss: 5.6292\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.0724 - val_loss: 5.6515\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.5529 - val_loss: 5.6850\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.4592 - val_loss: 5.7052\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 7.2697 - val_loss: 5.9666\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.9329 - val_loss: 5.9742\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.7114 - val_loss: 5.9847\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 7.3390 - val_loss: 6.0299\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 6.3428 - val_loss: 6.0658\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.6734 - val_loss: 6.1058\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.4160 - val_loss: 6.1492\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 6.2299 - val_loss: 6.1984\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 5.8911 - val_loss: 6.2596\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3630 - val_loss: 6.3284\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.9981 - val_loss: 6.3866\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 9.4615 - val_loss: 72.8858\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.6246 - val_loss: 70.6274\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.8146 - val_loss: 68.4799\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8540 - val_loss: 66.6469\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5804 - val_loss: 64.8465\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.0880 - val_loss: 63.7700\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.8812 - val_loss: 62.9380\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.3371 - val_loss: 62.2810\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.1521 - val_loss: 61.5010\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.8503 - val_loss: 60.5323\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.7968 - val_loss: 59.8170\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.1996 - val_loss: 59.1760\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.6381 - val_loss: 58.4632\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.1052 - val_loss: 57.9157\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.1219 - val_loss: 57.4023\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.3408 - val_loss: 56.8592\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.1676 - val_loss: 56.2653\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.7260 - val_loss: 55.9906\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.8445 - val_loss: 55.7850\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9001 - val_loss: 55.3858\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.2314 - val_loss: 55.4235\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.1764 - val_loss: 55.3951\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.0324 - val_loss: 55.0609\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 3.2881 - val_loss: 55.1518\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5616 - val_loss: 55.2259\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.0450 - val_loss: 55.4455\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.0579 - val_loss: 55.4432\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.1468 - val_loss: 55.4918\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.8997 - val_loss: 55.5118\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.0838 - val_loss: 55.2977\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.4966 - val_loss: 54.8539\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.7766 - val_loss: 55.0730\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.7717 - val_loss: 55.6582\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 2.5035 - val_loss: 56.2495\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.4903 - val_loss: 56.7630\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.0228 - val_loss: 56.8832\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.0618 - val_loss: 57.3453\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.4791 - val_loss: 57.5183\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.3432 - val_loss: 57.3341\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.2154 - val_loss: 57.8097\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6010 - val_loss: 57.6649\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 31s 1s/step - loss: 6.9468 - val_loss: 43.5166\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.5736 - val_loss: 43.7377\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.5740 - val_loss: 43.8709\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.0951 - val_loss: 43.9588\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.9202 - val_loss: 43.7972\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.6590 - val_loss: 44.0764\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.0270 - val_loss: 44.1716\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.1011 - val_loss: 44.3882\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.0045 - val_loss: 44.5406\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.5466 - val_loss: 44.4695\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.4990 - val_loss: 44.6236\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 7.8608 - val_loss: 54.8375\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.7140 - val_loss: 55.0662\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3502 - val_loss: 55.3951\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.6795 - val_loss: 55.6349\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.2085 - val_loss: 55.7494\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2256 - val_loss: 56.0744\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.0102 - val_loss: 56.3179\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.0840 - val_loss: 56.5865\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9053 - val_loss: 56.7216\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.9105 - val_loss: 56.9025\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.0241 - val_loss: 57.0955\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 37s 1s/step - loss: 9.9781 - val_loss: 58.7608\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.9794 - val_loss: 58.9700\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.0743 - val_loss: 59.5604\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.0910 - val_loss: 59.9470\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.5593 - val_loss: 60.2017\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9487 - val_loss: 60.4885\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.3070 - val_loss: 60.6645\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.7188 - val_loss: 60.7770\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.8418 - val_loss: 60.8588\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.1851 - val_loss: 60.9837\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6887 - val_loss: 61.0495\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 31s 1s/step - loss: 8.9771 - val_loss: 14.0813\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.4027 - val_loss: 12.4641\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2221 - val_loss: 11.3924\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3384 - val_loss: 10.5430\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.4762 - val_loss: 10.0166\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.1848 - val_loss: 9.6359\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.9828 - val_loss: 9.2038\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.6282 - val_loss: 8.8876\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7453 - val_loss: 8.6017\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.5834 - val_loss: 8.2619\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.7823 - val_loss: 8.2183\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.2685 - val_loss: 8.4886\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.2084 - val_loss: 8.6120\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.7129 - val_loss: 8.7395\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 4.9698 - val_loss: 8.7426\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.9560 - val_loss: 8.4776\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.4238 - val_loss: 8.6166\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3368 - val_loss: 8.7438\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.9968 - val_loss: 8.9016\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.1119 - val_loss: 9.0352\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.7907 - val_loss: 8.9939\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 35s 1s/step - loss: 8.3338 - val_loss: 11.2374\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.8642 - val_loss: 10.1052\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.5754 - val_loss: 9.3110\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.4927 - val_loss: 8.7104\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7333 - val_loss: 8.1451\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.2673 - val_loss: 7.6848\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.6106 - val_loss: 7.2827\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.2910 - val_loss: 7.0090\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.0592 - val_loss: 6.7017\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.9419 - val_loss: 6.4658\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.7276 - val_loss: 6.3500\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.3737 - val_loss: 6.3676\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.6460 - val_loss: 6.1565\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.3170 - val_loss: 6.0223\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.2628 - val_loss: 5.8449\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.0274 - val_loss: 5.7570\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.8493 - val_loss: 5.9789\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.0048 - val_loss: 6.1253\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.6306 - val_loss: 6.2083\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.1507 - val_loss: 6.2424\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.4310 - val_loss: 6.2182\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.3647 - val_loss: 6.1507\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3850 - val_loss: 6.2520\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.2959 - val_loss: 6.4284\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.9899 - val_loss: 6.5513\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.2905 - val_loss: 6.7626\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 33s 1s/step - loss: 6.9507 - val_loss: 8.9008\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.1108 - val_loss: 8.8508\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.5574 - val_loss: 8.9089\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.3013 - val_loss: 9.0422\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.4365 - val_loss: 9.1197\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.9770 - val_loss: 9.2471\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.7736 - val_loss: 9.2759\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.7094 - val_loss: 9.3074\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.6338 - val_loss: 9.1892\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.9826 - val_loss: 9.0416\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 4.5341 - val_loss: 9.1744\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.7817 - val_loss: 9.4273\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 33s 1s/step - loss: 9.7280 - val_loss: 10.8854\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1556 - val_loss: 9.4301\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2929 - val_loss: 8.4508\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.0281 - val_loss: 7.6082\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.2388 - val_loss: 6.9767\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.2026 - val_loss: 6.3197\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2647 - val_loss: 5.8349\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.7551 - val_loss: 5.4236\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.5162 - val_loss: 5.0669\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.4278 - val_loss: 4.7207\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.6350 - val_loss: 4.5811\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.0205 - val_loss: 4.5269\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0595 - val_loss: 4.3689\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.3226 - val_loss: 4.2403\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7667 - val_loss: 4.1548\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.6498 - val_loss: 4.1422\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.4908 - val_loss: 4.3626\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.4640 - val_loss: 4.4762\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.1941 - val_loss: 4.6912\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.4913 - val_loss: 4.9693\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.4262 - val_loss: 5.0960\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.1105 - val_loss: 5.1834\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.4191 - val_loss: 5.0673\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.4980 - val_loss: 4.9702\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.2160 - val_loss: 4.8930\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.2932 - val_loss: 5.0237\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Executing 3df87a13 iter 6\n",
      "Train predicting  1 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 37s 1s/step - loss: 20.4064 - val_loss: 8.3343\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 19.4877 - val_loss: 8.2322\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 18.3136 - val_loss: 8.1216\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 17.8667 - val_loss: 7.9915\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 18.6591 - val_loss: 7.8428\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 16.0547 - val_loss: 7.7136\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 16.1640 - val_loss: 7.5632\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.6698 - val_loss: 7.4150\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 15.4496 - val_loss: 7.2991\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 15.0052 - val_loss: 7.1924\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.3878 - val_loss: 7.0790\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.6572 - val_loss: 6.9707\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.8594 - val_loss: 6.8495\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.1995 - val_loss: 6.7447\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.9344 - val_loss: 6.6418\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.5867 - val_loss: 6.5325\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 11.8499 - val_loss: 6.4323\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 11.5458 - val_loss: 6.3303\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 11.8998 - val_loss: 6.2269\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 11.8689 - val_loss: 6.1540\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 11.7051 - val_loss: 6.0883\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 11.0720 - val_loss: 6.0262\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.9212 - val_loss: 5.9583\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 10.1737 - val_loss: 5.8995\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.8780 - val_loss: 5.8450\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 9.5850 - val_loss: 5.7988\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.8460 - val_loss: 5.7461\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 9.3762 - val_loss: 5.6864\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 9.0578 - val_loss: 5.6311\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.2315 - val_loss: 5.5856\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 9.4476 - val_loss: 5.5450\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.7289 - val_loss: 5.4878\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 8.5032 - val_loss: 5.4407\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.4679 - val_loss: 5.4060\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.6177 - val_loss: 5.3688\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.3468 - val_loss: 5.3311\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.2376 - val_loss: 5.2842\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.2277 - val_loss: 5.2490\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.8183 - val_loss: 5.2128\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.0408 - val_loss: 5.1809\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.3848 - val_loss: 5.1597\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.3550 - val_loss: 5.1349\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.7822 - val_loss: 5.1076\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 5.9380 - val_loss: 5.0824\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 7.1790 - val_loss: 5.0786\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.1924 - val_loss: 5.0762\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.5190 - val_loss: 5.0715\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.1791 - val_loss: 5.0604\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.0842 - val_loss: 5.0525\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.0640 - val_loss: 5.0366\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.7444 - val_loss: 5.0238\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.3546 - val_loss: 5.0340\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.5503 - val_loss: 5.0415\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 6.2252 - val_loss: 5.0329\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 6.3068 - val_loss: 5.0111\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.5719 - val_loss: 4.9911\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.4009 - val_loss: 4.9685\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.4038 - val_loss: 4.9481\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.6931 - val_loss: 4.9445\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.9035 - val_loss: 4.9305\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.7214 - val_loss: 4.9116\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.0241 - val_loss: 4.8964\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.2838 - val_loss: 4.8894\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.7614 - val_loss: 4.8671\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.8690 - val_loss: 4.8590\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 6.1108 - val_loss: 4.8321\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.3503 - val_loss: 4.8116\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.6308 - val_loss: 4.8108\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.5103 - val_loss: 4.8113\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.1045 - val_loss: 4.7878\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.5238 - val_loss: 4.7613\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.7606 - val_loss: 4.7565\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.7541 - val_loss: 4.7441\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.6832 - val_loss: 4.7455\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.1085 - val_loss: 4.7600\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.8103 - val_loss: 4.7646\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.9231 - val_loss: 4.7573\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.9197 - val_loss: 4.7445\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.6334 - val_loss: 4.7169\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.3434 - val_loss: 4.7041\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.5832 - val_loss: 4.6958\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.6114 - val_loss: 4.6856\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.5803 - val_loss: 4.6929\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6839 - val_loss: 4.6868\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.1069 - val_loss: 4.6602\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.2070 - val_loss: 4.6382\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.2102 - val_loss: 4.6421\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.5648 - val_loss: 4.6421\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.2127 - val_loss: 4.6175\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.9412 - val_loss: 4.6038\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.1497 - val_loss: 4.5960\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.0807 - val_loss: 4.6020\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.4586 - val_loss: 4.6021\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.0794 - val_loss: 4.5933\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.3574 - val_loss: 4.5880\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.7892 - val_loss: 4.5972\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.8772 - val_loss: 4.5865\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.6522 - val_loss: 4.5808\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.9968 - val_loss: 4.5673\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.0046 - val_loss: 4.5703\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.4684 - val_loss: 4.5674\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.6519 - val_loss: 4.5641\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.4572 - val_loss: 4.5737\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5924 - val_loss: 4.5882\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.3588 - val_loss: 4.5874\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5356 - val_loss: 4.6181\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.6496 - val_loss: 4.6718\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.3840 - val_loss: 4.6934\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.4303 - val_loss: 4.6861\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.6848 - val_loss: 4.6946\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5727 - val_loss: 4.7116\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.0513 - val_loss: 4.7521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  1 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 39s 1s/step - loss: 16.5278 - val_loss: 7.2229\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 16.6755 - val_loss: 7.1507\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.4011 - val_loss: 7.0751\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 16.1924 - val_loss: 6.9905\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 16.5220 - val_loss: 6.9137\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 15.0785 - val_loss: 6.8455\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.6917 - val_loss: 6.7669\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 16.1892 - val_loss: 6.6901\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 15.6999 - val_loss: 6.6120\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.9949 - val_loss: 6.5271\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.3739 - val_loss: 6.4607\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.4068 - val_loss: 6.3870\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.7545 - val_loss: 6.3056\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 15.2456 - val_loss: 6.2264\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.3488 - val_loss: 6.1325\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 15.0201 - val_loss: 6.0365\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.7112 - val_loss: 5.9224\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 14.3825 - val_loss: 5.8355\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 14.8082 - val_loss: 5.7227\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 14.5592 - val_loss: 5.6118\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 14.4949 - val_loss: 5.5179\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 14.2464 - val_loss: 5.4352\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 13.4052 - val_loss: 5.3509\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 13.8380 - val_loss: 5.2685\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 13.6100 - val_loss: 5.1846\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 13.0497 - val_loss: 5.1179\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 13.4781 - val_loss: 5.0345\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 13.0352 - val_loss: 4.9618\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 12.7793 - val_loss: 4.8791\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 12.5580 - val_loss: 4.8062\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.9867 - val_loss: 4.7463\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 12.0926 - val_loss: 4.6956\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 11.8900 - val_loss: 4.6475\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 11.1300 - val_loss: 4.5955\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 11.2600 - val_loss: 4.5467\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 11.0797 - val_loss: 4.5139\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 10.5588 - val_loss: 4.4870\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 10.2302 - val_loss: 4.4580\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 10.5482 - val_loss: 4.4154\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.7217 - val_loss: 4.3901\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 10.2431 - val_loss: 4.3617\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.5189 - val_loss: 4.3555\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.1793 - val_loss: 4.3435\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.8994 - val_loss: 4.3240\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.3014 - val_loss: 4.3178\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.2268 - val_loss: 4.3106\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.5370 - val_loss: 4.3174\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.2621 - val_loss: 4.3357\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.4701 - val_loss: 4.3320\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.5651 - val_loss: 4.3366\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.1858 - val_loss: 4.3352\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.4201 - val_loss: 4.3275\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.7282 - val_loss: 4.3047\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.5726 - val_loss: 4.3087\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.3265 - val_loss: 4.3145\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8603 - val_loss: 4.3540\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.0293 - val_loss: 4.3892\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.8086 - val_loss: 4.4146\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.3829 - val_loss: 4.4513\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.4080 - val_loss: 4.4714\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.0638 - val_loss: 4.4951\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.2943 - val_loss: 4.5387\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.9073 - val_loss: 4.5911\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  1 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 38s 1s/step - loss: 16.2104 - val_loss: 11.7218\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 16.0028 - val_loss: 11.2810\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 14.3183 - val_loss: 10.8233\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 15.2628 - val_loss: 10.4024\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.5462 - val_loss: 9.9807\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.3217 - val_loss: 9.6877\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.5875 - val_loss: 9.3521\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.5074 - val_loss: 9.0682\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.2090 - val_loss: 8.7880\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.4953 - val_loss: 8.4974\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.5428 - val_loss: 8.2474\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.4502 - val_loss: 8.0172\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.9388 - val_loss: 7.7712\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.1795 - val_loss: 7.5592\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 11.3475 - val_loss: 7.3542\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.9837 - val_loss: 7.1762\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 11.9019 - val_loss: 6.9705\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 10.2343 - val_loss: 6.8150\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 10.7920 - val_loss: 6.6639\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.7818 - val_loss: 6.5130\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 10.2687 - val_loss: 6.3937\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.6997 - val_loss: 6.3140\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.8759 - val_loss: 6.2097\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.0000 - val_loss: 6.1362\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.3163 - val_loss: 6.0536\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.8710 - val_loss: 5.9952\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.8446 - val_loss: 5.9207\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.8905 - val_loss: 5.8636\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.1642 - val_loss: 5.8149\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.3691 - val_loss: 5.7563\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.5617 - val_loss: 5.7185\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.0349 - val_loss: 5.6689\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.5590 - val_loss: 5.6475\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.1105 - val_loss: 5.6431\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.5842 - val_loss: 5.6312\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.8183 - val_loss: 5.6427\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 7.5987 - val_loss: 5.6611\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.0638 - val_loss: 5.6628\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.7982 - val_loss: 5.6463\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.6149 - val_loss: 5.6569\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.5779 - val_loss: 5.6598\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.5091 - val_loss: 5.6822\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.4833 - val_loss: 5.6844\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.9237 - val_loss: 5.6687\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.2643 - val_loss: 5.6537\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  1 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 37s 1s/step - loss: 23.4355 - val_loss: 6.0289\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 22.3014 - val_loss: 5.9076\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 18.7359 - val_loss: 5.7892\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 18.6855 - val_loss: 5.6740\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 17.1339 - val_loss: 5.5779\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.1573 - val_loss: 5.4996\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 16.0825 - val_loss: 5.4141\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.1159 - val_loss: 5.3343\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 15.0104 - val_loss: 5.2527\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.5441 - val_loss: 5.1773\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.3190 - val_loss: 5.1177\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.8094 - val_loss: 5.0597\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.1644 - val_loss: 5.0174\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.1955 - val_loss: 4.9855\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0898 - val_loss: 4.9571\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.6397 - val_loss: 4.9226\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 11.1249 - val_loss: 4.8796\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.0371 - val_loss: 4.8511\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.0690 - val_loss: 4.8171\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.4635 - val_loss: 4.7918\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.5608 - val_loss: 4.7725\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.7451 - val_loss: 4.7570\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.2313 - val_loss: 4.7411\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.9860 - val_loss: 4.7253\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.2798 - val_loss: 4.7169\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.7256 - val_loss: 4.7093\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.1478 - val_loss: 4.7032\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.8538 - val_loss: 4.6938\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.1234 - val_loss: 4.6857\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.2818 - val_loss: 4.6773\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.1722 - val_loss: 4.6749\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.7783 - val_loss: 4.6681\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.2107 - val_loss: 4.6627\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.9462 - val_loss: 4.6571\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.8258 - val_loss: 4.6356\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.3695 - val_loss: 4.6178\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.4863 - val_loss: 4.6066\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.2157 - val_loss: 4.5909\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.9393 - val_loss: 4.5775\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.7310 - val_loss: 4.5974\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.8548 - val_loss: 4.6143\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.6301 - val_loss: 4.6365\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.3298 - val_loss: 4.6514\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.1962 - val_loss: 4.6608\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.4363 - val_loss: 4.6618\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.6221 - val_loss: 4.6714\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.4691 - val_loss: 4.7117\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.3160 - val_loss: 4.7580\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.8656 - val_loss: 4.7797\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 36s 1s/step - loss: 7.4203 - val_loss: 10.9884\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.5958 - val_loss: 11.4083\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.8262 - val_loss: 11.6915\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7939 - val_loss: 11.8452\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.5485 - val_loss: 12.1729\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.1747 - val_loss: 12.5097\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.1492 - val_loss: 12.7490\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.3832 - val_loss: 12.9760\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.3548 - val_loss: 13.1791\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.7810 - val_loss: 13.2992\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5919 - val_loss: 13.5409\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 241s 2s/step - loss: 5.7248 - val_loss: 21.7386\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.7420 - val_loss: 21.4970\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.6254 - val_loss: 21.3428\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.8913 - val_loss: 21.0745\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.5534 - val_loss: 20.9429\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.4072 - val_loss: 20.7193\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.4568 - val_loss: 20.4954\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.3617 - val_loss: 20.4061\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.0590 - val_loss: 20.3404\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.0321 - val_loss: 20.2200\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8987 - val_loss: 20.0936\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.7028 - val_loss: 20.0427\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.6221 - val_loss: 20.0105\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.4793 - val_loss: 19.9282\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.2186 - val_loss: 19.9024\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.3545 - val_loss: 19.8900\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 4.1313 - val_loss: 19.8874\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.1612 - val_loss: 19.8290\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.1533 - val_loss: 19.8223\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.9923 - val_loss: 19.7783\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.7392 - val_loss: 19.7911\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.0504 - val_loss: 19.6879\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 3.8329 - val_loss: 19.6960\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.4361 - val_loss: 19.7313\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.4596 - val_loss: 19.7638\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 3.4776 - val_loss: 19.7414\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 3.5370 - val_loss: 19.6717\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.4338 - val_loss: 19.5967\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.3815 - val_loss: 19.6056\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.1642 - val_loss: 19.6545\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.2364 - val_loss: 19.7057\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.1240 - val_loss: 19.7401\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.9536 - val_loss: 19.8197\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 3.2326 - val_loss: 19.8263\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 3.0047 - val_loss: 19.8855\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.8567 - val_loss: 19.9155\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.8181 - val_loss: 19.8593\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.8660 - val_loss: 19.8183\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  2 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 6.3412 - val_loss: 20.9141\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.0070 - val_loss: 20.6583\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.0760 - val_loss: 20.5371\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.3245 - val_loss: 20.3870\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.9224 - val_loss: 20.4367\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.0859 - val_loss: 20.4297\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.9137 - val_loss: 20.4498\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.5152 - val_loss: 20.5295\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.7791 - val_loss: 20.6099\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.4463 - val_loss: 20.5311\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.4208 - val_loss: 20.5510\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.6688 - val_loss: 20.6089\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.0056 - val_loss: 20.6329\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.0370 - val_loss: 20.6269\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Train predicting  2 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 6.8834 - val_loss: 22.6902\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.3928 - val_loss: 22.5055\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.1327 - val_loss: 22.5576\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3909 - val_loss: 22.3197\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.3286 - val_loss: 22.2245\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.3443 - val_loss: 21.8950\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9843 - val_loss: 21.5556\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.8725 - val_loss: 21.4409\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.8055 - val_loss: 21.3894\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.8519 - val_loss: 21.2799\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.0894 - val_loss: 21.0492\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.6423 - val_loss: 21.0198\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.0903 - val_loss: 20.8397\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.3521 - val_loss: 20.7116\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.5358 - val_loss: 20.5918\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5343 - val_loss: 20.3983\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6728 - val_loss: 20.1841\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.7060 - val_loss: 20.1524\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6566 - val_loss: 20.1657\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.3256 - val_loss: 20.2220\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.4992 - val_loss: 20.3312\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.2371 - val_loss: 20.2945\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.6618 - val_loss: 20.3862\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.8693 - val_loss: 20.4787\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.0770 - val_loss: 20.6530\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.7317 - val_loss: 20.7031\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.0967 - val_loss: 20.7448\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.9260 - val_loss: 20.6376\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  3 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 13.7674 - val_loss: 11.1813\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 12.1664 - val_loss: 10.6434\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.8677 - val_loss: 10.1874\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.8436 - val_loss: 9.7244\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.2451 - val_loss: 9.4154\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 13.1795 - val_loss: 9.0687\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.2121 - val_loss: 8.7704\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.4883 - val_loss: 8.4655\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.3683 - val_loss: 8.1345\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.1344 - val_loss: 7.8333\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.5436 - val_loss: 7.5404\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.1813 - val_loss: 7.2950\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.2088 - val_loss: 7.1709\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.8857 - val_loss: 6.9425\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.0003 - val_loss: 6.7574\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.4827 - val_loss: 6.5630\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.8008 - val_loss: 6.3534\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6216 - val_loss: 6.1827\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 12.8304 - val_loss: 5.9615\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.4289 - val_loss: 5.8034\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.2888 - val_loss: 5.6946\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.0963 - val_loss: 5.5656\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.6481 - val_loss: 5.3530\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.7838 - val_loss: 5.1844\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.8860 - val_loss: 5.0585\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.9991 - val_loss: 4.9625\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.9675 - val_loss: 4.9144\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.1337 - val_loss: 4.8503\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.9683 - val_loss: 4.8101\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.3901 - val_loss: 4.7563\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.7574 - val_loss: 4.6926\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.8311 - val_loss: 4.5848\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.0582 - val_loss: 4.5312\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.7961 - val_loss: 4.4621\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.6184 - val_loss: 4.4023\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 6.3994 - val_loss: 4.3477\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 6.1313 - val_loss: 4.3426\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.4124 - val_loss: 4.3092\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.7361 - val_loss: 4.2896\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.0254 - val_loss: 4.2799\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.5042 - val_loss: 4.2342\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.9170 - val_loss: 4.1965\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.3667 - val_loss: 4.1802\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.3619 - val_loss: 4.1534\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.2699 - val_loss: 4.1600\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.1566 - val_loss: 4.1587\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.3348 - val_loss: 4.1782\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9134 - val_loss: 4.1965\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.1317 - val_loss: 4.1834\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.4734 - val_loss: 4.1559\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.8536 - val_loss: 4.0943\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.2711 - val_loss: 4.0208\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9390 - val_loss: 3.9803\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.7806 - val_loss: 3.9520\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.1942 - val_loss: 3.9476\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.7885 - val_loss: 3.9465\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 3.9078 - val_loss: 3.9486\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.0573 - val_loss: 3.9137\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.2719 - val_loss: 3.9099\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.8450 - val_loss: 3.8473\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.3651 - val_loss: 3.8156\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9291 - val_loss: 3.8392\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.5128 - val_loss: 3.8479\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.5310 - val_loss: 3.8121\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.1313 - val_loss: 3.8116\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.4573 - val_loss: 3.8395\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.1640 - val_loss: 3.8001\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.0780 - val_loss: 3.7885\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.6002 - val_loss: 3.7630\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.8227 - val_loss: 3.7488\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.8608 - val_loss: 3.7367\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.3654 - val_loss: 3.7196\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.7671 - val_loss: 3.6560\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.7549 - val_loss: 3.6259\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.7916 - val_loss: 3.5650\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.7121 - val_loss: 3.5499\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.6633 - val_loss: 3.5352\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.0670 - val_loss: 3.5568\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.8043 - val_loss: 3.5696\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.6643 - val_loss: 3.5456\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.1136 - val_loss: 3.5055\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.1676 - val_loss: 3.5282\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.0067 - val_loss: 3.5391\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 2.7909 - val_loss: 3.5441\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.3561 - val_loss: 3.5494\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.7130 - val_loss: 3.5418\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9197 - val_loss: 3.5508\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.0613 - val_loss: 3.5326\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9682 - val_loss: 3.4990\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.6765 - val_loss: 3.4810\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.9663 - val_loss: 3.4624\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.8673 - val_loss: 3.4295\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.6098 - val_loss: 3.4485\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.5569 - val_loss: 3.5133\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 2.9126 - val_loss: 3.5709\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.3798 - val_loss: 3.6037\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.5090 - val_loss: 3.6840\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.0008 - val_loss: 3.7445\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.9959 - val_loss: 3.7678\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.8560 - val_loss: 3.7691\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 2.1864 - val_loss: 3.6813\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.9505 - val_loss: 3.6015\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  3 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 10.1424 - val_loss: 4.3946\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.7728 - val_loss: 4.3142\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.4334 - val_loss: 4.2370\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.6505 - val_loss: 4.1896\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.8734 - val_loss: 4.1428\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.7789 - val_loss: 4.0964\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.8513 - val_loss: 4.0679\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.2124 - val_loss: 4.0417\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.9978 - val_loss: 4.0116\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.5104 - val_loss: 3.9790\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7014 - val_loss: 3.9613\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.7485 - val_loss: 3.9676\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.2157 - val_loss: 3.9796\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.9676 - val_loss: 3.9643\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.0648 - val_loss: 3.9680\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.0948 - val_loss: 3.9735\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.0608 - val_loss: 3.9804\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.6261 - val_loss: 4.0099\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.7482 - val_loss: 4.0169\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.3578 - val_loss: 4.0350\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.0854 - val_loss: 4.0651\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  3 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 13.1740 - val_loss: 7.3199\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 12.2908 - val_loss: 7.1883\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 13.7930 - val_loss: 7.0909\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.8445 - val_loss: 7.0600\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 11.6335 - val_loss: 7.0109\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.1611 - val_loss: 6.9322\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.1468 - val_loss: 6.8288\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.8514 - val_loss: 6.7326\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.4396 - val_loss: 6.6489\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.1779 - val_loss: 6.5585\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.7733 - val_loss: 6.4988\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.5606 - val_loss: 6.5003\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7530 - val_loss: 6.5259\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.0994 - val_loss: 6.4807\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.0056 - val_loss: 6.4545\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.6092 - val_loss: 6.4170\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.3766 - val_loss: 6.3768\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.5529 - val_loss: 6.3835\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.8544 - val_loss: 6.3436\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.4745 - val_loss: 6.3229\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.1842 - val_loss: 6.3530\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.6394 - val_loss: 6.3654\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.5271 - val_loss: 6.3438\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.6191 - val_loss: 6.3124\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.0744 - val_loss: 6.2781\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.9534 - val_loss: 6.2447\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.7760 - val_loss: 6.2292\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.3361 - val_loss: 6.1846\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.5946 - val_loss: 6.2177\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.6756 - val_loss: 6.2566\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.7577 - val_loss: 6.2238\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.7761 - val_loss: 6.1837\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.8582 - val_loss: 6.2198\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.9204 - val_loss: 6.2515\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.1844 - val_loss: 6.3199\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.4148 - val_loss: 6.3195\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.3479 - val_loss: 6.3209\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.5045 - val_loss: 6.4234\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.4317 - val_loss: 6.4693\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.3404 - val_loss: 6.4880\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.7187 - val_loss: 6.4591\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.1516 - val_loss: 6.5090\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  3 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 11.3040 - val_loss: 6.7647\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.9076 - val_loss: 6.8022\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.9526 - val_loss: 6.7812\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.0942 - val_loss: 6.7505\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0027 - val_loss: 6.7095\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.4395 - val_loss: 6.6756\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.1514 - val_loss: 6.7201\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5199 - val_loss: 6.7449\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.9470 - val_loss: 6.7687\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 12.6414 - val_loss: 6.7429\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.6868 - val_loss: 6.7120\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.2837 - val_loss: 6.7651\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.4952 - val_loss: 6.7624\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.8658 - val_loss: 6.6784\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.2921 - val_loss: 6.6027\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.4363 - val_loss: 6.5244\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6735 - val_loss: 6.4501\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.5251 - val_loss: 6.3933\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.9997 - val_loss: 6.3342\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.4221 - val_loss: 6.2902\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.2569 - val_loss: 6.2413\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.3231 - val_loss: 6.1581\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.9015 - val_loss: 6.0666\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 7.5589 - val_loss: 6.0039\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.4762 - val_loss: 5.9577\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.6802 - val_loss: 5.9308\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.4786 - val_loss: 5.8964\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.2746 - val_loss: 5.8640\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.6927 - val_loss: 5.8612\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.7488 - val_loss: 5.8650\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.3890 - val_loss: 5.8668\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.3848 - val_loss: 5.8510\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.4079 - val_loss: 5.8538\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.9508 - val_loss: 5.8660\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.4682 - val_loss: 5.8769\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.8218 - val_loss: 5.8590\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.4240 - val_loss: 5.8783\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.2131 - val_loss: 5.8907\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.5586 - val_loss: 5.8587\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.1416 - val_loss: 5.8430\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.8346 - val_loss: 5.8341\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.0353 - val_loss: 5.8403\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.2727 - val_loss: 5.8399\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.4318 - val_loss: 5.8994\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.1247 - val_loss: 5.9223\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.8143 - val_loss: 5.9060\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.0355 - val_loss: 5.9196\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.9876 - val_loss: 5.9644\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.6944 - val_loss: 5.9764\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6318 - val_loss: 6.0144\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.1359 - val_loss: 6.0121\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  4 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 14.1579 - val_loss: 5.6577\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.2935 - val_loss: 5.4503\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.7444 - val_loss: 5.3282\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.7140 - val_loss: 5.2083\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.8103 - val_loss: 5.1135\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.8463 - val_loss: 5.0019\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.8649 - val_loss: 4.8882\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.4773 - val_loss: 4.7759\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 10.3248 - val_loss: 4.6443\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.7815 - val_loss: 4.5408\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.2620 - val_loss: 4.4254\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.7469 - val_loss: 4.2836\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.5889 - val_loss: 4.2624\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.2086 - val_loss: 4.2291\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.8602 - val_loss: 4.1355\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.2125 - val_loss: 4.0423\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 9.8708 - val_loss: 3.9611\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.9903 - val_loss: 3.8696\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.9275 - val_loss: 3.8371\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 9.4752 - val_loss: 3.7558\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 10.2151 - val_loss: 3.6268\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6116 - val_loss: 3.5304\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.1300 - val_loss: 3.4305\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6060 - val_loss: 3.3209\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.9099 - val_loss: 3.2475\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.0653 - val_loss: 3.1487\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.6415 - val_loss: 3.0774\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 9.6189 - val_loss: 3.0237\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.2117 - val_loss: 2.9701\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.1056 - val_loss: 2.9063\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.9616 - val_loss: 2.8440\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.6322 - val_loss: 2.8126\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.4330 - val_loss: 2.8277\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.0463 - val_loss: 2.8236\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.9251 - val_loss: 2.8322\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.0864 - val_loss: 2.7904\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.4963 - val_loss: 2.6794\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.5103 - val_loss: 2.6367\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.1190 - val_loss: 2.5880\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.7799 - val_loss: 2.5930\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.3397 - val_loss: 2.5751\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.7369 - val_loss: 2.5282\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 6.5365 - val_loss: 2.5536\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.1951 - val_loss: 2.5718\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.4435 - val_loss: 2.5584\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 6.6900 - val_loss: 2.5881\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.5002 - val_loss: 2.5924\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.7283 - val_loss: 2.5811\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.5896 - val_loss: 2.5542\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.3947 - val_loss: 2.5529\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.2645 - val_loss: 2.5614\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.4023 - val_loss: 2.5759\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  4 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 12.3734 - val_loss: 2.8372\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 11.8070 - val_loss: 2.7981\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.6190 - val_loss: 2.8113\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.4414 - val_loss: 2.8273\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.5801 - val_loss: 2.8211\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.6615 - val_loss: 2.8023\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.8563 - val_loss: 2.7871\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.2475 - val_loss: 2.7782\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.4425 - val_loss: 2.7616\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.9494 - val_loss: 2.7691\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.5159 - val_loss: 2.7675\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.6770 - val_loss: 2.7504\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.2218 - val_loss: 2.7668\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.2441 - val_loss: 2.7642\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.8489 - val_loss: 2.7375\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.9604 - val_loss: 2.7033\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.7098 - val_loss: 2.6842\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 8.4087 - val_loss: 2.6510\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.5230 - val_loss: 2.6154\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6360 - val_loss: 2.5758\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.3094 - val_loss: 2.5381\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.8568 - val_loss: 2.5105\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.9150 - val_loss: 2.4789\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.5569 - val_loss: 2.4511\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.4188 - val_loss: 2.4361\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.9687 - val_loss: 2.4029\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 8.0534 - val_loss: 2.3651\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.6386 - val_loss: 2.3323\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.1153 - val_loss: 2.3217\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.0739 - val_loss: 2.2958\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 7.5771 - val_loss: 2.2635\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.7919 - val_loss: 2.2696\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.6321 - val_loss: 2.2783\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.2955 - val_loss: 2.2819\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.8441 - val_loss: 2.2860\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 6.9332 - val_loss: 2.2712\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 7.3915 - val_loss: 2.2350\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 6.5807 - val_loss: 2.2093\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.8905 - val_loss: 2.1900\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.3419 - val_loss: 2.1831\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.1130 - val_loss: 2.1795\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.4342 - val_loss: 2.1597\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.8812 - val_loss: 2.1497\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 5.9133 - val_loss: 2.1625\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.1600 - val_loss: 2.1635\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.5837 - val_loss: 2.1803\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 5.5759 - val_loss: 2.1900\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.9309 - val_loss: 2.1993\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.4629 - val_loss: 2.2001\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 6.4089 - val_loss: 2.2013\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.0314 - val_loss: 2.2119\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.7175 - val_loss: 2.2557\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.6600 - val_loss: 2.2802\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 533us/step\n",
      "Train predicting  4 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 16.3673 - val_loss: 1.6564\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 14.9832 - val_loss: 1.5956\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 13.5844 - val_loss: 1.5603\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 16.4104 - val_loss: 1.5252\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.7071 - val_loss: 1.4989\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 13.5211 - val_loss: 1.4703\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.9690 - val_loss: 1.4547\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 14.1909 - val_loss: 1.4418\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.7257 - val_loss: 1.4257\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.1848 - val_loss: 1.4144\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.9332 - val_loss: 1.3994\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 12.1071 - val_loss: 1.3794\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.7631 - val_loss: 1.3659\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.7693 - val_loss: 1.3513\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.1880 - val_loss: 1.3382\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 12.8880 - val_loss: 1.3341\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 10.3694 - val_loss: 1.3390\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 11.2111 - val_loss: 1.3404\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 11.1180 - val_loss: 1.3522\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 9.5993 - val_loss: 1.3602\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 10.6819 - val_loss: 1.3592\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 9.5914 - val_loss: 1.3552\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 10.0897 - val_loss: 1.3456\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 8.8613 - val_loss: 1.3442\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.2631 - val_loss: 1.3396\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 8.8393 - val_loss: 1.3341\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.5824 - val_loss: 1.3397\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.2897 - val_loss: 1.3549\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 9.9131 - val_loss: 1.3667\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.0117 - val_loss: 1.3620\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6223 - val_loss: 1.3703\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.1233 - val_loss: 1.3844\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.6404 - val_loss: 1.3940\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.1996 - val_loss: 1.4099\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.4528 - val_loss: 1.4062\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.0896 - val_loss: 1.3879\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  4 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 14.4265 - val_loss: 1.3393\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.9865 - val_loss: 1.2847\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.6003 - val_loss: 1.2322\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 14.6370 - val_loss: 1.1871\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.5837 - val_loss: 1.1633\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.1479 - val_loss: 1.1388\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.9620 - val_loss: 1.1285\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.0614 - val_loss: 1.1216\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 11.8407 - val_loss: 1.1133\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.7945 - val_loss: 1.1051\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.7602 - val_loss: 1.0989\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3292 - val_loss: 1.0963\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 14.4167 - val_loss: 1.0917\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.6615 - val_loss: 1.0916\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.5164 - val_loss: 1.0924\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.9127 - val_loss: 1.0952\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.9874 - val_loss: 1.0969\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.4347 - val_loss: 1.0968\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 9.3918 - val_loss: 1.0971\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 10.2802 - val_loss: 1.1017\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 10.0461 - val_loss: 1.0996\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.7099 - val_loss: 1.0989\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 8.1346 - val_loss: 1.1005\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.1584 - val_loss: 1.1056\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 234s 1s/step - loss: 9.0979 - val_loss: 57.7134\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.7056 - val_loss: 57.9617\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.5240 - val_loss: 58.1094\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.3049 - val_loss: 58.0056\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.4607 - val_loss: 58.2749\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.7380 - val_loss: 58.0905\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.5175 - val_loss: 57.7942\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4831 - val_loss: 57.3192\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.2843 - val_loss: 57.2557\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9240 - val_loss: 57.2306\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.0203 - val_loss: 56.9558\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.8920 - val_loss: 56.4278\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.7709 - val_loss: 56.4373\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.2310 - val_loss: 56.2320\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.2798 - val_loss: 55.9187\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.9902 - val_loss: 55.8673\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.9993 - val_loss: 55.3937\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.6633 - val_loss: 55.0038\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.0639 - val_loss: 54.6802\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8183 - val_loss: 54.4047\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.6838 - val_loss: 53.8835\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.7663 - val_loss: 53.7731\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.6139 - val_loss: 53.7967\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8554 - val_loss: 53.6544\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.5773 - val_loss: 53.8190\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.0798 - val_loss: 53.6363\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.1879 - val_loss: 53.6023\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.0549 - val_loss: 53.7523\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6780 - val_loss: 53.8357\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.8989 - val_loss: 53.7466\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.1050 - val_loss: 53.7129\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.1340 - val_loss: 53.3709\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.9770 - val_loss: 53.3612\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.5449 - val_loss: 53.4032\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.9214 - val_loss: 53.3789\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7246 - val_loss: 53.3048\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3004 - val_loss: 53.3766\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.0084 - val_loss: 53.0786\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.4376 - val_loss: 52.9323\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.5513 - val_loss: 53.1834\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.8586 - val_loss: 53.3832\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.3823 - val_loss: 53.4907\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.1607 - val_loss: 53.5894\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.0766 - val_loss: 54.0554\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3342 - val_loss: 54.4271\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8718 - val_loss: 54.4342\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3338 - val_loss: 54.4544\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.5629 - val_loss: 54.6723\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.8254 - val_loss: 54.2323\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 8.9584 - val_loss: 69.9736\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.5299 - val_loss: 70.8815\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.3809 - val_loss: 71.3498\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.9668 - val_loss: 71.6669\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.6085 - val_loss: 72.3509\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.0246 - val_loss: 72.7952\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.6804 - val_loss: 73.1482\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.8386 - val_loss: 73.2614\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.5164 - val_loss: 73.5426\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9169 - val_loss: 73.8454\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.0471 - val_loss: 74.0359\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Train predicting  5 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 9.8951 - val_loss: 65.6382\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.6666 - val_loss: 66.3677\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 9.7368 - val_loss: 66.9477\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.0159 - val_loss: 67.3928\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.6486 - val_loss: 68.1358\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.6058 - val_loss: 68.6463\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.1727 - val_loss: 68.9728\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.4121 - val_loss: 69.0616\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.4201 - val_loss: 69.3084\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.7541 - val_loss: 69.6646\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.3155 - val_loss: 69.8516\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  5 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 11.3890 - val_loss: 61.0742\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.8089 - val_loss: 61.6489\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.6356 - val_loss: 62.0851\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.7672 - val_loss: 62.2630\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.0232 - val_loss: 62.8009\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1519 - val_loss: 62.8887\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1442 - val_loss: 62.9624\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.5704 - val_loss: 63.0338\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6520 - val_loss: 63.3121\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.7986 - val_loss: 63.5902\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.5187 - val_loss: 63.7663\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 29s 1s/step - loss: 13.0096 - val_loss: 6.8417\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.8471 - val_loss: 6.7496\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.2947 - val_loss: 6.6754\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.3378 - val_loss: 6.6012\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.6610 - val_loss: 6.5366\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.9687 - val_loss: 6.4649\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1047 - val_loss: 6.4065\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.8107 - val_loss: 6.3557\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.8135 - val_loss: 6.3025\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.4118 - val_loss: 6.2466\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.8358 - val_loss: 6.1973\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.3762 - val_loss: 6.1656\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.8170 - val_loss: 6.1421\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.8758 - val_loss: 6.1102\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.3009 - val_loss: 6.0756\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.5080 - val_loss: 6.0493\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 9.3144 - val_loss: 6.0251\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.5094 - val_loss: 6.0166\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.2750 - val_loss: 6.0004\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.9822 - val_loss: 5.9843\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.4797 - val_loss: 5.9695\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.5209 - val_loss: 5.9883\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.2317 - val_loss: 5.9968\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8129 - val_loss: 6.0067\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.9146 - val_loss: 6.0234\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.2511 - val_loss: 6.0409\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.1436 - val_loss: 6.0653\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.1446 - val_loss: 6.0759\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.9506 - val_loss: 6.0977\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.0704 - val_loss: 6.1169\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8428 - val_loss: 6.1434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  6 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 26s 1s/step - loss: 12.3504 - val_loss: 9.8023\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 11.1895 - val_loss: 9.7225\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.8865 - val_loss: 9.6734\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.1002 - val_loss: 9.6214\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.7241 - val_loss: 9.6227\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.7191 - val_loss: 9.6048\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1548 - val_loss: 9.6005\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.2886 - val_loss: 9.6063\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.7803 - val_loss: 9.6241\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.6121 - val_loss: 9.6241\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.6834 - val_loss: 9.6205\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.6082 - val_loss: 9.6919\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4100 - val_loss: 9.7489\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.8122 - val_loss: 9.8116\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.0494 - val_loss: 9.8894\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.4228 - val_loss: 9.9952\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.0309 - val_loss: 10.0823\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  6 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 12.7103 - val_loss: 13.9556\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.7607 - val_loss: 13.8979\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.6096 - val_loss: 13.8171\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.3615 - val_loss: 13.7692\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.8367 - val_loss: 13.7786\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2817 - val_loss: 13.7640\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.6168 - val_loss: 13.7574\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.2413 - val_loss: 13.7546\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.7998 - val_loss: 13.7512\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.8327 - val_loss: 13.7449\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4848 - val_loss: 13.7484\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9693 - val_loss: 13.8091\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.2948 - val_loss: 13.8076\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.1729 - val_loss: 13.8406\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.3806 - val_loss: 13.9168\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.6330 - val_loss: 13.9570\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.2764 - val_loss: 13.9842\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.6393 - val_loss: 14.0372\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.4464 - val_loss: 14.0767\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.7900 - val_loss: 14.1212\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  6 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 10.9747 - val_loss: 8.7306\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.5217 - val_loss: 8.7135\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.1813 - val_loss: 8.6895\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.1320 - val_loss: 8.6304\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.9903 - val_loss: 8.5787\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.0699 - val_loss: 8.5476\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.6844 - val_loss: 8.5427\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3416 - val_loss: 8.5378\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.0478 - val_loss: 8.5333\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.7362 - val_loss: 8.5199\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.9647 - val_loss: 8.5128\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.6522 - val_loss: 8.5185\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.9313 - val_loss: 8.5181\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2146 - val_loss: 8.5254\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.0902 - val_loss: 8.5511\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4145 - val_loss: 8.5831\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.9405 - val_loss: 8.5882\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 10.2252 - val_loss: 8.6326\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.4848 - val_loss: 8.6654\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.5842 - val_loss: 8.6935\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.5893 - val_loss: 8.7246\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 12.6866 - val_loss: 6.6582\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 13.6285 - val_loss: 6.8379\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 16.0167 - val_loss: 6.9555\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.6636 - val_loss: 7.1156\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.7155 - val_loss: 7.3653\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.6684 - val_loss: 7.5993\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.1201 - val_loss: 7.8021\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.1665 - val_loss: 7.9342\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.4922 - val_loss: 7.9671\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.1636 - val_loss: 8.0272\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.8082 - val_loss: 8.1073\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  7 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 31s 1s/step - loss: 17.3885 - val_loss: 9.0052\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 17.9796 - val_loss: 9.0060\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 18.0057 - val_loss: 8.9760\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 14.2440 - val_loss: 8.9551\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 15.7666 - val_loss: 8.9937\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 15.8815 - val_loss: 8.9878\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 15.2394 - val_loss: 9.0028\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.9181 - val_loss: 9.0337\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.2458 - val_loss: 9.0273\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.2051 - val_loss: 9.0424\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.9399 - val_loss: 9.0678\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.8257 - val_loss: 9.0940\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.5816 - val_loss: 9.1432\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0361 - val_loss: 9.1711\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  7 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 24s 1s/step - loss: 16.4959 - val_loss: 8.6542\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 15.1357 - val_loss: 8.5076\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.6627 - val_loss: 8.3572\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 12.3105 - val_loss: 8.1962\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.7189 - val_loss: 8.1003\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 13.0048 - val_loss: 7.9753\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.4218 - val_loss: 7.8401\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 11.9146 - val_loss: 7.7500\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.0967 - val_loss: 7.6557\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.7153 - val_loss: 7.5732\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.1705 - val_loss: 7.5014\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0015 - val_loss: 7.4375\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.2602 - val_loss: 7.3711\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.9234 - val_loss: 7.3292\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.6360 - val_loss: 7.3230\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.9091 - val_loss: 7.2607\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 9.5606 - val_loss: 7.2314\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 9.5187 - val_loss: 7.2233\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 10.0214 - val_loss: 7.1791\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 10.0989 - val_loss: 7.1261\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 10.3780 - val_loss: 7.1063\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.8510 - val_loss: 7.0971\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 9.3431 - val_loss: 7.0486\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.7927 - val_loss: 7.0047\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.3533 - val_loss: 6.9787\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 10.2944 - val_loss: 6.9347\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.9891 - val_loss: 6.9143\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 8.2412 - val_loss: 6.8624\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.1672 - val_loss: 6.8132\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.6826 - val_loss: 6.7743\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.2660 - val_loss: 6.7566\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 9.5183 - val_loss: 6.7344\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.4867 - val_loss: 6.7203\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.7816 - val_loss: 6.6931\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 7.5091 - val_loss: 6.6804\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 8.4252 - val_loss: 6.6474\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 8.0165 - val_loss: 6.6243\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.8644 - val_loss: 6.5918\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.2521 - val_loss: 6.5760\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 7.4739 - val_loss: 6.5603\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.1350 - val_loss: 6.5424\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.4330 - val_loss: 6.5566\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.4482 - val_loss: 6.5626\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.6889 - val_loss: 6.5362\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.5163 - val_loss: 6.4990\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.9620 - val_loss: 6.4629\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.1006 - val_loss: 6.4597\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.8183 - val_loss: 6.4624\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.6640 - val_loss: 6.4705\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.3127 - val_loss: 6.4854\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.1954 - val_loss: 6.4816\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.3978 - val_loss: 6.5084\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.9683 - val_loss: 6.5235\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.2659 - val_loss: 6.5373\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.7611 - val_loss: 6.5360\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.8799 - val_loss: 6.5293\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.7527 - val_loss: 6.5307\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  7 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 23s 1s/step - loss: 16.9655 - val_loss: 6.2758\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15.9191 - val_loss: 6.3245\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 17.0010 - val_loss: 6.3512\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 13.3138 - val_loss: 6.3851\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.2027 - val_loss: 6.4362\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 16.7106 - val_loss: 6.4796\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 14.0905 - val_loss: 6.5160\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 13.2631 - val_loss: 6.5727\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.9061 - val_loss: 6.6441\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 11.9602 - val_loss: 6.6937\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 14.2724 - val_loss: 6.7499\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  8 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 13.9111 - val_loss: 4.4148\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.7740 - val_loss: 4.3819\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.2662 - val_loss: 4.3824\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.5003 - val_loss: 4.4299\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11.0180 - val_loss: 4.3636\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.2783 - val_loss: 4.3952\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.7864 - val_loss: 4.4119\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.6313 - val_loss: 4.4281\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.2557 - val_loss: 4.3810\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.1285 - val_loss: 4.3693\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.3226 - val_loss: 4.3632\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.2438 - val_loss: 4.3347\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.3163 - val_loss: 4.3945\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.9098 - val_loss: 4.3320\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.4594 - val_loss: 4.2682\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.8806 - val_loss: 4.2145\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.1573 - val_loss: 4.1499\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.9059 - val_loss: 4.1001\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.5261 - val_loss: 4.0572\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.5992 - val_loss: 3.9692\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.4137 - val_loss: 3.9130\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 8.4562 - val_loss: 3.8709\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.4507 - val_loss: 3.8052\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.4793 - val_loss: 3.7531\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.3632 - val_loss: 3.7180\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.5366 - val_loss: 3.7108\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.9896 - val_loss: 3.6882\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.9270 - val_loss: 3.7026\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.5438 - val_loss: 3.6815\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.2101 - val_loss: 3.6487\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.0081 - val_loss: 3.6354\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.2871 - val_loss: 3.6026\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.3100 - val_loss: 3.5820\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.5270 - val_loss: 3.5831\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.0724 - val_loss: 3.6246\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.9975 - val_loss: 3.6422\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8599 - val_loss: 3.6316\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.5633 - val_loss: 3.6688\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.6457 - val_loss: 3.6510\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3631 - val_loss: 3.6520\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.0660 - val_loss: 3.6298\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.1464 - val_loss: 3.6758\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.1856 - val_loss: 3.7056\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  8 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 27s 1s/step - loss: 12.8184 - val_loss: 4.8631\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.0938 - val_loss: 4.7887\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.5421 - val_loss: 4.7575\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 12.0756 - val_loss: 4.7377\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 11.0965 - val_loss: 4.6574\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.9260 - val_loss: 4.6171\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.0346 - val_loss: 4.5526\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.8596 - val_loss: 4.4935\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.0384 - val_loss: 4.4218\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 10.4050 - val_loss: 4.3670\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 10.0248 - val_loss: 4.3195\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.2909 - val_loss: 4.2690\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.2833 - val_loss: 4.2503\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.1362 - val_loss: 4.2003\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.7002 - val_loss: 4.1520\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 7.6699 - val_loss: 4.1310\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.9361 - val_loss: 4.0920\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.6440 - val_loss: 4.0588\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.0380 - val_loss: 4.0446\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.0106 - val_loss: 3.9962\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.4140 - val_loss: 3.9686\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.7766 - val_loss: 3.9519\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.3653 - val_loss: 3.9377\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.6556 - val_loss: 3.9511\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.8817 - val_loss: 3.9473\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.4031 - val_loss: 3.9404\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.8502 - val_loss: 3.9353\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.1221 - val_loss: 3.9407\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.5202 - val_loss: 3.9241\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 7.1293 - val_loss: 3.9177\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.5541 - val_loss: 3.9288\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 7.2996 - val_loss: 3.9142\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.7516 - val_loss: 3.8878\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 6.7796 - val_loss: 3.8751\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.7831 - val_loss: 3.8887\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.8807 - val_loss: 3.8880\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.9759 - val_loss: 3.8685\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.0113 - val_loss: 3.8930\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.1113 - val_loss: 3.8806\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.6158 - val_loss: 3.8812\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.4458 - val_loss: 3.8701\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.4318 - val_loss: 3.8842\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.6886 - val_loss: 3.8917\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.0504 - val_loss: 3.8891\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.0610 - val_loss: 3.8978\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.4229 - val_loss: 3.9001\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.9486 - val_loss: 3.9257\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  8 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 25s 1s/step - loss: 18.9353 - val_loss: 2.3877\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 16.0749 - val_loss: 2.4453\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 15.2069 - val_loss: 2.5504\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 12.1047 - val_loss: 2.6529\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.5491 - val_loss: 2.7034\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.8507 - val_loss: 2.8287\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.8055 - val_loss: 2.9554\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7832 - val_loss: 3.1101\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.6724 - val_loss: 3.2184\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.8377 - val_loss: 3.2992\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.7009 - val_loss: 3.3725\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  8 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 32s 1s/step - loss: 10.8346 - val_loss: 2.3440\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.8478 - val_loss: 2.3671\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 10.1169 - val_loss: 2.4100\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.5399 - val_loss: 2.4385\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.7973 - val_loss: 2.4162\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5504 - val_loss: 2.4505\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.5761 - val_loss: 2.4727\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.6540 - val_loss: 2.4953\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.7116 - val_loss: 2.4969\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1019 - val_loss: 2.4900\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.1515 - val_loss: 2.4757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  9 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 28s 1s/step - loss: 17.4868 - val_loss: 7.0436\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13.4699 - val_loss: 6.9102\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 14.5994 - val_loss: 6.8176\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 12.4940 - val_loss: 6.7342\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 13.2381 - val_loss: 6.6502\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.4267 - val_loss: 6.5931\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.5475 - val_loss: 6.5413\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 12.8226 - val_loss: 6.4007\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 11.1224 - val_loss: 6.2334\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.4630 - val_loss: 6.1105\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 11.0361 - val_loss: 6.0061\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.5991 - val_loss: 5.8936\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.3413 - val_loss: 5.7793\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 9.0801 - val_loss: 5.6622\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9994 - val_loss: 5.5711\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8272 - val_loss: 5.5551\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.8109 - val_loss: 5.5049\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.1600 - val_loss: 5.5022\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.0720 - val_loss: 5.4878\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.9536 - val_loss: 5.4468\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.7283 - val_loss: 5.4683\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.5650 - val_loss: 5.4786\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.2336 - val_loss: 5.4976\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.0940 - val_loss: 5.4656\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.9879 - val_loss: 5.4972\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.3298 - val_loss: 5.4916\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.1320 - val_loss: 5.5895\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.1736 - val_loss: 5.6647\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8108 - val_loss: 5.7656\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.1850 - val_loss: 5.9099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  9 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 12.5717 - val_loss: 10.8497\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 10.5551 - val_loss: 10.1889\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.4208 - val_loss: 9.6916\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.5513 - val_loss: 9.2770\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.7172 - val_loss: 8.8747\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.9218 - val_loss: 8.5441\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5626 - val_loss: 8.3167\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.9447 - val_loss: 8.0997\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.8698 - val_loss: 7.8950\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0907 - val_loss: 7.7107\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.9798 - val_loss: 7.5102\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.8577 - val_loss: 7.3354\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.0186 - val_loss: 7.1255\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.0057 - val_loss: 7.0475\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.1803 - val_loss: 7.0002\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.5476 - val_loss: 6.9982\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.5558 - val_loss: 6.9666\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7083 - val_loss: 6.9462\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.3731 - val_loss: 6.9897\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.2689 - val_loss: 6.9907\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.6119 - val_loss: 7.0608\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.7228 - val_loss: 7.1276\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.2631 - val_loss: 7.2002\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.9864 - val_loss: 7.2768\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.7438 - val_loss: 7.3339\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.1751 - val_loss: 7.4375\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.2829 - val_loss: 7.6066\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.7463 - val_loss: 7.6182\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  9 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 14.5580 - val_loss: 18.5579\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 12.5747 - val_loss: 16.8630\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.7129 - val_loss: 15.4833\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.5177 - val_loss: 14.3165\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.3426 - val_loss: 13.2013\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 10.3096 - val_loss: 12.3520\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 9.4644 - val_loss: 11.6277\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 10.5022 - val_loss: 11.0566\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.5916 - val_loss: 10.6078\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2981 - val_loss: 10.2216\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.8267 - val_loss: 9.9242\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.0300 - val_loss: 9.7074\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7688 - val_loss: 9.4748\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7463 - val_loss: 9.2874\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 6.2590 - val_loss: 9.2396\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7787 - val_loss: 9.2662\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.3013 - val_loss: 9.1723\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.1413 - val_loss: 9.1615\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9735 - val_loss: 9.1461\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.6685 - val_loss: 9.1003\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.3575 - val_loss: 9.0824\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.5298 - val_loss: 9.1463\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.8215 - val_loss: 9.1587\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.5199 - val_loss: 9.1733\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.2957 - val_loss: 9.1896\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.8228 - val_loss: 9.2720\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.9597 - val_loss: 9.3664\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.3597 - val_loss: 9.4242\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.2327 - val_loss: 9.4271\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.1946 - val_loss: 9.4341\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.2217 - val_loss: 9.5380\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  9 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 29s 1s/step - loss: 10.9458 - val_loss: 9.7994\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 10.2581 - val_loss: 9.4728\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 10.5128 - val_loss: 9.2297\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.5119 - val_loss: 9.0053\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.4905 - val_loss: 8.7232\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.9310 - val_loss: 8.4578\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.8395 - val_loss: 8.2369\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 8.6785 - val_loss: 8.0541\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.3096 - val_loss: 7.8141\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.5893 - val_loss: 7.5611\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.1883 - val_loss: 7.3964\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 6.0516 - val_loss: 7.2250\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.0895 - val_loss: 7.1143\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.7226 - val_loss: 7.0222\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 5.4908 - val_loss: 6.9494\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.5336 - val_loss: 6.8976\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.4719 - val_loss: 6.8159\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6694 - val_loss: 6.7856\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.8840 - val_loss: 6.7489\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.5244 - val_loss: 6.7197\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.0676 - val_loss: 6.7084\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9.0254 - val_loss: 6.6669\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.7685 - val_loss: 6.5852\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.8412 - val_loss: 6.5497\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.8705 - val_loss: 6.5207\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.1612 - val_loss: 6.5298\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.0983 - val_loss: 6.5864\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.2978 - val_loss: 6.6487\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.5826 - val_loss: 6.6671\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.1958 - val_loss: 6.6786\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.3583 - val_loss: 6.6978\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 3.7064 - val_loss: 6.7248\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.3958 - val_loss: 6.7844\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.3274 - val_loss: 6.8539\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.7486 - val_loss: 6.8964\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 30s 1s/step - loss: 9.4706 - val_loss: 3.8889\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8630 - val_loss: 3.9224\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 8.0166 - val_loss: 3.9082\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.6788 - val_loss: 3.8718\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.1160 - val_loss: 3.8544\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.6558 - val_loss: 3.8502\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.4030 - val_loss: 3.8402\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4524 - val_loss: 3.8390\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.2715 - val_loss: 3.8409\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.4819 - val_loss: 3.8370\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.6046 - val_loss: 3.8385\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.3527 - val_loss: 3.8343\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.9927 - val_loss: 3.8267\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.4806 - val_loss: 3.8293\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 5.9366 - val_loss: 3.8391\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 6.7053 - val_loss: 3.8435\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.1318 - val_loss: 3.8557\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.8808 - val_loss: 3.8568\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.3270 - val_loss: 3.8691\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.8395 - val_loss: 3.8948\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.9829 - val_loss: 3.9179\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.9905 - val_loss: 3.9369\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.4941 - val_loss: 3.9531\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 34s 1s/step - loss: 8.2396 - val_loss: 2.5658\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.9299 - val_loss: 2.6090\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 7.5697 - val_loss: 2.6425\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.9410 - val_loss: 2.6855\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.3805 - val_loss: 2.7442\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.4097 - val_loss: 2.7904\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 6.1598 - val_loss: 2.8207\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.3690 - val_loss: 2.8405\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.8013 - val_loss: 2.8651\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.0671 - val_loss: 2.8867\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.2929 - val_loss: 2.9090\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  10 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 34s 1s/step - loss: 6.2986 - val_loss: 8.5536\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 6.3954 - val_loss: 8.7214\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.6442 - val_loss: 8.9557\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.3147 - val_loss: 9.1898\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.4224 - val_loss: 9.4002\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.3726 - val_loss: 9.5054\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.2174 - val_loss: 9.4839\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.9038 - val_loss: 9.5155\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.3204 - val_loss: 9.5749\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.3690 - val_loss: 9.5487\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.3519 - val_loss: 9.4427\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train predicting  10 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 41s 1s/step - loss: 10.3794 - val_loss: 4.8111\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 8.7698 - val_loss: 4.9185\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.7536 - val_loss: 5.0177\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.3821 - val_loss: 5.1335\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.6315 - val_loss: 5.2833\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.1548 - val_loss: 5.4272\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.7805 - val_loss: 5.5669\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.6702 - val_loss: 5.6944\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.6528 - val_loss: 5.7980\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.0943 - val_loss: 5.9271\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.4935 - val_loss: 6.0580\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Train predicting  11 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 35s 1s/step - loss: 9.5091 - val_loss: 70.5432\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 8.9480 - val_loss: 69.9181\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.8781 - val_loss: 69.3023\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.4881 - val_loss: 68.6448\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.1536 - val_loss: 68.0329\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.2176 - val_loss: 67.5386\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.0711 - val_loss: 67.1593\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.4534 - val_loss: 66.7759\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.9493 - val_loss: 66.4249\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.3530 - val_loss: 65.4791\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.9174 - val_loss: 64.3870\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.7362 - val_loss: 63.2397\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.7508 - val_loss: 62.3893\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.7849 - val_loss: 61.6420\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.2092 - val_loss: 61.0073\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.9016 - val_loss: 60.5512\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.6947 - val_loss: 60.1311\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.9005 - val_loss: 59.9372\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.3235 - val_loss: 59.5689\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.5575 - val_loss: 59.1550\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.1445 - val_loss: 59.0594\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.5362 - val_loss: 59.2104\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.2634 - val_loss: 59.2490\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.2526 - val_loss: 59.0299\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.1671 - val_loss: 58.8876\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 3.7232 - val_loss: 58.5771\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.8713 - val_loss: 58.1291\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.3318 - val_loss: 57.9069\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.0392 - val_loss: 57.6370\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.4563 - val_loss: 57.1510\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.0190 - val_loss: 56.7171\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.4083 - val_loss: 56.5099\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.2691 - val_loss: 56.3369\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.0067 - val_loss: 56.4181\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.0617 - val_loss: 56.4752\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.4271 - val_loss: 56.5737\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.4034 - val_loss: 56.2161\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.9744 - val_loss: 55.6858\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.8150 - val_loss: 54.9605\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.8593 - val_loss: 54.9719\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.4714 - val_loss: 54.5212\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.4684 - val_loss: 54.3641\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.5108 - val_loss: 54.5420\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.6595 - val_loss: 54.5739\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.0345 - val_loss: 54.4322\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.2037 - val_loss: 54.2453\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.3737 - val_loss: 54.2765\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.4651 - val_loss: 54.1655\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.8420 - val_loss: 53.6151\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.2732 - val_loss: 53.3509\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.1466 - val_loss: 53.0999\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.5200 - val_loss: 52.6864\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.2203 - val_loss: 52.1402\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.3769 - val_loss: 51.9887\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.3469 - val_loss: 51.8141\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.0412 - val_loss: 51.8035\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.0564 - val_loss: 51.8658\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4948 - val_loss: 51.9724\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.8324 - val_loss: 51.9669\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.0412 - val_loss: 52.2023\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.8469 - val_loss: 52.0056\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.9818 - val_loss: 51.4288\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.9822 - val_loss: 50.9940\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.8506 - val_loss: 50.5163\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.1486 - val_loss: 50.4125\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8461 - val_loss: 50.7417\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.0103 - val_loss: 51.0149\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.6124 - val_loss: 51.0743\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.8424 - val_loss: 51.0273\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.9270 - val_loss: 51.4018\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.9802 - val_loss: 51.5116\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.0396 - val_loss: 51.1697\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.5277 - val_loss: 50.7032\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.8196 - val_loss: 50.2732\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.5501 - val_loss: 49.8612\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.6485 - val_loss: 50.0250\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1.5364 - val_loss: 50.5855\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4214 - val_loss: 50.8922\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.9344 - val_loss: 51.1632\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.5658 - val_loss: 50.3669\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.3151 - val_loss: 49.9848\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.6242 - val_loss: 49.8813\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.6629 - val_loss: 50.1380\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.5154 - val_loss: 50.5895\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.7701 - val_loss: 51.1053\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  11 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 40s 1s/step - loss: 9.2534 - val_loss: 76.0303\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.6556 - val_loss: 75.1337\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.1885 - val_loss: 74.5340\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 8.2420 - val_loss: 73.9650\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 8.5713 - val_loss: 73.1403\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.2417 - val_loss: 72.6806\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 7.3218 - val_loss: 72.0675\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.9516 - val_loss: 71.6329\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.2828 - val_loss: 71.1607\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.2649 - val_loss: 70.8100\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.3168 - val_loss: 70.7176\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.0812 - val_loss: 70.4704\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.5630 - val_loss: 70.4043\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 6.2108 - val_loss: 70.1598\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.4628 - val_loss: 70.0668\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.1220 - val_loss: 70.1273\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.2663 - val_loss: 70.0335\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 5.0236 - val_loss: 70.1731\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 5.4111 - val_loss: 70.1959\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.9795 - val_loss: 69.9230\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 5.2179 - val_loss: 69.7419\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 4.6281 - val_loss: 69.8190\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 4.1763 - val_loss: 69.9290\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 4.2226 - val_loss: 70.0794\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.3676 - val_loss: 70.2812\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.9768 - val_loss: 70.4819\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 3.9937 - val_loss: 70.4712\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 4.0657 - val_loss: 70.5153\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.1565 - val_loss: 70.6560\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.3115 - val_loss: 70.2627\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.0652 - val_loss: 70.1046\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Train predicting  11 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 39s 1s/step - loss: 9.0754 - val_loss: 62.7168\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.8660 - val_loss: 60.6703\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.4760 - val_loss: 59.0904\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.7563 - val_loss: 57.3947\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.8210 - val_loss: 55.6670\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.5289 - val_loss: 54.8724\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.3296 - val_loss: 54.2425\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.4464 - val_loss: 53.5564\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.6445 - val_loss: 52.9255\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 4.9301 - val_loss: 52.1749\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.5155 - val_loss: 51.9317\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.9394 - val_loss: 51.7205\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.4109 - val_loss: 51.7364\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.4640 - val_loss: 51.6041\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.3389 - val_loss: 51.5033\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.8724 - val_loss: 51.2170\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.6563 - val_loss: 50.7411\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.4356 - val_loss: 50.7739\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.6501 - val_loss: 50.6417\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.0763 - val_loss: 50.3727\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.2942 - val_loss: 50.4728\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.1984 - val_loss: 50.8864\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.3875 - val_loss: 50.9915\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.3720 - val_loss: 51.4868\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.7928 - val_loss: 51.4841\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.5986 - val_loss: 51.5141\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.4213 - val_loss: 51.3002\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.0696 - val_loss: 51.3007\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.6224 - val_loss: 51.4821\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.3986 - val_loss: 51.4708\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Train predicting  11 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 38s 1s/step - loss: 8.7000 - val_loss: 78.0640\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 9.1144 - val_loss: 77.1035\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 8.6970 - val_loss: 76.1967\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.9525 - val_loss: 75.4285\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 8.4410 - val_loss: 74.7597\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 7.6118 - val_loss: 74.4576\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.8712 - val_loss: 74.1399\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2518 - val_loss: 73.9161\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.2578 - val_loss: 73.5430\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.8346 - val_loss: 73.1210\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.9460 - val_loss: 72.8938\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 7.2080 - val_loss: 72.5070\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.6595 - val_loss: 72.1375\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 5.8715 - val_loss: 71.8885\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.1084 - val_loss: 71.6460\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.8377 - val_loss: 71.3540\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.5072 - val_loss: 71.0755\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.0034 - val_loss: 70.9733\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.9217 - val_loss: 70.7994\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.3520 - val_loss: 70.5258\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.9478 - val_loss: 70.5070\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 6.1196 - val_loss: 70.5677\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.4255 - val_loss: 70.4122\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 4.4871 - val_loss: 70.4243\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.6462 - val_loss: 70.2789\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.2164 - val_loss: 70.1801\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.5397 - val_loss: 70.1050\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 4.2434 - val_loss: 69.9734\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.9215 - val_loss: 69.8597\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.1724 - val_loss: 69.4270\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.9537 - val_loss: 69.1635\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.6928 - val_loss: 69.1306\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.7141 - val_loss: 68.7797\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.6782 - val_loss: 68.5977\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.3251 - val_loss: 68.2948\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.5280 - val_loss: 67.9495\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5832 - val_loss: 67.6058\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.5020 - val_loss: 67.6201\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.7711 - val_loss: 67.3711\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.0745 - val_loss: 67.1993\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.9221 - val_loss: 66.9587\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.3026 - val_loss: 66.6726\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5382 - val_loss: 66.6743\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8798 - val_loss: 66.6801\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.2909 - val_loss: 66.9006\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.7202 - val_loss: 66.8041\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.3479 - val_loss: 66.8574\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.6292 - val_loss: 66.6296\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.4333 - val_loss: 66.4723\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4577 - val_loss: 66.4672\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.2100 - val_loss: 66.5042\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.4320 - val_loss: 66.2390\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.2422 - val_loss: 66.0275\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.9649 - val_loss: 65.9257\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.2156 - val_loss: 65.8100\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.9675 - val_loss: 65.8123\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4574 - val_loss: 66.0229\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.7524 - val_loss: 66.3716\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.4583 - val_loss: 66.5569\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.3083 - val_loss: 66.3822\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.0536 - val_loss: 66.2302\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.4959 - val_loss: 65.7294\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8722 - val_loss: 65.4474\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.2296 - val_loss: 65.2791\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.2253 - val_loss: 65.0464\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.3481 - val_loss: 64.7850\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 3.5567 - val_loss: 64.5569\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.8438 - val_loss: 64.2169\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.7558 - val_loss: 63.9135\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.7900 - val_loss: 64.0436\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.1506 - val_loss: 63.5883\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.7959 - val_loss: 63.7008\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8463 - val_loss: 63.7140\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6292 - val_loss: 64.0849\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.8464 - val_loss: 64.3995\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.7156 - val_loss: 64.8480\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1.7273 - val_loss: 65.2504\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.8542 - val_loss: 65.6481\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.5685 - val_loss: 65.8992\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.5075 - val_loss: 66.1144\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.7779 - val_loss: 66.1535\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 RNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 41s 1s/step - loss: 10.4976 - val_loss: 10.7005\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 9.4994 - val_loss: 9.3142\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 9.2481 - val_loss: 7.9856\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9854 - val_loss: 7.1961\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.7234 - val_loss: 6.7475\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.9734 - val_loss: 6.4083\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.6634 - val_loss: 6.1314\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 7.4541 - val_loss: 5.9842\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.0958 - val_loss: 5.8726\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.9505 - val_loss: 5.7993\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.3574 - val_loss: 5.7894\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.9739 - val_loss: 5.8011\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6.2579 - val_loss: 5.7221\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.0398 - val_loss: 5.6784\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.8809 - val_loss: 5.6039\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.4029 - val_loss: 5.5333\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.0410 - val_loss: 5.5328\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.6416 - val_loss: 5.4575\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.4091 - val_loss: 5.3332\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 4.9252 - val_loss: 5.2849\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 4.8948 - val_loss: 5.2126\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.2001 - val_loss: 5.2092\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 5.4496 - val_loss: 5.2362\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.6624 - val_loss: 5.3158\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 3.8519 - val_loss: 5.4036\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 3.7293 - val_loss: 5.5179\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.5907 - val_loss: 5.6997\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 4.9243 - val_loss: 5.7687\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 4.6577 - val_loss: 5.7310\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 3.6637 - val_loss: 5.7698\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.1615 - val_loss: 5.6975\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 3.6936 - val_loss: 5.6429\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Train predicting  12 LSTM16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 46s 2s/step - loss: 8.8710 - val_loss: 12.8947\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 7.7410 - val_loss: 11.8750\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 8.1118 - val_loss: 11.0476\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9017 - val_loss: 10.3187\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 7.3495 - val_loss: 9.6675\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6.8086 - val_loss: 9.0677\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 6.6463 - val_loss: 8.5575\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 6.5018 - val_loss: 8.1742\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.5702 - val_loss: 7.7686\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.9298 - val_loss: 7.2851\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 5.2481 - val_loss: 7.0480\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 5.6332 - val_loss: 6.8486\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.9349 - val_loss: 6.5472\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 5.4660 - val_loss: 6.2826\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 5.7509 - val_loss: 6.0280\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.1681 - val_loss: 5.9178\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.2362 - val_loss: 5.9245\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.1656 - val_loss: 5.8488\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 5.0736 - val_loss: 5.8567\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 5.2675 - val_loss: 5.8487\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.5759 - val_loss: 5.7822\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.3431 - val_loss: 5.5795\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.7370 - val_loss: 5.5257\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.4057 - val_loss: 5.5153\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 4.6252 - val_loss: 5.4585\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.9206 - val_loss: 5.5176\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.9022 - val_loss: 5.5698\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.3326 - val_loss: 5.6617\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 4.2188 - val_loss: 5.6157\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 4.0240 - val_loss: 5.7038\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 3.6578 - val_loss: 5.7811\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 3.4773 - val_loss: 5.8677\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 3.6417 - val_loss: 5.7674\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 3.4928 - val_loss: 5.6082\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 3.6980 - val_loss: 5.6329\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 CNNRNN16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 44s 1s/step - loss: 9.3848 - val_loss: 11.1651\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.0685 - val_loss: 9.7276\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 8.6564 - val_loss: 8.8418\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7962 - val_loss: 8.0436\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 7.3373 - val_loss: 7.3985\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 8.4945 - val_loss: 7.0324\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.8376 - val_loss: 6.8490\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.9437 - val_loss: 6.8975\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 6.7424 - val_loss: 6.7150\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 6.1183 - val_loss: 6.5287\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.8422 - val_loss: 6.6097\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 5.5015 - val_loss: 6.7494\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.9834 - val_loss: 6.6616\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 4.8386 - val_loss: 6.7750\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.5917 - val_loss: 6.7501\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 4.7100 - val_loss: 6.9096\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.1837 - val_loss: 6.9491\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.5343 - val_loss: 6.9272\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 4.6492 - val_loss: 7.0404\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.9588 - val_loss: 7.2913\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Train predicting  12 MLP16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 42s 1s/step - loss: 9.4167 - val_loss: 12.6227\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 9.3747 - val_loss: 10.9703\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.7096 - val_loss: 9.7014\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.7437 - val_loss: 8.7426\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7.4784 - val_loss: 8.0950\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 7.1277 - val_loss: 7.6256\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 7.3996 - val_loss: 6.9214\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.8126 - val_loss: 6.2577\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.1987 - val_loss: 5.7502\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 6.7992 - val_loss: 5.1515\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.8272 - val_loss: 4.8779\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.7781 - val_loss: 4.7524\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 5.4810 - val_loss: 4.8009\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.5532 - val_loss: 4.8348\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 5.3967 - val_loss: 4.7608\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.6111 - val_loss: 4.7318\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 5.2583 - val_loss: 4.7812\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 5.7149 - val_loss: 4.7513\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.9659 - val_loss: 4.7964\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 5.5115 - val_loss: 4.8856\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.0976 - val_loss: 4.7470\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 4.3366 - val_loss: 4.4584\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.9682 - val_loss: 4.3582\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.5086 - val_loss: 4.3484\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 5.0902 - val_loss: 4.5020\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.2195 - val_loss: 4.6375\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 3.6137 - val_loss: 4.8304\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.5469 - val_loss: 4.9549\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.9458 - val_loss: 4.9950\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 4.6699 - val_loss: 5.2548\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 4.7136 - val_loss: 5.2217\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 3.9172 - val_loss: 5.1392\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.0032 - val_loss: 5.0966\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 4.1329 - val_loss: 5.1205\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for id in ids_to_execute[10:]:\n",
    "    k+=1\n",
    "    print(\"Executing\",id, \"iter\", k)\n",
    "    data = {i: pd.read_parquet(f\"data/climate_features/{region}/predictor_{id}_{i}.parquet\") for i in range(1,13)}\n",
    "    rnn16_model = Sequential([\n",
    "    SimpleRNN(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    lstm16_model = Sequential([\n",
    "    LSTM(16, activation=\"tanh\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "    Dropout(0.1),  # Regularization\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(len(indices_of_interest))  # Predict 5 indices\n",
    "    ])\n",
    "    cnn_rnn_model = Sequential([\n",
    "        Conv1D(16, kernel_size=1, activation=\"relu\", input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Reshape((1, 16)),  # Back to time dimension\n",
    "        SimpleRNN(8, activation=\"tanh\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    lp_model = Sequential([\n",
    "        Flatten(input_shape=(1, len(data[1].columns) - len(indices_of_interest))),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(len(indices_of_interest))\n",
    "    ])\n",
    "    # assert len(regressors) == len(name_regressors)\n",
    "    regressors =  [rnn16_model, lstm16_model, cnn_rnn_model, lp_model]\n",
    "    name_regressors =  [\"RNN16\", \"LSTM16\", \"CNNRNN16\", \"MLP16\"]\n",
    "    assert len(regressors) == len(name_regressors)\n",
    "    experiment_1 = PredictionExperiment(data, indices_of_interest, regressors, name_regressors, 5, id, loss_fn=SERA(bounds=bounds,T=100))\n",
    "    experiment_1.execute_experiment()\n",
    "    experiment_1.get_metrics(\"r2\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", \"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"r2\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mape\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"mae\", stage=\"TSCV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"prediction\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"training\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"CV\", show=False)\n",
    "    experiment_1.get_metrics(\"sera\", stage=\"TSCV\", show=False)\n",
    "\n",
    "    #experiment_1.top_results(\"r2\", 5, stage=\"prediction\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    #experiment_1.top_results(\"cv_r2\", 5, stage=\"CV\", top_data_path=f\"data/results/{FREQUENCY}/top_results.csv\")\n",
    "    experiment_1.save_results(f\"data/sera_results/{region}_results/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
