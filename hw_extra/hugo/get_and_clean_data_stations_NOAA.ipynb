{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data of Maximum Temperature in California (NOAA)\n",
    "\n",
    "Author: Martin Pavez\n",
    "\n",
    "Creation: January 2025\n",
    "\n",
    "This notebook shows the very beginning steps in heatwave detection from meteorological stations data. \n",
    "1. Detection of missing data: quantification and cleaning.\n",
    "2. Selection of stations. \n",
    "3. We generate cleaned data for heatwave detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) # Suppress specific RuntimeWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\Desktop\\data\\hw_extra\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH_AND_FILENAME = 'data/local_data/NOAA/stations.parquet'\n",
    "TEMP_DATA_PATH = 'data/local_data/NOAA/original'\n",
    "CLEANED_DATA_PATH = 'data/local_data/NOAA/cleaned/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate CSV files in a folder\n",
    "def concatenate_csv(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all .csv files in the specified folder, concatenates them (axis=0),\n",
    "    and indexes the resulting DataFrame by the 'date' column.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing .csv files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame indexed by the 'date' column.\n",
    "    \"\"\"\n",
    "    # List to store DataFrames from each CSV file\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read CSV file, parse 'date' column as datetime\n",
    "            df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames along axis 0\n",
    "    concatenated_df = pd.concat(dataframes, axis=0)\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    concatenated_df.set_index('date', inplace=True)\n",
    "\n",
    "    ### Found duplicated items, these come from the end and start between files (some have them, some not)\n",
    "    #duplicates = concatenated_df.index[concatenated_df.index.duplicated(keep=False)]\n",
    "    #if not duplicates.empty:\n",
    "    #    print(\"Duplicate indices found:\")\n",
    "    #    print(duplicates)\n",
    "    concatenated_df = concatenated_df[~concatenated_df.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "    # Create a complete date range from the earliest to the latest date\n",
    "    complete_index = pd.date_range(start=concatenated_df.index.min(), end=concatenated_df.index.max(), freq='D')\n",
    "\n",
    "    # Reindex the DataFrame to the complete date range, filling gaps with NaN\n",
    "    concatenated_df = concatenated_df.reindex(complete_index)\n",
    "\n",
    "    # Rename the index to 'date'\n",
    "    concatenated_df.index.name = 'date'\n",
    "\n",
    "    # Sort by index for consistency\n",
    "    concatenated_df.sort_index(inplace=True)\n",
    "\n",
    "    concatenated_df[\"value\"] = concatenated_df[\"value\"]/10\n",
    "    concatenated_df.rename(columns={\"value\":\"max_temp\"}, inplace=True)\n",
    "\n",
    "    return concatenated_df\n",
    "\n",
    "def Month_Days(year):\n",
    "    return {\"year\": year, \"month_days\": {m: monthrange(year, m)[1] for m in range(1, 13)}}\n",
    "\n",
    "def Tfilter(data, column_label, nperc, year_window_init: int, year_window_end: int):\n",
    "    start_date = data.index[0]\n",
    "    end_date = data.index[-1]\n",
    "    perc_label = 'perc'\n",
    "    Tadd = 0.0\n",
    "    year_window_init = year_window_init\n",
    "    year_window_end = year_window_end\n",
    "    data_temp = data[column_label]\n",
    "\n",
    "    data_threshold = pd.DataFrame(\n",
    "        [],\n",
    "        columns=[perc_label],\n",
    "        index = data.index\n",
    "    )\n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        month_days = Month_Days(year)\n",
    "        for month in month_days[\"month_days\"]:\n",
    "            for day in range(1, month_days[\"month_days\"][month] + 1):\n",
    "                try:\n",
    "                    current_date = datetime(year, month, day)\n",
    "                except ValueError:\n",
    "                    if current_date == start_date:\n",
    "                        current_date = datetime(year, month, day+1)\n",
    "                    if current_date == end_date:\n",
    "                        current_date = datetime(year, month, day-1)\n",
    "                if  current_date >= start_date and current_date <= end_date:\n",
    "                    f_data_temp = data_temp[\n",
    "                        (year_window_init <= data_temp.index.year)\n",
    "                        & (data_temp.index.year <= year_window_end)\n",
    "                        & (data_temp.index.day == day)\n",
    "                        & (data_temp.index.month == month)\n",
    "                    ]\n",
    "                    try:\n",
    "                        data_threshold.loc[datetime(year, month, day), perc_label] = f_data_temp.quantile(\n",
    "                            nperc*0.01, interpolation=\"midpoint\"\n",
    "                        ).values[0]\n",
    "                    except AttributeError:\n",
    "                        data_threshold.loc[datetime(year, month, day), perc_label] = f_data_temp.quantile(\n",
    "                            nperc*0.01, interpolation=\"midpoint\"\n",
    "                        )\n",
    "                    except ValueError:\n",
    "                        data_threshold.loc[datetime(year, month, day-1), perc_label] = f_data_temp.quantile(\n",
    "                            nperc*0.01, interpolation=\"midpoint\"\n",
    "                        ).values[0] + Tadd\n",
    "\n",
    "        smoothed_series = data_threshold.rolling(window=31, center=True).mean()\n",
    "    return smoothed_series + Tadd\n",
    "    #return data_threshold + Tadd\n",
    "\n",
    "def to_format(data, max_temp_lim = 50, add_filter_year = None, filter_by_hist = False, filter = True, dropnans = True):\n",
    "\n",
    "    #data[\"Date\"] = pd.to_datetime(data[\"Date\"],format=\"%Y-%m-%d\")\n",
    "\n",
    "    if dropnans:\n",
    "        max_temp = data.set_index(\"date\").dropna(subset=[\"max_temp\"])[[\"max_temp\"]]\n",
    "\n",
    "    #max_temp = max_temp.rename(columns={\"DayAirTmpMax\":\"max_temp\"})\n",
    "    #min_temp = min_temp.rename(columns={\"DayAirTmpMin\":\"min_temp\"})\n",
    "    #mean_temp = mean_temp.rename(columns={\"DayAirTmpAvg\":\"mean_temp\"})\n",
    "    max_temp = data[[\"max_temp\"]]\n",
    "\n",
    "    if filter:\n",
    "\n",
    "        if add_filter_year is None:\n",
    "            max_temp = max_temp.drop(max_temp[np.abs(max_temp[\"max_temp\"])>max_temp_lim].index)\n",
    "        else:\n",
    "        #if add_filter_year is not None:\n",
    "            max_temp.loc[(max_temp.index.year < add_filter_year) & (np.abs(max_temp['max_temp']) > max_temp_lim), 'max_temp'] = np.nan\n",
    "            max_temp = max_temp.dropna(subset=[\"max_temp\"])[[\"max_temp\"]]\n",
    "\n",
    "\n",
    "        if filter_by_hist:#add_filter_year is not None:\n",
    "            perc_max = Tfilter(max_temp, 'max_temp', 99.9, add_filter_year, 2023)\n",
    "            perc_max = perc_max.reindex(max_temp.index)\n",
    "\n",
    "\n",
    "            max_temp.loc[(max_temp.index.year < add_filter_year) & (max_temp['max_temp'] > perc_max['perc'] + 10), 'max_temp'] = np.nan\n",
    "\n",
    "        if dropnans:\n",
    "            max_temp = max_temp.dropna(subset=[\"max_temp\"])[[\"max_temp\"]]\n",
    "    \n",
    "    else:\n",
    "        return data\n",
    "\n",
    "    concatenated_df = pd.concat([max_temp], axis=1)\n",
    "\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>elevationUnit</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040136</th>\n",
       "      <td>516.6</td>\n",
       "      <td>1952-10-01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>32.83580</td>\n",
       "      <td>ALPINE, CA US</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-116.77740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040161</th>\n",
       "      <td>1332.9</td>\n",
       "      <td>1905-04-01</td>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>41.49021</td>\n",
       "      <td>ALTURAS, CA US</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-120.54376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040192</th>\n",
       "      <td>70.7</td>\n",
       "      <td>1989-08-01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>33.86470</td>\n",
       "      <td>ANAHEIM, CA US</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-117.84250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040212</th>\n",
       "      <td>522.7</td>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>38.57300</td>\n",
       "      <td>ANGWIN PACIFIC UNION COLLEGE, CA US</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-122.44050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040332</th>\n",
       "      <td>137.2</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>2024-08-08</td>\n",
       "      <td>35.21110</td>\n",
       "      <td>ARVIN, CA US</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-118.83360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040343</th>\n",
       "      <td>520.6</td>\n",
       "      <td>1927-01-01</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>36.49140</td>\n",
       "      <td>ASH MOUNTAIN, CA US</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-118.82530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040383</th>\n",
       "      <td>393.8</td>\n",
       "      <td>1905-01-01</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>38.90720</td>\n",
       "      <td>AUBURN, CA US</td>\n",
       "      <td>0.9179</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-121.08380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040444</th>\n",
       "      <td>143.3</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>35.41860</td>\n",
       "      <td>BAKERSFIELD 5 NW, CA US</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-119.05080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040449</th>\n",
       "      <td>528.8</td>\n",
       "      <td>1950-02-01</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>36.90920</td>\n",
       "      <td>BALCH POWER HOUSE, CA US</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-119.08830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040521</th>\n",
       "      <td>676.7</td>\n",
       "      <td>1980-05-01</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>34.89270</td>\n",
       "      <td>BARSTOW, CA US</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-117.02190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040673</th>\n",
       "      <td>132.6</td>\n",
       "      <td>1972-12-02</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>37.08689</td>\n",
       "      <td>BEN LOMOND NUMBER 4, CA US</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-122.08221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040693</th>\n",
       "      <td>94.5</td>\n",
       "      <td>1893-01-01</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>37.87440</td>\n",
       "      <td>BERKELEY, CA US</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-122.26050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040741</th>\n",
       "      <td>2058.3</td>\n",
       "      <td>1960-07-01</td>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>34.24300</td>\n",
       "      <td>BIG BEAR LAKE, CA US</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-116.91700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040790</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1915-01-01</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>36.24720</td>\n",
       "      <td>BIG SUR STATION, CA US</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-121.78020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040798</th>\n",
       "      <td>709.0</td>\n",
       "      <td>1932-01-01</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>34.29481</td>\n",
       "      <td>BIG TUJUNGA DAM FC46, CA US</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-118.18849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040820</th>\n",
       "      <td>2581.7</td>\n",
       "      <td>2003-05-01</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>37.23210</td>\n",
       "      <td>ASPENDELL, CA US</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-118.59940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040931</th>\n",
       "      <td>1699.3</td>\n",
       "      <td>1906-03-03</td>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>39.38860</td>\n",
       "      <td>BOCA, CA US</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-120.09360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040943</th>\n",
       "      <td>2551.2</td>\n",
       "      <td>1895-02-01</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>38.21190</td>\n",
       "      <td>BODIE CALIFORNIA STATE HISTORIC PARK, CA US</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-119.01420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00040983</th>\n",
       "      <td>246.9</td>\n",
       "      <td>1942-07-01</td>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>33.25590</td>\n",
       "      <td>BORREGO DESERT PARK, CA US</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-116.40360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND:USC00041018</th>\n",
       "      <td>1641.3</td>\n",
       "      <td>1896-06-01</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>39.45390</td>\n",
       "      <td>BOWMAN DAM, CA US</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>METERS</td>\n",
       "      <td>-120.65560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   elevation     mindate     maxdate  latitude   \n",
       "id                                                               \n",
       "GHCND:USC00040136      516.6  1952-10-01  2024-06-30  32.83580  \\\n",
       "GHCND:USC00040161     1332.9  1905-04-01  2023-03-21  41.49021   \n",
       "GHCND:USC00040192       70.7  1989-08-01  2024-06-30  33.86470   \n",
       "GHCND:USC00040212      522.7  1940-01-01  2024-07-31  38.57300   \n",
       "GHCND:USC00040332      137.2  2008-08-01  2024-08-08  35.21110   \n",
       "GHCND:USC00040343      520.6  1927-01-01  2024-05-31  36.49140   \n",
       "GHCND:USC00040383      393.8  1905-01-01  2024-06-28  38.90720   \n",
       "GHCND:USC00040444      143.3  1999-01-01  2024-08-28  35.41860   \n",
       "GHCND:USC00040449      528.8  1950-02-01  2023-12-31  36.90920   \n",
       "GHCND:USC00040521      676.7  1980-05-01  2024-08-27  34.89270   \n",
       "GHCND:USC00040673      132.6  1972-12-02  2024-08-27  37.08689   \n",
       "GHCND:USC00040693       94.5  1893-01-01  2024-04-30  37.87440   \n",
       "GHCND:USC00040741     2058.3  1960-07-01  2024-08-23  34.24300   \n",
       "GHCND:USC00040790       61.0  1915-01-01  2024-08-27  36.24720   \n",
       "GHCND:USC00040798      709.0  1932-01-01  2024-07-31  34.29481   \n",
       "GHCND:USC00040820     2581.7  2003-05-01  2024-07-31  37.23210   \n",
       "GHCND:USC00040931     1699.3  1906-03-03  2024-08-26  39.38860   \n",
       "GHCND:USC00040943     2551.2  1895-02-01  2023-09-30  38.21190   \n",
       "GHCND:USC00040983      246.9  1942-07-01  2024-08-25  33.25590   \n",
       "GHCND:USC00041018     1641.3  1896-06-01  2024-06-27  39.45390   \n",
       "\n",
       "                                                          name  datacoverage   \n",
       "id                                                                             \n",
       "GHCND:USC00040136                                ALPINE, CA US        0.9499  \\\n",
       "GHCND:USC00040161                               ALTURAS, CA US        0.8324   \n",
       "GHCND:USC00040192                               ANAHEIM, CA US        0.9749   \n",
       "GHCND:USC00040212          ANGWIN PACIFIC UNION COLLEGE, CA US        0.9201   \n",
       "GHCND:USC00040332                                 ARVIN, CA US        0.6777   \n",
       "GHCND:USC00040343                          ASH MOUNTAIN, CA US        0.9478   \n",
       "GHCND:USC00040383                                AUBURN, CA US        0.9179   \n",
       "GHCND:USC00040444                      BAKERSFIELD 5 NW, CA US        0.9423   \n",
       "GHCND:USC00040449                     BALCH POWER HOUSE, CA US        0.9483   \n",
       "GHCND:USC00040521                               BARSTOW, CA US        0.9762   \n",
       "GHCND:USC00040673                   BEN LOMOND NUMBER 4, CA US        0.9868   \n",
       "GHCND:USC00040693                              BERKELEY, CA US        0.9251   \n",
       "GHCND:USC00040741                         BIG BEAR LAKE, CA US        0.9810   \n",
       "GHCND:USC00040790                       BIG SUR STATION, CA US        0.9283   \n",
       "GHCND:USC00040798                  BIG TUJUNGA DAM FC46, CA US        0.8904   \n",
       "GHCND:USC00040820                             ASPENDELL, CA US        0.5298   \n",
       "GHCND:USC00040931                                  BOCA, CA US        0.7913   \n",
       "GHCND:USC00040943  BODIE CALIFORNIA STATE HISTORIC PARK, CA US        0.5052   \n",
       "GHCND:USC00040983                   BORREGO DESERT PARK, CA US        0.9384   \n",
       "GHCND:USC00041018                            BOWMAN DAM, CA US        0.7830   \n",
       "\n",
       "                  elevationUnit  longitude  \n",
       "id                                          \n",
       "GHCND:USC00040136        METERS -116.77740  \n",
       "GHCND:USC00040161        METERS -120.54376  \n",
       "GHCND:USC00040192        METERS -117.84250  \n",
       "GHCND:USC00040212        METERS -122.44050  \n",
       "GHCND:USC00040332        METERS -118.83360  \n",
       "GHCND:USC00040343        METERS -118.82530  \n",
       "GHCND:USC00040383        METERS -121.08380  \n",
       "GHCND:USC00040444        METERS -119.05080  \n",
       "GHCND:USC00040449        METERS -119.08830  \n",
       "GHCND:USC00040521        METERS -117.02190  \n",
       "GHCND:USC00040673        METERS -122.08221  \n",
       "GHCND:USC00040693        METERS -122.26050  \n",
       "GHCND:USC00040741        METERS -116.91700  \n",
       "GHCND:USC00040790        METERS -121.78020  \n",
       "GHCND:USC00040798        METERS -118.18849  \n",
       "GHCND:USC00040820        METERS -118.59940  \n",
       "GHCND:USC00040931        METERS -120.09360  \n",
       "GHCND:USC00040943        METERS -119.01420  \n",
       "GHCND:USC00040983        METERS -116.40360  \n",
       "GHCND:USC00041018        METERS -120.65560  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all cimis stations information\n",
    "stations = pd.read_parquet(METADATA_PATH_AND_FILENAME)\n",
    "stations.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GHCND_USC00040136',\n",
       " 'GHCND_USC00040161',\n",
       " 'GHCND_USC00040212',\n",
       " 'GHCND_USC00040343',\n",
       " 'GHCND_USC00040383',\n",
       " 'GHCND_USC00040449',\n",
       " 'GHCND_USC00040693',\n",
       " 'GHCND_USC00040741',\n",
       " 'GHCND_USC00040790',\n",
       " 'GHCND_USC00040798',\n",
       " 'GHCND_USC00040931',\n",
       " 'GHCND_USC00040943',\n",
       " 'GHCND_USC00040983',\n",
       " 'GHCND_USC00041018',\n",
       " 'GHCND_USC00041072',\n",
       " 'GHCND_USC00041194',\n",
       " 'GHCND_USC00041244',\n",
       " 'GHCND_USC00041253',\n",
       " 'GHCND_USC00041277']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter only stations that have data at least from 1971\n",
    "statlist = list(stations[pd.to_datetime(stations[\"mindate\"])<=  \"1971-01-01\"].index)\n",
    "statlist_corrected = [stat.replace(\":\",\"_\") for stat in statlist]\n",
    "statlist_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHCND_USC00040136\n",
      "GHCND_USC00040161\n",
      "GHCND_USC00040212\n",
      "GHCND_USC00040343\n",
      "GHCND_USC00040383\n",
      "GHCND_USC00040449\n",
      "GHCND_USC00040693\n",
      "GHCND_USC00040741\n",
      "GHCND_USC00040790\n",
      "GHCND_USC00040798\n",
      "GHCND_USC00040931\n",
      "GHCND_USC00040943\n",
      "GHCND_USC00040983\n",
      "GHCND_USC00041018\n",
      "GHCND_USC00041072\n",
      "GHCND_USC00041194\n",
      "GHCND_USC00041244\n",
      "GHCND_USC00041253\n",
      "GHCND_USC00041277\n"
     ]
    }
   ],
   "source": [
    "stations_data_no_filter = {}\n",
    "stations_data_filter_nans = {}\n",
    "stations_data_filter1 = {}\n",
    "dropnans = False\n",
    "\n",
    "for stat in statlist_corrected:\n",
    "    print(stat)\n",
    "    station_data_to_read = concatenate_csv(f\"{TEMP_DATA_PATH}/{stat}\")[[\"max_temp\"]]\n",
    "    stations_data_no_filter[stat] = to_format(station_data_to_read, max_temp_lim=50, add_filter_year=None, filter_by_hist = False, filter = False, dropnans=dropnans)\n",
    "    stations_data_filter1[stat] = to_format(station_data_to_read, max_temp_lim=50, add_filter_year=None, filter_by_hist = False, filter = True, dropnans=dropnans)\n",
    "    stations_data_filter_nans[stat] = to_format(station_data_to_read, max_temp_lim=50, add_filter_year=None, filter_by_hist = False, filter = False, dropnans=dropnans)\n",
    "\n",
    "    stations_data_filter1[stat].to_parquet(CLEANED_DATA_PATH + f'Stat_{stat}.parquet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     total      nans       >50\n",
      "GHCND_USC00040136  19266.0  0.119174  0.010589\n",
      "GHCND_USC00040161  19073.0  0.201183  0.005865\n",
      "GHCND_USC00040212  18993.0  0.077546  0.014170\n",
      "GHCND_USC00040343  18353.0  0.061974  0.000311\n",
      "GHCND_USC00040383  18994.0  0.143984  0.000208\n",
      "GHCND_USC00040449  18991.0  0.106405  0.008357\n",
      "GHCND_USC00040693  18994.0  0.097633  0.002855\n",
      "GHCND_USC00040741  19174.0  0.062753  0.045676\n",
      "GHCND_USC00040790  10620.0  0.058289  0.000000\n",
      "GHCND_USC00040798      0.0  0.000000  0.000000\n",
      "GHCND_USC00040931  19054.0  0.085384  0.019049\n",
      "GHCND_USC00040943  18968.0  0.127478  0.004100\n",
      "GHCND_USC00040983  19174.0  0.006644  0.000104\n",
      "GHCND_USC00041018  19144.0  0.233987  0.004152\n",
      "GHCND_USC00041072  18922.0  0.151874  0.000104\n",
      "GHCND_USC00041194  19327.0  0.010641  0.003426\n",
      "GHCND_USC00041244  18994.0  0.087408  0.019049\n",
      "GHCND_USC00041253  19052.0  0.016298  0.000104\n",
      "GHCND_USC00041277  19266.0  0.086733  0.004671\n"
     ]
    }
   ],
   "source": [
    "#Percentage of missing and cleaned data\n",
    "\n",
    "df_nans_and_deleted = pd.DataFrame(index=statlist_corrected)\n",
    "df_total_days = {}\n",
    "df_filter1_days = {}\n",
    "total_days = np.zeros((len(statlist_corrected),))\n",
    "filter_nan_days = np.zeros((len(statlist_corrected),))\n",
    "filter1_days = np.zeros((len(statlist_corrected),))\n",
    "\n",
    "for i, stat in enumerate(statlist_corrected):\n",
    "    df_total_days = stations_data_no_filter[stat][stations_data_no_filter[stat].index.year>1970]['max_temp']\n",
    "    #np.isnan(station_data_to_read[stat]['temperature'])\n",
    "    df_filter_nan_days = stations_data_filter_nans[stat][stations_data_filter_nans[stat].index.year>1970]['max_temp']\n",
    "\n",
    "    df_filter1_days = stations_data_filter1[stat][stations_data_filter1[stat].index.year>1970]['max_temp']\n",
    "\n",
    "    #station_data_to_read[stat][np.isnan(station_data_to_read[stat]['temperature'])]\n",
    "    total_days[i] = len(df_total_days)#[np.isnan(df_total_days)])\n",
    "    filter_nan_days[i] = len(df_filter_nan_days[np.isnan(df_total_days)])\n",
    "    filter1_days[i] = len(df_filter1_days[np.isnan(df_filter1_days)])\n",
    "\n",
    "df_nans_and_deleted['total'] = np.array(total_days)\n",
    "df_nans_and_deleted['nans'] = np.array(filter_nan_days)/(np.array(total_days)[0])\n",
    "df_nans_and_deleted['>50'] = -np.array(filter_nan_days)/(np.array(total_days)[0])+np.array(filter1_days)/(np.array(total_days)[0])\n",
    "\n",
    "\n",
    "print(df_nans_and_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\frac{total missing data}{total days} =$0.09734623533179748\n",
      "$\\frac{total missing data}{total days} =$0.008157624464452805\n"
     ]
    }
   ],
   "source": [
    "print(r'$\\frac{total missing data}{total days} =$' +\n",
    "      str(np.sum(df_nans_and_deleted['nans']*df_nans_and_deleted['total'])/np.sum(df_nans_and_deleted['total'])))\n",
    "\n",
    "print(r'$\\frac{total missing data}{total days} =$' +\n",
    "      str(np.sum(df_nans_and_deleted['>50']*df_nans_and_deleted['total'])/np.sum(df_nans_and_deleted['total'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>nans</th>\n",
       "      <th>&gt;50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040983</th>\n",
       "      <td>19174.0</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00041194</th>\n",
       "      <td>19327.0</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00041253</th>\n",
       "      <td>19052.0</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040741</th>\n",
       "      <td>19174.0</td>\n",
       "      <td>0.062753</td>\n",
       "      <td>0.045676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040212</th>\n",
       "      <td>18993.0</td>\n",
       "      <td>0.077546</td>\n",
       "      <td>0.014170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040931</th>\n",
       "      <td>19054.0</td>\n",
       "      <td>0.085384</td>\n",
       "      <td>0.019049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00041277</th>\n",
       "      <td>19266.0</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00041244</th>\n",
       "      <td>18994.0</td>\n",
       "      <td>0.087408</td>\n",
       "      <td>0.019049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040693</th>\n",
       "      <td>18994.0</td>\n",
       "      <td>0.097633</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCND_USC00040449</th>\n",
       "      <td>18991.0</td>\n",
       "      <td>0.106405</td>\n",
       "      <td>0.008357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     total      nans       >50\n",
       "GHCND_USC00040983  19174.0  0.006644  0.000104\n",
       "GHCND_USC00041194  19327.0  0.010641  0.003426\n",
       "GHCND_USC00041253  19052.0  0.016298  0.000104\n",
       "GHCND_USC00040741  19174.0  0.062753  0.045676\n",
       "GHCND_USC00040212  18993.0  0.077546  0.014170\n",
       "GHCND_USC00040931  19054.0  0.085384  0.019049\n",
       "GHCND_USC00041277  19266.0  0.086733  0.004671\n",
       "GHCND_USC00041244  18994.0  0.087408  0.019049\n",
       "GHCND_USC00040693  18994.0  0.097633  0.002855\n",
       "GHCND_USC00040449  18991.0  0.106405  0.008357"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_and_deleted.sort_values(\"nans\", ascending=True, inplace=True)\n",
    "df_nans_and_deleted = df_nans_and_deleted[df_nans_and_deleted[\"total\"] > 18500]\n",
    "df_nans_and_deleted.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GHCND_USC00040983',\n",
       " 'GHCND_USC00041194',\n",
       " 'GHCND_USC00041253',\n",
       " 'GHCND_USC00040741',\n",
       " 'GHCND_USC00040212',\n",
       " 'GHCND_USC00040931',\n",
       " 'GHCND_USC00041277',\n",
       " 'GHCND_USC00041244',\n",
       " 'GHCND_USC00040693',\n",
       " 'GHCND_USC00040449']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statlist_10 = list(df_nans_and_deleted.iloc[0:10].index)\n",
    "statlist_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GHCND_USC00040983', 'GHCND_USC00041194', 'GHCND_USC00041253', 'GHCND_USC00040741', 'GHCND_USC00040212', 'GHCND_USC00040931', 'GHCND_USC00041277', 'GHCND_USC00041244', 'GHCND_USC00040693', 'GHCND_USC00040449']\n"
     ]
    }
   ],
   "source": [
    "print(str(statlist_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
