{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC Yearly Automatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the folder to the Python path\n",
    "\n",
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())\n",
    "\n",
    "folder_path = os.path.abspath(\"functions/\") #INPUT_PATH)#'path_to_your_folder')  # Replace with the actual folder path\n",
    "sys.path.insert(0, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PredictorsDrivers import (\n",
    "    PCAPredictors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_6means = xr.load_dataset(\"data/local_data/7means_world.nc\")\n",
    "num_modes = 3\n",
    "generate_pcas = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_pcas:\n",
    "    predictors = PCAPredictors(ds_6means, num_modes, frequency=\"yearly\", total_variables=[\"SP\", \"TTR\", \"U10\", \"V10\", \"Z\", \"T2M\"] )\n",
    "    with open(\"pcas_t2m_yearly.pkl\", \"wb\") as inp:\n",
    "        pickle.dump(predictors.dict_predictors, inp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(\"pcas_1972_yearly.pkl\", \"rb\") as inp:\n",
    "        pcas = pickle.load(inp)\n",
    "    predictors = PCAPredictors(ds_6means, num_modes, frequency=\"yearly\", saved_pcas=pcas, total_variables=[\"SP\", \"TTR\", \"U10\", \"V10\", \"Z\", \"T2M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total of different PCAS {len(predictors.df_predictors.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwis_chile= pd.read_csv(f\"data/local_data/yearly/HWs_chile_central.csv\")\n",
    "hwis_chile[\"Date\"] = pd.to_datetime(hwis_chile[\"Date\"],format='%Y')\n",
    "hwis_chile.set_index('Date', inplace=True)\n",
    "first_year = 1972\n",
    "hwis_chile = hwis_chile[(hwis_chile.index.year <= 2022) & (hwis_chile.index.year >= first_year)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = [5, 10, 15, 20, 30]\n",
    "var_thresh = [None, 0.05, 0.1, 0.15]\n",
    "num_modes = [1, 2, 3]\n",
    "\n",
    "for n_mod in num_modes:\n",
    "    for thresh in var_thresh:\n",
    "        for top in top_n:\n",
    "            predictors.num_modes = n_mod\n",
    "            predictors.df_predictors = predictors.set_df_predictors()\n",
    "            top, n_exp = predictors.top_correlations_predictors(hwis_chile, threshold_variance=thresh, top_n=top)\n",
    "            predictors.experiment_to_parquet(n_exp, \"data/new_features_t2m/chile\", \"data/new_features_t2m/chile/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwis_cali= pd.read_csv(f\"data/local_data/yearly/HWs_california_NOAA.csv\")\n",
    "hwis_cali[\"Date\"] = pd.to_datetime(hwis_cali[\"Date\"],format='%Y')\n",
    "hwis_cali.set_index('Date', inplace=True)\n",
    "hwis_cali = hwis_cali[(hwis_cali.index.year <= 2022) & (hwis_cali.index.year >= first_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_mod in num_modes:\n",
    "    for thresh in var_thresh:\n",
    "        for top in top_n:\n",
    "            predictors.num_modes = n_mod\n",
    "            predictors.df_predictors = predictors.set_df_predictors()\n",
    "            top, n_exp = predictors.top_correlations_predictors(hwis_cali, threshold_variance=thresh, top_n=top)\n",
    "            predictors.experiment_to_parquet(n_exp, \"data/new_features_t2m/california\", \"data/new_features_t2m/california/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
