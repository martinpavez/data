{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC Top Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\Desktop\\data\\hw_extra\n"
     ]
    }
   ],
   "source": [
    "# Add the folder to the Python path\n",
    "\n",
    "os.chdir(\"../\")\n",
    "# change working directory to project's root path\n",
    "print(os.getcwd())\n",
    "\n",
    "folder_path = os.path.abspath(\"functions/\") #INPUT_PATH)#'path_to_your_folder')  # Replace with the actual folder path\n",
    "sys.path.insert(0, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PredictorsDrivers import (\n",
    "    PCAPredictors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_6means = xr.load_dataset(\"data/local_data/6means_world.nc\")\n",
    "with open(\"pcas_1972.pkl\", \"rb\") as inp:\n",
    "    pcas = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = PCAPredictors(ds_6means, 3, saved_pcas=pcas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of different PCAS 4536\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of different PCAS {len(predictors.df_predictors.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwis_chile= pd.read_csv(f\"data/local_data/monthly/HWs_chile_central.csv\")\n",
    "hwis_chile[\"Date\"] = pd.to_datetime(hwis_chile[\"Date\"],format='%Y-%m')\n",
    "hwis_chile.set_index('Date', inplace=True)\n",
    "hwis_chile = hwis_chile.rolling(2).mean()\n",
    "hwis_chile = hwis_chile[(hwis_chile.index.year <= 2022) & (hwis_chile.index.year >= 1972)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = [5, 10, 15, 20, 30]\n",
    "var_thresh = [None, 0.05, 0.1, 0.15]\n",
    "num_modes = [1, 2, 3]\n",
    "\n",
    "for n_mod in num_modes:\n",
    "    for thresh in var_thresh:\n",
    "        for top in top_n:\n",
    "            predictors.n_modes = n_mod\n",
    "            predictors.df_predictors = predictors.set_df_predictors()\n",
    "            top, n_exp = predictors.top_correlations_predictors(hwis_chile, threshold_variance=thresh, top_n=top)\n",
    "            predictors.experiment_to_parquet(n_exp, \"data/new_features/chile\", \"data/new_features/chile/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwis_cali= pd.read_csv(f\"data/local_data/monthly/HWs_california_NOAA.csv\")\n",
    "hwis_cali[\"Date\"] = pd.to_datetime(hwis_cali[\"Date\"],format='%Y-%m')\n",
    "hwis_cali.set_index('Date', inplace=True)\n",
    "hwis_cali = hwis_cali.rolling(2).mean()\n",
    "hwis_cali = hwis_cali[(hwis_cali.index.year <= 2022) & (hwis_cali.index.year >= 1972)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_mod in num_modes:\n",
    "    for thresh in var_thresh:\n",
    "        for top in top_n:\n",
    "            predictors.n_modes = n_mod\n",
    "            predictors.df_predictors = predictors.set_df_predictors()\n",
    "            top, n_exp = predictors.top_correlations_predictors(hwis_cali, threshold_variance=thresh, top_n=top)\n",
    "            predictors.experiment_to_parquet(n_exp, \"data/new_features/california\", \"data/new_features/california/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
